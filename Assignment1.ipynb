{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\12905\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 17.0/39.5 MB 97.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 109.3 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\12905\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YuBvALz9PLB7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cdx_nyEUVVsW",
    "outputId": "25b7a28f-8c28-4cf1-e898-09bbf8667bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data=tf.keras.datasets.fashion_mnist\n",
    "(xtrain,ytrain),(xtest,ytest)=data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOOp_NuHV8OJ",
    "outputId": "75598847-98b5-4cc1-c447-6afb22a7bbf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "1St2KK4nV9MB",
    "outputId": "e7c5ebc1-ba57-4ff9-8270-38c5d0379dbf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize images\n",
    "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "def plotdata(images,num):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(num):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(images[i])\n",
    "    plt.show()\n",
    "\n",
    "plotdata(xtrain,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqwlWgXjWAyj"
   },
   "source": [
    "SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5S4Zxq2pV-WE"
   },
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features=[]\n",
    "    for i in image:\n",
    "        keypoint,descriptor=sift.detectAndCompute(i,None)\n",
    "        if descriptor is not None:\n",
    "            features.append(np.mean(descriptor,axis=0))\n",
    "        else:\n",
    "            features.append(np.zeros(128))\n",
    "    return np.array(features)\n",
    "\n",
    "# create SIFT feature extractor\n",
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "k06amvHXWENk"
   },
   "outputs": [],
   "source": [
    "xtrain_sift =extract_features(xtrain)\n",
    "xtest_sift =extract_features(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tGLzt9FyWGiw"
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "xtrain_sift=scaler.fit_transform(xtrain_sift)\n",
    "xtest_sift=scaler.transform(xtest_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bmizLtszWHP0"
   },
   "outputs": [],
   "source": [
    "y_trainc=to_categorical(ytrain,10)\n",
    "y_testc=to_categorical(ytest,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kJwjXD7WKA6",
    "outputId": "da189c4f-c1d3-4d23-8be4-06232c6f7c18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12905\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SHFSVJffWK0M"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fmr2ulhtXDcB",
    "outputId": "19d6e327-b4de-4ac1-d203-fdb7d17722ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5164 - loss: 1.4208 - val_accuracy: 0.6195 - val_loss: 1.0995\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6199 - loss: 1.1151 - val_accuracy: 0.6372 - val_loss: 1.0498\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6357 - loss: 1.0536 - val_accuracy: 0.6486 - val_loss: 1.0211\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6478 - loss: 1.0140 - val_accuracy: 0.6543 - val_loss: 1.0048\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6631 - loss: 0.9665 - val_accuracy: 0.6540 - val_loss: 0.9888\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6738 - loss: 0.9429 - val_accuracy: 0.6635 - val_loss: 0.9810\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6829 - loss: 0.9099 - val_accuracy: 0.6668 - val_loss: 0.9730\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6845 - loss: 0.9067 - val_accuracy: 0.6648 - val_loss: 0.9598\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6877 - loss: 0.8843 - val_accuracy: 0.6671 - val_loss: 0.9505\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6963 - loss: 0.8710 - val_accuracy: 0.6690 - val_loss: 0.9551\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7068 - loss: 0.8401 - val_accuracy: 0.6620 - val_loss: 0.9757\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7070 - loss: 0.8316 - val_accuracy: 0.6709 - val_loss: 0.9554\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7133 - loss: 0.8153 - val_accuracy: 0.6736 - val_loss: 0.9453\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7185 - loss: 0.8059 - val_accuracy: 0.6743 - val_loss: 0.9489\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7173 - loss: 0.8045 - val_accuracy: 0.6773 - val_loss: 0.9414\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7280 - loss: 0.7794 - val_accuracy: 0.6814 - val_loss: 0.9549\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7287 - loss: 0.7680 - val_accuracy: 0.6746 - val_loss: 0.9679\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.7687 - val_accuracy: 0.6729 - val_loss: 0.9610\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.7540 - val_accuracy: 0.6804 - val_loss: 0.9499\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.7442 - val_accuracy: 0.6749 - val_loss: 0.9627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f9b67ab70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_sift,y_trainc,epochs=20,batch_size=32,validation_data=(xtest_sift,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OoobTJ0XFPa",
    "outputId": "6e6292fc-086a-4d69-c501-cc1cec0bbf1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6751 - loss: 0.9648\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLTu0eBjXHic",
    "outputId": "6cd93be2-d03e-4b2f-beff-07d386e74ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 67.49%\n"
     ]
    }
   ],
   "source": [
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSn4zBV9a4fy",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combination 2: change the hyperparameter to LR  = 0.1 ; batch size =4  optimizer = SGD , activation function. = sigmoid and the loss function is MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x23hFODS5YIs",
    "outputId": "5175e1b1-b526-4932-8c82-c89bb7e9afd3"
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='sigmoid',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='sigmoid',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='sigmoid'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "pt0kO4rQbvU5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),loss='mae',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7j1DkgtXdH2l",
    "outputId": "22cc3e58-f62f-4a90-90be-b3d90cfd62c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 533us/step - accuracy: 0.1086 - loss: 0.1789 - val_accuracy: 0.2372 - val_loss: 0.1603\n",
      "Epoch 2/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 506us/step - accuracy: 0.2385 - loss: 0.1556 - val_accuracy: 0.2638 - val_loss: 0.1479\n",
      "Epoch 3/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 508us/step - accuracy: 0.2629 - loss: 0.1482 - val_accuracy: 0.2682 - val_loss: 0.1464\n",
      "Epoch 4/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 528us/step - accuracy: 0.2964 - loss: 0.1429 - val_accuracy: 0.3273 - val_loss: 0.1361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f9b30d8b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_sift,y_trainc,epochs=4,batch_size=4,validation_data=(xtest_sift,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0YIagi57PhB",
    "outputId": "a2a499dd-251f-43f0-dcde-c006b4d67e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.3282 - loss: 0.1360\n",
      "test_accuracy: 32.73%\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYsaeJkU7So0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### combination 3: tanh , rmsprop, 16, 0.01, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Rrj4-mI61UCD"
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='tanh',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='tanh',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "GAFpprRj9uMz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8LV5m9tY7yBp"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= RMSprop(learning_rate=0.01),loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nyjzPRh1Ug_",
    "outputId": "0f659a12-b8ff-4cee-dee0-0b88542aabc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 853us/step - accuracy: 0.4143 - loss: 0.0798 - val_accuracy: 0.4575 - val_loss: 0.0775\n",
      "Epoch 2/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 821us/step - accuracy: 0.4688 - loss: 0.0743 - val_accuracy: 0.4697 - val_loss: 0.0717\n",
      "Epoch 3/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 821us/step - accuracy: 0.4702 - loss: 0.0745 - val_accuracy: 0.5010 - val_loss: 0.0703\n",
      "Epoch 4/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 822us/step - accuracy: 0.4682 - loss: 0.0750 - val_accuracy: 0.4714 - val_loss: 0.0708\n",
      "Epoch 5/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 826us/step - accuracy: 0.4702 - loss: 0.0747 - val_accuracy: 0.4799 - val_loss: 0.0694\n",
      "Epoch 6/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 824us/step - accuracy: 0.4763 - loss: 0.0741 - val_accuracy: 0.5200 - val_loss: 0.0709\n",
      "Epoch 7/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 828us/step - accuracy: 0.4806 - loss: 0.0741 - val_accuracy: 0.5048 - val_loss: 0.0722\n",
      "Epoch 8/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 823us/step - accuracy: 0.4829 - loss: 0.0743 - val_accuracy: 0.5058 - val_loss: 0.0705\n",
      "Epoch 9/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 851us/step - accuracy: 0.4764 - loss: 0.0747 - val_accuracy: 0.4664 - val_loss: 0.0754\n",
      "Epoch 10/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 836us/step - accuracy: 0.4786 - loss: 0.0748 - val_accuracy: 0.5208 - val_loss: 0.0672\n",
      "Epoch 11/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 833us/step - accuracy: 0.4758 - loss: 0.0751 - val_accuracy: 0.4689 - val_loss: 0.0699\n",
      "Epoch 12/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 825us/step - accuracy: 0.4743 - loss: 0.0749 - val_accuracy: 0.5072 - val_loss: 0.0719\n",
      "Epoch 13/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 926us/step - accuracy: 0.4771 - loss: 0.0750 - val_accuracy: 0.5123 - val_loss: 0.0713\n",
      "Epoch 14/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4739 - loss: 0.0755 - val_accuracy: 0.4676 - val_loss: 0.0783\n",
      "Epoch 15/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 825us/step - accuracy: 0.4758 - loss: 0.0754 - val_accuracy: 0.5151 - val_loss: 0.0709\n",
      "Epoch 16/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 830us/step - accuracy: 0.4755 - loss: 0.0755 - val_accuracy: 0.5154 - val_loss: 0.0707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22f94d1f440>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_sift,y_trainc,epochs=16,batch_size=16,validation_data=(xtest_sift,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SgHZrBN1Tv4",
    "outputId": "42bbec40-ae70-4f60-d738-800f09f5f2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.5134 - loss: 0.0710\n",
      "test_accuracy: 51.54%\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgcDImBF8YON",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### combination 4: 0.001 , batch 8 , sgd ,  sigmoid, huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "uXvfWgLV-L9e"
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='sigmoid',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='sigmoid',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='sigmoid'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "k2ml8LL9-Lwq"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001),loss=tf.keras.losses.Huber(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjv6QeIA-LMI",
    "outputId": "45519006-bab0-41ae-a6ec-c0e9534d1303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 619us/step - accuracy: 0.1003 - loss: 0.0462 - val_accuracy: 0.1000 - val_loss: 0.0453\n",
      "Epoch 2/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 591us/step - accuracy: 0.0996 - loss: 0.0459 - val_accuracy: 0.1226 - val_loss: 0.0452\n",
      "Epoch 3/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 603us/step - accuracy: 0.0997 - loss: 0.0458 - val_accuracy: 0.1116 - val_loss: 0.0451\n",
      "Epoch 4/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 644us/step - accuracy: 0.0995 - loss: 0.0457 - val_accuracy: 0.1065 - val_loss: 0.0451\n",
      "Epoch 5/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 602us/step - accuracy: 0.1039 - loss: 0.0456 - val_accuracy: 0.1136 - val_loss: 0.0450\n",
      "Epoch 6/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 741us/step - accuracy: 0.1010 - loss: 0.0456 - val_accuracy: 0.1164 - val_loss: 0.0450\n",
      "Epoch 7/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 594us/step - accuracy: 0.0987 - loss: 0.0456 - val_accuracy: 0.1176 - val_loss: 0.0450\n",
      "Epoch 8/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593us/step - accuracy: 0.0980 - loss: 0.0456 - val_accuracy: 0.1218 - val_loss: 0.0450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22fa034ea20>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_sift,y_trainc,epochs=8,batch_size=8,validation_data=(xtest_sift,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Fji4J68-Ssb",
    "outputId": "af7db5d6-a895-4945-9b78-a43fc6e54da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.1264 - loss: 0.0450\n",
      "test_accuracy: 12.18%\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is for tuneing for task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# load dataset\n",
    "data=tf.keras.datasets.fashion_mnist\n",
    "(xtrain,ytrain),(xtest,ytest)=data.load_data()\n",
    "\n",
    "def extract_features(image):\n",
    "    features=[]\n",
    "    for i in image:\n",
    "        keypoint,descriptor=sift.detectAndCompute(i,None)\n",
    "        if descriptor is not None:\n",
    "            features.append(np.mean(descriptor,axis=0))\n",
    "        else:\n",
    "            features.append(np.zeros(128))\n",
    "    return np.array(features)\n",
    "\n",
    "# create SIFT feature extractor\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "xtrain_sift =extract_features(xtrain)\n",
    "xtest_sift =extract_features(xtest)\n",
    "scaler=StandardScaler()\n",
    "xtrain_sift=scaler.fit_transform(xtrain_sift)\n",
    "xtest_sift=scaler.transform(xtest_sift)\n",
    "y_trainc=to_categorical(ytrain,10)\n",
    "y_testc=to_categorical(ytest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5172 - loss: 1.4230 - val_accuracy: 0.6249 - val_loss: 1.0935\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6192 - loss: 1.1154 - val_accuracy: 0.6382 - val_loss: 1.0428\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6397 - loss: 1.0474 - val_accuracy: 0.6521 - val_loss: 1.0014\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6536 - loss: 1.0066 - val_accuracy: 0.6517 - val_loss: 0.9995\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6646 - loss: 0.9723 - val_accuracy: 0.6582 - val_loss: 0.9766\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6724 - loss: 0.9439 - val_accuracy: 0.6616 - val_loss: 0.9672\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6783 - loss: 0.9163 - val_accuracy: 0.6664 - val_loss: 0.9622\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6875 - loss: 0.9011 - val_accuracy: 0.6750 - val_loss: 0.9612\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6899 - loss: 0.8854 - val_accuracy: 0.6735 - val_loss: 0.9545\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6976 - loss: 0.8662 - val_accuracy: 0.6766 - val_loss: 0.9573\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7040 - loss: 0.8498 - val_accuracy: 0.6807 - val_loss: 0.9382\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7081 - loss: 0.8346 - val_accuracy: 0.6758 - val_loss: 0.9384\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7151 - loss: 0.8157 - val_accuracy: 0.6745 - val_loss: 0.9401\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7128 - loss: 0.8130 - val_accuracy: 0.6788 - val_loss: 0.9521\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7198 - loss: 0.7994 - val_accuracy: 0.6743 - val_loss: 0.9487\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 0.7827 - val_accuracy: 0.6720 - val_loss: 0.9613\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7318 - loss: 0.7702 - val_accuracy: 0.6759 - val_loss: 0.9608\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7295 - loss: 0.7699 - val_accuracy: 0.6758 - val_loss: 0.9667\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7321 - loss: 0.7524 - val_accuracy: 0.6820 - val_loss: 0.9496\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.7455 - val_accuracy: 0.6756 - val_loss: 0.9548\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.6765 - loss: 0.9502\n",
      "test_accuracy: 67.56%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=20,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 1.3766 - val_accuracy: 0.6221 - val_loss: 1.0887\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 1.1004 - val_accuracy: 0.6414 - val_loss: 1.0404\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6427 - loss: 1.0404 - val_accuracy: 0.6454 - val_loss: 1.0241\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6558 - loss: 0.9918 - val_accuracy: 0.6546 - val_loss: 0.9983\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6679 - loss: 0.9583 - val_accuracy: 0.6616 - val_loss: 0.9868\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6780 - loss: 0.9291 - val_accuracy: 0.6588 - val_loss: 0.9803\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6849 - loss: 0.9015 - val_accuracy: 0.6682 - val_loss: 0.9646\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8678 - val_accuracy: 0.6744 - val_loss: 0.9605\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.8455 - val_accuracy: 0.6776 - val_loss: 0.9507\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7071 - loss: 0.8284 - val_accuracy: 0.6758 - val_loss: 0.9603\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8151 - val_accuracy: 0.6769 - val_loss: 0.9577\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.7937 - val_accuracy: 0.6774 - val_loss: 0.9719\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.7772 - val_accuracy: 0.6733 - val_loss: 0.9843\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.7632 - val_accuracy: 0.6751 - val_loss: 0.9702\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.7478 - val_accuracy: 0.6765 - val_loss: 0.9739\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.7328 - val_accuracy: 0.6731 - val_loss: 0.9812\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7481 - loss: 0.7185 - val_accuracy: 0.6798 - val_loss: 0.9968\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.7138 - val_accuracy: 0.6759 - val_loss: 1.0268\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.7021 - val_accuracy: 0.6728 - val_loss: 0.9987\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.6846 - val_accuracy: 0.6741 - val_loss: 1.0303\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7650 - loss: 0.6765 - val_accuracy: 0.6754 - val_loss: 1.0234\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.6700 - val_accuracy: 0.6813 - val_loss: 1.0199\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.6485 - val_accuracy: 0.6812 - val_loss: 1.0306\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.6432 - val_accuracy: 0.6857 - val_loss: 1.0293\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.6457 - val_accuracy: 0.6764 - val_loss: 1.0307\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.6293 - val_accuracy: 0.6763 - val_loss: 1.0319\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.6227 - val_accuracy: 0.6792 - val_loss: 1.0446\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.6062 - val_accuracy: 0.6840 - val_loss: 1.0240\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.6117 - val_accuracy: 0.6821 - val_loss: 1.0795\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.6044 - val_accuracy: 0.6813 - val_loss: 1.0646\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.6089 - val_accuracy: 0.6833 - val_loss: 1.0842\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.5908 - val_accuracy: 0.6811 - val_loss: 1.0965\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.6792 - loss: 1.0854\n",
      "test_accuracy: 68.11%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(1024,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5373 - loss: 1.3617 - val_accuracy: 0.6106 - val_loss: 1.1255\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6189 - loss: 1.1056 - val_accuracy: 0.6355 - val_loss: 1.0604\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 1.0310 - val_accuracy: 0.6459 - val_loss: 1.0262\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6559 - loss: 0.9946 - val_accuracy: 0.6475 - val_loss: 1.0206\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.9502 - val_accuracy: 0.6617 - val_loss: 0.9900\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.9258 - val_accuracy: 0.6664 - val_loss: 0.9756\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.8971 - val_accuracy: 0.6684 - val_loss: 0.9647\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.8763 - val_accuracy: 0.6703 - val_loss: 0.9569\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6999 - loss: 0.8540 - val_accuracy: 0.6658 - val_loss: 0.9923\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7046 - loss: 0.8481 - val_accuracy: 0.6801 - val_loss: 0.9495\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7090 - loss: 0.8298 - val_accuracy: 0.6744 - val_loss: 0.9595\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7180 - loss: 0.8028 - val_accuracy: 0.6706 - val_loss: 0.9590\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.7924 - val_accuracy: 0.6825 - val_loss: 0.9688\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.7749 - val_accuracy: 0.6767 - val_loss: 0.9992\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.7532 - val_accuracy: 0.6736 - val_loss: 0.9760\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.7506 - val_accuracy: 0.6782 - val_loss: 0.9708\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.7310 - val_accuracy: 0.6796 - val_loss: 0.9919\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7454 - loss: 0.7279 - val_accuracy: 0.6800 - val_loss: 0.9725\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.7089 - val_accuracy: 0.6819 - val_loss: 0.9952\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7532 - loss: 0.7066 - val_accuracy: 0.6819 - val_loss: 1.0168\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.6935 - val_accuracy: 0.6816 - val_loss: 0.9844\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7576 - loss: 0.6885 - val_accuracy: 0.6831 - val_loss: 1.0166\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7654 - loss: 0.6701 - val_accuracy: 0.6785 - val_loss: 1.0104\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.6669 - val_accuracy: 0.6826 - val_loss: 1.0059\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.6508 - val_accuracy: 0.6846 - val_loss: 0.9847\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.6403 - val_accuracy: 0.6792 - val_loss: 1.0175\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.6392 - val_accuracy: 0.6834 - val_loss: 1.0190\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.6291 - val_accuracy: 0.6857 - val_loss: 1.0174\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.6322 - val_accuracy: 0.6827 - val_loss: 1.0336\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.6186 - val_accuracy: 0.6817 - val_loss: 1.0515\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.6052 - val_accuracy: 0.6822 - val_loss: 1.0227\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.6042 - val_accuracy: 0.6782 - val_loss: 1.0656\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.6771 - loss: 1.0549\n",
      "test_accuracy: 67.82%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(1024,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5367 - loss: 1.3575 - val_accuracy: 0.6261 - val_loss: 1.0864\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6254 - loss: 1.0846 - val_accuracy: 0.6426 - val_loss: 1.0429\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6427 - loss: 1.0248 - val_accuracy: 0.6460 - val_loss: 1.0200\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.9793 - val_accuracy: 0.6494 - val_loss: 1.0066\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.9381 - val_accuracy: 0.6614 - val_loss: 0.9873\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6790 - loss: 0.9162 - val_accuracy: 0.6633 - val_loss: 0.9720\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.8843 - val_accuracy: 0.6717 - val_loss: 0.9529\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6989 - loss: 0.8600 - val_accuracy: 0.6659 - val_loss: 0.9632\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.8426 - val_accuracy: 0.6703 - val_loss: 0.9580\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7113 - loss: 0.8247 - val_accuracy: 0.6706 - val_loss: 0.9688\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.8120 - val_accuracy: 0.6795 - val_loss: 0.9492\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.7887 - val_accuracy: 0.6713 - val_loss: 0.9646\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.7758 - val_accuracy: 0.6722 - val_loss: 0.9661\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.7594 - val_accuracy: 0.6727 - val_loss: 0.9603\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.7451 - val_accuracy: 0.6762 - val_loss: 0.9794\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.7383 - val_accuracy: 0.6739 - val_loss: 0.9929\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.7222 - val_accuracy: 0.6836 - val_loss: 0.9628\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.7118 - val_accuracy: 0.6784 - val_loss: 0.9652\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7506 - loss: 0.7122 - val_accuracy: 0.6721 - val_loss: 0.9793\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.7002 - val_accuracy: 0.6805 - val_loss: 0.9747\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.6765 - val_accuracy: 0.6762 - val_loss: 0.9978\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7611 - loss: 0.6793 - val_accuracy: 0.6754 - val_loss: 0.9953\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.6771 - val_accuracy: 0.6772 - val_loss: 0.9956\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7696 - loss: 0.6612 - val_accuracy: 0.6750 - val_loss: 1.0093\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.6557 - val_accuracy: 0.6768 - val_loss: 1.0256\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.6527 - val_accuracy: 0.6816 - val_loss: 0.9954\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7781 - loss: 0.6401 - val_accuracy: 0.6748 - val_loss: 1.0007\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.6325 - val_accuracy: 0.6855 - val_loss: 1.0409\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6286 - val_accuracy: 0.6795 - val_loss: 1.0104\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.6233 - val_accuracy: 0.6808 - val_loss: 1.0387\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.6245 - val_accuracy: 0.6743 - val_loss: 1.0346\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.6113 - val_accuracy: 0.6748 - val_loss: 1.0171\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.6809 - loss: 0.9935\n",
      "test_accuracy: 67.48%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1024,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5309 - loss: 1.3637 - val_accuracy: 0.6093 - val_loss: 1.1493\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6225 - loss: 1.1013 - val_accuracy: 0.6352 - val_loss: 1.0483\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6439 - loss: 1.0311 - val_accuracy: 0.6453 - val_loss: 1.0126\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6576 - loss: 0.9911 - val_accuracy: 0.6478 - val_loss: 1.0162\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6689 - loss: 0.9558 - val_accuracy: 0.6610 - val_loss: 0.9837\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.9237 - val_accuracy: 0.6621 - val_loss: 0.9890\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6848 - loss: 0.9044 - val_accuracy: 0.6640 - val_loss: 0.9806\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6957 - loss: 0.8736 - val_accuracy: 0.6709 - val_loss: 0.9686\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7029 - loss: 0.8507 - val_accuracy: 0.6705 - val_loss: 0.9534\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.8331 - val_accuracy: 0.6729 - val_loss: 0.9838\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7148 - loss: 0.8218 - val_accuracy: 0.6746 - val_loss: 0.9660\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.7930 - val_accuracy: 0.6680 - val_loss: 0.9841\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.7735 - val_accuracy: 0.6793 - val_loss: 0.9668\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.7714 - val_accuracy: 0.6754 - val_loss: 0.9831\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.7525 - val_accuracy: 0.6791 - val_loss: 0.9854\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7414 - loss: 0.7413 - val_accuracy: 0.6737 - val_loss: 0.9785\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7454 - loss: 0.7317 - val_accuracy: 0.6752 - val_loss: 1.0027\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.7193 - val_accuracy: 0.6761 - val_loss: 1.0078\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.6988 - val_accuracy: 0.6754 - val_loss: 1.0096\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.7006 - val_accuracy: 0.6774 - val_loss: 1.0249\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7605 - loss: 0.6863 - val_accuracy: 0.6767 - val_loss: 1.0232\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.6773 - val_accuracy: 0.6728 - val_loss: 1.0129\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7712 - loss: 0.6586 - val_accuracy: 0.6782 - val_loss: 1.0060\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.6602 - val_accuracy: 0.6803 - val_loss: 1.0048\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.6428 - val_accuracy: 0.6766 - val_loss: 1.0338\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.6342 - val_accuracy: 0.6851 - val_loss: 1.0257\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 0.6321 - val_accuracy: 0.6803 - val_loss: 1.0425\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.6232 - val_accuracy: 0.6776 - val_loss: 1.0766\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7897 - loss: 0.6183 - val_accuracy: 0.6808 - val_loss: 1.0519\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.5940 - val_accuracy: 0.6802 - val_loss: 1.0605\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.5915 - val_accuracy: 0.6750 - val_loss: 1.0444\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.5954 - val_accuracy: 0.6782 - val_loss: 1.0406\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.6857 - loss: 1.0303\n",
      "test_accuracy: 67.82%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(1024,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1024,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1024,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.5156 - loss: 1.4221 - val_accuracy: 0.6093 - val_loss: 1.1159\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 1.1091 - val_accuracy: 0.6368 - val_loss: 1.0402\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 1.0392 - val_accuracy: 0.6527 - val_loss: 1.0117\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 0.9980 - val_accuracy: 0.6546 - val_loss: 0.9986\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6622 - loss: 0.9688 - val_accuracy: 0.6537 - val_loss: 0.9800\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6681 - loss: 0.9478 - val_accuracy: 0.6647 - val_loss: 0.9667\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6824 - loss: 0.9165 - val_accuracy: 0.6684 - val_loss: 0.9642\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6888 - loss: 0.8954 - val_accuracy: 0.6690 - val_loss: 0.9608\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6954 - loss: 0.8786 - val_accuracy: 0.6683 - val_loss: 0.9590\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6922 - loss: 0.8730 - val_accuracy: 0.6678 - val_loss: 0.9681\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6999 - loss: 0.8546 - val_accuracy: 0.6742 - val_loss: 0.9553\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7052 - loss: 0.8379 - val_accuracy: 0.6745 - val_loss: 0.9607\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7062 - loss: 0.8323 - val_accuracy: 0.6725 - val_loss: 0.9547\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7130 - loss: 0.8183 - val_accuracy: 0.6732 - val_loss: 0.9487\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7134 - loss: 0.8107 - val_accuracy: 0.6764 - val_loss: 0.9445\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7145 - loss: 0.8074 - val_accuracy: 0.6714 - val_loss: 0.9569\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7232 - loss: 0.7871 - val_accuracy: 0.6724 - val_loss: 0.9635\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7200 - loss: 0.7887 - val_accuracy: 0.6735 - val_loss: 0.9611\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7263 - loss: 0.7792 - val_accuracy: 0.6774 - val_loss: 0.9588\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7240 - loss: 0.7746 - val_accuracy: 0.6798 - val_loss: 0.9515\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.7693 - val_accuracy: 0.6776 - val_loss: 0.9658\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7298 - loss: 0.7604 - val_accuracy: 0.6712 - val_loss: 0.9664\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.7492 - val_accuracy: 0.6715 - val_loss: 0.9837\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.7402 - val_accuracy: 0.6764 - val_loss: 0.9648\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.7328 - val_accuracy: 0.6757 - val_loss: 0.9650\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7427 - loss: 0.7302 - val_accuracy: 0.6791 - val_loss: 0.9581\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.7279 - val_accuracy: 0.6697 - val_loss: 0.9876\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.7225 - val_accuracy: 0.6754 - val_loss: 0.9740\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.7283 - val_accuracy: 0.6788 - val_loss: 0.9700\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7484 - loss: 0.7097 - val_accuracy: 0.6757 - val_loss: 0.9590\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7507 - loss: 0.7087 - val_accuracy: 0.6772 - val_loss: 0.9978\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7541 - loss: 0.6990 - val_accuracy: 0.6795 - val_loss: 0.9837\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6789 - loss: 0.9823\n",
      "test_accuracy: 67.95%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(256,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 912us/step - accuracy: 0.5078 - loss: 1.4458 - val_accuracy: 0.6163 - val_loss: 1.1068\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887us/step - accuracy: 0.6086 - loss: 1.1360 - val_accuracy: 0.6360 - val_loss: 1.0567\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - accuracy: 0.6311 - loss: 1.0687 - val_accuracy: 0.6431 - val_loss: 1.0105\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887us/step - accuracy: 0.6443 - loss: 1.0314 - val_accuracy: 0.6552 - val_loss: 0.9950\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 938us/step - accuracy: 0.6496 - loss: 0.9930 - val_accuracy: 0.6517 - val_loss: 0.9836\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948us/step - accuracy: 0.6659 - loss: 0.9667 - val_accuracy: 0.6562 - val_loss: 0.9838\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 950us/step - accuracy: 0.6716 - loss: 0.9435 - val_accuracy: 0.6648 - val_loss: 0.9606\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 953us/step - accuracy: 0.6752 - loss: 0.9324 - val_accuracy: 0.6664 - val_loss: 0.9598\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 910us/step - accuracy: 0.6807 - loss: 0.9163 - val_accuracy: 0.6645 - val_loss: 0.9622\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900us/step - accuracy: 0.6875 - loss: 0.8971 - val_accuracy: 0.6670 - val_loss: 0.9542\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904us/step - accuracy: 0.6883 - loss: 0.8920 - val_accuracy: 0.6716 - val_loss: 0.9520\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 899us/step - accuracy: 0.6969 - loss: 0.8655 - val_accuracy: 0.6716 - val_loss: 0.9441\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step - accuracy: 0.6954 - loss: 0.8625 - val_accuracy: 0.6747 - val_loss: 0.9444\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step - accuracy: 0.7020 - loss: 0.8539 - val_accuracy: 0.6706 - val_loss: 0.9478\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 938us/step - accuracy: 0.7036 - loss: 0.8473 - val_accuracy: 0.6770 - val_loss: 0.9445\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 893us/step - accuracy: 0.7028 - loss: 0.8390 - val_accuracy: 0.6724 - val_loss: 0.9430\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896us/step - accuracy: 0.7112 - loss: 0.8232 - val_accuracy: 0.6748 - val_loss: 0.9418\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 910us/step - accuracy: 0.7082 - loss: 0.8255 - val_accuracy: 0.6792 - val_loss: 0.9411\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 889us/step - accuracy: 0.7130 - loss: 0.8126 - val_accuracy: 0.6788 - val_loss: 0.9439\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 881us/step - accuracy: 0.7140 - loss: 0.8108 - val_accuracy: 0.6774 - val_loss: 0.9442\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869us/step - accuracy: 0.7186 - loss: 0.8033 - val_accuracy: 0.6791 - val_loss: 0.9468\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 873us/step - accuracy: 0.7179 - loss: 0.8022 - val_accuracy: 0.6785 - val_loss: 0.9345\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 877us/step - accuracy: 0.7235 - loss: 0.7871 - val_accuracy: 0.6765 - val_loss: 0.9506\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 858us/step - accuracy: 0.7257 - loss: 0.7760 - val_accuracy: 0.6774 - val_loss: 0.9477\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 855us/step - accuracy: 0.7252 - loss: 0.7770 - val_accuracy: 0.6781 - val_loss: 0.9433\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866us/step - accuracy: 0.7278 - loss: 0.7757 - val_accuracy: 0.6781 - val_loss: 0.9464\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896us/step - accuracy: 0.7278 - loss: 0.7742 - val_accuracy: 0.6780 - val_loss: 0.9513\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 868us/step - accuracy: 0.7296 - loss: 0.7668 - val_accuracy: 0.6783 - val_loss: 0.9558\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 880us/step - accuracy: 0.7336 - loss: 0.7580 - val_accuracy: 0.6804 - val_loss: 0.9394\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 868us/step - accuracy: 0.7316 - loss: 0.7594 - val_accuracy: 0.6782 - val_loss: 0.9511\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866us/step - accuracy: 0.7358 - loss: 0.7517 - val_accuracy: 0.6779 - val_loss: 0.9582\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 865us/step - accuracy: 0.7374 - loss: 0.7491 - val_accuracy: 0.6775 - val_loss: 0.9636\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.6764 - loss: 0.9630\n",
      "test_accuracy: 67.75%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(256,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4967 - loss: 1.4684 - val_accuracy: 0.6076 - val_loss: 1.1322\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6031 - loss: 1.1529 - val_accuracy: 0.6297 - val_loss: 1.0650\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6211 - loss: 1.0942 - val_accuracy: 0.6418 - val_loss: 1.0325\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6335 - loss: 1.0550 - val_accuracy: 0.6471 - val_loss: 1.0146\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 1.0319 - val_accuracy: 0.6498 - val_loss: 1.0027\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6481 - loss: 1.0093 - val_accuracy: 0.6536 - val_loss: 0.9931\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6540 - loss: 0.9942 - val_accuracy: 0.6569 - val_loss: 0.9862\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6585 - loss: 0.9749 - val_accuracy: 0.6574 - val_loss: 0.9839\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6612 - loss: 0.9645 - val_accuracy: 0.6571 - val_loss: 0.9865\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6672 - loss: 0.9495 - val_accuracy: 0.6609 - val_loss: 0.9804\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.9463 - val_accuracy: 0.6619 - val_loss: 0.9724\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6666 - loss: 0.9467 - val_accuracy: 0.6628 - val_loss: 0.9631\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6777 - loss: 0.9233 - val_accuracy: 0.6622 - val_loss: 0.9682\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6768 - loss: 0.9219 - val_accuracy: 0.6703 - val_loss: 0.9591\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6795 - loss: 0.9113 - val_accuracy: 0.6631 - val_loss: 0.9733\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6813 - loss: 0.9092 - val_accuracy: 0.6660 - val_loss: 0.9737\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6836 - loss: 0.9086 - val_accuracy: 0.6650 - val_loss: 0.9567\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6866 - loss: 0.8938 - val_accuracy: 0.6649 - val_loss: 0.9538\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6820 - loss: 0.9057 - val_accuracy: 0.6652 - val_loss: 0.9612\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6873 - loss: 0.8904 - val_accuracy: 0.6692 - val_loss: 0.9536\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6887 - loss: 0.8897 - val_accuracy: 0.6697 - val_loss: 0.9593\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6897 - loss: 0.8840 - val_accuracy: 0.6630 - val_loss: 0.9777\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6890 - loss: 0.8857 - val_accuracy: 0.6692 - val_loss: 0.9588\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6915 - loss: 0.8724 - val_accuracy: 0.6655 - val_loss: 0.9613\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6928 - loss: 0.8759 - val_accuracy: 0.6703 - val_loss: 0.9577\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6948 - loss: 0.8711 - val_accuracy: 0.6636 - val_loss: 0.9602\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6926 - loss: 0.8685 - val_accuracy: 0.6709 - val_loss: 0.9494\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6970 - loss: 0.8659 - val_accuracy: 0.6622 - val_loss: 0.9610\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6991 - loss: 0.8546 - val_accuracy: 0.6687 - val_loss: 0.9642\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7009 - loss: 0.8529 - val_accuracy: 0.6653 - val_loss: 0.9597\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7004 - loss: 0.8574 - val_accuracy: 0.6631 - val_loss: 0.9658\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6968 - loss: 0.8594 - val_accuracy: 0.6655 - val_loss: 0.9570\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.6677 - loss: 0.9505\n",
      "test_accuracy: 66.55%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 800us/step - accuracy: 0.4831 - loss: 1.5060 - val_accuracy: 0.6068 - val_loss: 1.1243\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.5965 - loss: 1.1749 - val_accuracy: 0.6290 - val_loss: 1.0617\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.6181 - loss: 1.1050 - val_accuracy: 0.6409 - val_loss: 1.0320\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.6329 - loss: 1.0635 - val_accuracy: 0.6414 - val_loss: 1.0345\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.6400 - loss: 1.0399 - val_accuracy: 0.6482 - val_loss: 1.0055\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.6478 - loss: 1.0162 - val_accuracy: 0.6467 - val_loss: 0.9972\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.6521 - loss: 0.9995 - val_accuracy: 0.6568 - val_loss: 0.9861\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.6630 - loss: 0.9800 - val_accuracy: 0.6542 - val_loss: 0.9902\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.6627 - loss: 0.9675 - val_accuracy: 0.6569 - val_loss: 0.9804\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.6636 - loss: 0.9660 - val_accuracy: 0.6638 - val_loss: 0.9615\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.6679 - loss: 0.9490 - val_accuracy: 0.6632 - val_loss: 0.9638\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.6709 - loss: 0.9363 - val_accuracy: 0.6656 - val_loss: 0.9578\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.6750 - loss: 0.9292 - val_accuracy: 0.6654 - val_loss: 0.9663\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.6774 - loss: 0.9284 - val_accuracy: 0.6626 - val_loss: 0.9622\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.6829 - loss: 0.9109 - val_accuracy: 0.6652 - val_loss: 0.9546\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.6805 - loss: 0.9137 - val_accuracy: 0.6686 - val_loss: 0.9514\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.6828 - loss: 0.9092 - val_accuracy: 0.6625 - val_loss: 0.9563\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.6835 - loss: 0.9093 - val_accuracy: 0.6689 - val_loss: 0.9516\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.6841 - loss: 0.9020 - val_accuracy: 0.6655 - val_loss: 0.9586\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.6879 - loss: 0.8912 - val_accuracy: 0.6673 - val_loss: 0.9544\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.6910 - loss: 0.8811 - val_accuracy: 0.6671 - val_loss: 0.9456\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 831us/step - accuracy: 0.6917 - loss: 0.8852 - val_accuracy: 0.6698 - val_loss: 0.9458\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.6919 - loss: 0.8807 - val_accuracy: 0.6700 - val_loss: 0.9485\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.6921 - loss: 0.8762 - val_accuracy: 0.6750 - val_loss: 0.9485\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.6956 - loss: 0.8714 - val_accuracy: 0.6672 - val_loss: 0.9584\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.6976 - loss: 0.8602 - val_accuracy: 0.6698 - val_loss: 0.9570\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.6976 - loss: 0.8598 - val_accuracy: 0.6723 - val_loss: 0.9459\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.6975 - loss: 0.8685 - val_accuracy: 0.6694 - val_loss: 0.9512\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.6981 - loss: 0.8586 - val_accuracy: 0.6693 - val_loss: 0.9453\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.6965 - loss: 0.8532 - val_accuracy: 0.6694 - val_loss: 0.9468\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.7010 - loss: 0.8525 - val_accuracy: 0.6727 - val_loss: 0.9411\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.7040 - loss: 0.8470 - val_accuracy: 0.6729 - val_loss: 0.9518\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.6722 - loss: 0.9477\n",
      "test_accuracy: 67.29%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=32,batch_size=32,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4766 - loss: 1.5357 - val_accuracy: 0.6058 - val_loss: 1.1429\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5991 - loss: 1.1708 - val_accuracy: 0.6311 - val_loss: 1.0614\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6180 - loss: 1.1011 - val_accuracy: 0.6409 - val_loss: 1.0302\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6333 - loss: 1.0571 - val_accuracy: 0.6529 - val_loss: 1.0081\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6417 - loss: 1.0258 - val_accuracy: 0.6530 - val_loss: 0.9863\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6525 - loss: 0.9977 - val_accuracy: 0.6565 - val_loss: 0.9763\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6546 - loss: 0.9805 - val_accuracy: 0.6574 - val_loss: 0.9742\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6654 - loss: 0.9585 - val_accuracy: 0.6597 - val_loss: 0.9636\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.9541 - val_accuracy: 0.6627 - val_loss: 0.9601\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 0.9360 - val_accuracy: 0.6626 - val_loss: 0.9659\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6739 - loss: 0.9293 - val_accuracy: 0.6682 - val_loss: 0.9602\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.9122 - val_accuracy: 0.6710 - val_loss: 0.9451\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6804 - loss: 0.9065 - val_accuracy: 0.6684 - val_loss: 0.9495\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6855 - loss: 0.8907 - val_accuracy: 0.6673 - val_loss: 0.9554\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.8904 - val_accuracy: 0.6732 - val_loss: 0.9490\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: 0.8824 - val_accuracy: 0.6669 - val_loss: 0.9469\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8755 - val_accuracy: 0.6700 - val_loss: 0.9450\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6940 - loss: 0.8637 - val_accuracy: 0.6730 - val_loss: 0.9415\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.8642 - val_accuracy: 0.6686 - val_loss: 0.9471\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8565 - val_accuracy: 0.6706 - val_loss: 0.9452\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.8512 - val_accuracy: 0.6711 - val_loss: 0.9382\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8378 - val_accuracy: 0.6726 - val_loss: 0.9430\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.8469 - val_accuracy: 0.6731 - val_loss: 0.9419\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.8435 - val_accuracy: 0.6705 - val_loss: 0.9435\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7071 - loss: 0.8258 - val_accuracy: 0.6734 - val_loss: 0.9487\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.8350 - val_accuracy: 0.6724 - val_loss: 0.9432\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8279 - val_accuracy: 0.6735 - val_loss: 0.9456\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.8213 - val_accuracy: 0.6704 - val_loss: 0.9480\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8217 - val_accuracy: 0.6738 - val_loss: 0.9409\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.8101 - val_accuracy: 0.6726 - val_loss: 0.9448\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.8061 - val_accuracy: 0.6732 - val_loss: 0.9466\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.8131 - val_accuracy: 0.6760 - val_loss: 0.9476\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.8056 - val_accuracy: 0.6745 - val_loss: 0.9486\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.8079 - val_accuracy: 0.6743 - val_loss: 0.9449\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8044 - val_accuracy: 0.6758 - val_loss: 0.9479\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7971 - val_accuracy: 0.6675 - val_loss: 0.9609\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.7931 - val_accuracy: 0.6731 - val_loss: 0.9497\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.7887 - val_accuracy: 0.6741 - val_loss: 0.9474\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7851 - val_accuracy: 0.6686 - val_loss: 0.9524\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.7899 - val_accuracy: 0.6752 - val_loss: 0.9499\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.7915 - val_accuracy: 0.6717 - val_loss: 0.9581\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7819 - val_accuracy: 0.6735 - val_loss: 0.9540\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.7831 - val_accuracy: 0.6713 - val_loss: 0.9519\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.7720 - val_accuracy: 0.6711 - val_loss: 0.9508\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.7805 - val_accuracy: 0.6705 - val_loss: 0.9597\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.7727 - val_accuracy: 0.6708 - val_loss: 0.9528\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.7647 - val_accuracy: 0.6732 - val_loss: 0.9513\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.7727 - val_accuracy: 0.6689 - val_loss: 0.9553\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.7653 - val_accuracy: 0.6721 - val_loss: 0.9538\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.7580 - val_accuracy: 0.6742 - val_loss: 0.9622\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.7669 - val_accuracy: 0.6736 - val_loss: 0.9549\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.7690 - val_accuracy: 0.6733 - val_loss: 0.9535\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.7586 - val_accuracy: 0.6730 - val_loss: 0.9553\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.7517 - val_accuracy: 0.6742 - val_loss: 0.9563\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.7570 - val_accuracy: 0.6751 - val_loss: 0.9565\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.7554 - val_accuracy: 0.6719 - val_loss: 0.9628\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.7641 - val_accuracy: 0.6689 - val_loss: 0.9582\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.7627 - val_accuracy: 0.6716 - val_loss: 0.9718\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.7511 - val_accuracy: 0.6717 - val_loss: 0.9702\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.7555 - val_accuracy: 0.6713 - val_loss: 0.9630\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.7442 - val_accuracy: 0.6753 - val_loss: 0.9661\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.7467 - val_accuracy: 0.6747 - val_loss: 0.9673\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.7459 - val_accuracy: 0.6724 - val_loss: 0.9672\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.7477 - val_accuracy: 0.6732 - val_loss: 0.9726\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.7395 - val_accuracy: 0.6685 - val_loss: 0.9732\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.7414 - val_accuracy: 0.6700 - val_loss: 0.9756\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.7382 - val_accuracy: 0.6703 - val_loss: 0.9792\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.7332 - val_accuracy: 0.6754 - val_loss: 0.9748\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.7303 - val_accuracy: 0.6711 - val_loss: 0.9685\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.7403 - val_accuracy: 0.6724 - val_loss: 0.9662\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.7320 - val_accuracy: 0.6727 - val_loss: 0.9610\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.7403 - val_accuracy: 0.6725 - val_loss: 0.9746\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.7259 - val_accuracy: 0.6744 - val_loss: 0.9673\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.7353 - val_accuracy: 0.6732 - val_loss: 0.9654\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.7370 - val_accuracy: 0.6726 - val_loss: 0.9685\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.7292 - val_accuracy: 0.6706 - val_loss: 0.9680\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.7276 - val_accuracy: 0.6758 - val_loss: 0.9644\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.7255 - val_accuracy: 0.6711 - val_loss: 0.9644\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.7298 - val_accuracy: 0.6720 - val_loss: 0.9679\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.7212 - val_accuracy: 0.6741 - val_loss: 0.9729\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.7343 - val_accuracy: 0.6753 - val_loss: 0.9743\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.7278 - val_accuracy: 0.6730 - val_loss: 0.9724\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.7238 - val_accuracy: 0.6740 - val_loss: 0.9697\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.7323 - val_accuracy: 0.6697 - val_loss: 0.9644\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.7163 - val_accuracy: 0.6701 - val_loss: 0.9705\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.7253 - val_accuracy: 0.6686 - val_loss: 0.9789\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.7139 - val_accuracy: 0.6721 - val_loss: 0.9808\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.7227 - val_accuracy: 0.6727 - val_loss: 0.9719\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.7192 - val_accuracy: 0.6754 - val_loss: 0.9713\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7462 - loss: 0.7139 - val_accuracy: 0.6755 - val_loss: 0.9787\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.7225 - val_accuracy: 0.6750 - val_loss: 0.9735\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.7177 - val_accuracy: 0.6732 - val_loss: 0.9697\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.7164 - val_accuracy: 0.6713 - val_loss: 0.9802\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.7002 - val_accuracy: 0.6737 - val_loss: 0.9722\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7470 - loss: 0.7154 - val_accuracy: 0.6753 - val_loss: 0.9670\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.7181 - val_accuracy: 0.6748 - val_loss: 0.9777\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.7231 - val_accuracy: 0.6750 - val_loss: 0.9762\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.7164 - val_accuracy: 0.6740 - val_loss: 0.9774\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.7151 - val_accuracy: 0.6743 - val_loss: 0.9773\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.7117 - val_accuracy: 0.6746 - val_loss: 0.9805\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6728 - loss: 0.9728\n",
      "test_accuracy: 67.46%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=100,batch_size=100,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4492 - loss: 1.6070 - val_accuracy: 0.5982 - val_loss: 1.1547\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5905 - loss: 1.1958 - val_accuracy: 0.6261 - val_loss: 1.0760\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6128 - loss: 1.1263 - val_accuracy: 0.6361 - val_loss: 1.0426\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6283 - loss: 1.0798 - val_accuracy: 0.6475 - val_loss: 1.0189\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6411 - loss: 1.0386 - val_accuracy: 0.6504 - val_loss: 1.0090\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6432 - loss: 1.0269 - val_accuracy: 0.6534 - val_loss: 0.9890\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6510 - loss: 1.0037 - val_accuracy: 0.6579 - val_loss: 0.9805\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6532 - loss: 0.9862 - val_accuracy: 0.6586 - val_loss: 0.9751\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6607 - loss: 0.9682 - val_accuracy: 0.6654 - val_loss: 0.9624\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6702 - loss: 0.9487 - val_accuracy: 0.6602 - val_loss: 0.9564\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6689 - loss: 0.9440 - val_accuracy: 0.6660 - val_loss: 0.9601\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6717 - loss: 0.9418 - val_accuracy: 0.6682 - val_loss: 0.9487\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6733 - loss: 0.9295 - val_accuracy: 0.6693 - val_loss: 0.9507\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6801 - loss: 0.9113 - val_accuracy: 0.6701 - val_loss: 0.9475\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6795 - loss: 0.9159 - val_accuracy: 0.6680 - val_loss: 0.9448\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6870 - loss: 0.8992 - val_accuracy: 0.6677 - val_loss: 0.9486\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6888 - loss: 0.8970 - val_accuracy: 0.6652 - val_loss: 0.9459\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6890 - loss: 0.8837 - val_accuracy: 0.6708 - val_loss: 0.9413\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6919 - loss: 0.8759 - val_accuracy: 0.6691 - val_loss: 0.9436\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6879 - loss: 0.8846 - val_accuracy: 0.6723 - val_loss: 0.9389\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6921 - loss: 0.8695 - val_accuracy: 0.6702 - val_loss: 0.9392\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6931 - loss: 0.8690 - val_accuracy: 0.6724 - val_loss: 0.9350\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6965 - loss: 0.8641 - val_accuracy: 0.6721 - val_loss: 0.9368\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6983 - loss: 0.8576 - val_accuracy: 0.6726 - val_loss: 0.9304\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7050 - loss: 0.8460 - val_accuracy: 0.6755 - val_loss: 0.9330\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7044 - loss: 0.8451 - val_accuracy: 0.6770 - val_loss: 0.9339\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7048 - loss: 0.8354 - val_accuracy: 0.6732 - val_loss: 0.9461\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7042 - loss: 0.8383 - val_accuracy: 0.6736 - val_loss: 0.9414\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7074 - loss: 0.8297 - val_accuracy: 0.6753 - val_loss: 0.9317\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7082 - loss: 0.8298 - val_accuracy: 0.6731 - val_loss: 0.9375\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7092 - loss: 0.8274 - val_accuracy: 0.6746 - val_loss: 0.9364\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7084 - loss: 0.8273 - val_accuracy: 0.6755 - val_loss: 0.9365\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7057 - loss: 0.8279 - val_accuracy: 0.6763 - val_loss: 0.9328\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7092 - loss: 0.8286 - val_accuracy: 0.6739 - val_loss: 0.9318\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7132 - loss: 0.8136 - val_accuracy: 0.6747 - val_loss: 0.9384\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7100 - loss: 0.8206 - val_accuracy: 0.6737 - val_loss: 0.9467\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7153 - loss: 0.8121 - val_accuracy: 0.6726 - val_loss: 0.9342\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7115 - loss: 0.8118 - val_accuracy: 0.6746 - val_loss: 0.9315\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.8125 - val_accuracy: 0.6748 - val_loss: 0.9387\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7100 - loss: 0.8185 - val_accuracy: 0.6709 - val_loss: 0.9429\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7148 - loss: 0.8058 - val_accuracy: 0.6752 - val_loss: 0.9452\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7170 - loss: 0.8024 - val_accuracy: 0.6769 - val_loss: 0.9365\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7134 - loss: 0.8022 - val_accuracy: 0.6721 - val_loss: 0.9439\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7177 - loss: 0.8000 - val_accuracy: 0.6746 - val_loss: 0.9391\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7198 - loss: 0.7924 - val_accuracy: 0.6750 - val_loss: 0.9421\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7189 - loss: 0.8012 - val_accuracy: 0.6709 - val_loss: 0.9414\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7189 - loss: 0.7923 - val_accuracy: 0.6711 - val_loss: 0.9439\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7213 - loss: 0.7878 - val_accuracy: 0.6703 - val_loss: 0.9449\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7199 - loss: 0.7904 - val_accuracy: 0.6702 - val_loss: 0.9474\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.7924 - val_accuracy: 0.6760 - val_loss: 0.9390\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7205 - loss: 0.7851 - val_accuracy: 0.6757 - val_loss: 0.9413\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7233 - loss: 0.7844 - val_accuracy: 0.6775 - val_loss: 0.9446\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 0.7853 - val_accuracy: 0.6749 - val_loss: 0.9528\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7210 - loss: 0.7885 - val_accuracy: 0.6753 - val_loss: 0.9422\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7235 - loss: 0.7820 - val_accuracy: 0.6754 - val_loss: 0.9436\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7225 - loss: 0.7908 - val_accuracy: 0.6785 - val_loss: 0.9403\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7254 - loss: 0.7781 - val_accuracy: 0.6802 - val_loss: 0.9494\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.7868 - val_accuracy: 0.6799 - val_loss: 0.9426\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.7742 - val_accuracy: 0.6753 - val_loss: 0.9475\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7293 - loss: 0.7719 - val_accuracy: 0.6774 - val_loss: 0.9511\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7241 - loss: 0.7819 - val_accuracy: 0.6765 - val_loss: 0.9411\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7274 - loss: 0.7761 - val_accuracy: 0.6757 - val_loss: 0.9487\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7295 - loss: 0.7701 - val_accuracy: 0.6754 - val_loss: 0.9482\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7293 - loss: 0.7652 - val_accuracy: 0.6788 - val_loss: 0.9487\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7271 - loss: 0.7711 - val_accuracy: 0.6771 - val_loss: 0.9472\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.7764 - val_accuracy: 0.6742 - val_loss: 0.9497\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7279 - loss: 0.7664 - val_accuracy: 0.6741 - val_loss: 0.9578\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.7672 - val_accuracy: 0.6768 - val_loss: 0.9490\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7322 - loss: 0.7604 - val_accuracy: 0.6774 - val_loss: 0.9492\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7298 - loss: 0.7712 - val_accuracy: 0.6721 - val_loss: 0.9520\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7294 - loss: 0.7656 - val_accuracy: 0.6754 - val_loss: 0.9507\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.7557 - val_accuracy: 0.6787 - val_loss: 0.9532\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.7546 - val_accuracy: 0.6766 - val_loss: 0.9517\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7321 - loss: 0.7607 - val_accuracy: 0.6764 - val_loss: 0.9558\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.7590 - val_accuracy: 0.6741 - val_loss: 0.9589\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.7514 - val_accuracy: 0.6762 - val_loss: 0.9474\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7353 - loss: 0.7541 - val_accuracy: 0.6762 - val_loss: 0.9565\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.7537 - val_accuracy: 0.6735 - val_loss: 0.9632\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.7556 - val_accuracy: 0.6777 - val_loss: 0.9546\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7299 - loss: 0.7623 - val_accuracy: 0.6792 - val_loss: 0.9631\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.7453 - val_accuracy: 0.6768 - val_loss: 0.9650\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7311 - loss: 0.7568 - val_accuracy: 0.6792 - val_loss: 0.9588\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7327 - loss: 0.7610 - val_accuracy: 0.6779 - val_loss: 0.9558\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7332 - loss: 0.7575 - val_accuracy: 0.6749 - val_loss: 0.9621\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.7535 - val_accuracy: 0.6784 - val_loss: 0.9581\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.7522 - val_accuracy: 0.6782 - val_loss: 0.9554\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.7470 - val_accuracy: 0.6736 - val_loss: 0.9604\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7408 - loss: 0.7345 - val_accuracy: 0.6757 - val_loss: 0.9595\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7349 - loss: 0.7477 - val_accuracy: 0.6796 - val_loss: 0.9630\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7353 - loss: 0.7445 - val_accuracy: 0.6773 - val_loss: 0.9640\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7390 - loss: 0.7398 - val_accuracy: 0.6769 - val_loss: 0.9633\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.7417 - val_accuracy: 0.6784 - val_loss: 0.9556\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.7454 - val_accuracy: 0.6785 - val_loss: 0.9617\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.7404 - val_accuracy: 0.6786 - val_loss: 0.9596\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.7415 - val_accuracy: 0.6762 - val_loss: 0.9646\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7358 - loss: 0.7471 - val_accuracy: 0.6761 - val_loss: 0.9619\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7397 - loss: 0.7372 - val_accuracy: 0.6789 - val_loss: 0.9647\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.7390 - val_accuracy: 0.6775 - val_loss: 0.9730\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.7334 - val_accuracy: 0.6793 - val_loss: 0.9550\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7408 - loss: 0.7307 - val_accuracy: 0.6764 - val_loss: 0.9708\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.6757 - loss: 0.9756\n",
      "test_accuracy: 67.64%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=100,batch_size=100,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4540 - loss: 1.6053 - val_accuracy: 0.6081 - val_loss: 1.1508\n",
      "Epoch 2/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5860 - loss: 1.2129 - val_accuracy: 0.6273 - val_loss: 1.0869\n",
      "Epoch 3/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6060 - loss: 1.1359 - val_accuracy: 0.6427 - val_loss: 1.0438\n",
      "Epoch 4/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6287 - loss: 1.0828 - val_accuracy: 0.6514 - val_loss: 1.0217\n",
      "Epoch 5/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6367 - loss: 1.0557 - val_accuracy: 0.6512 - val_loss: 1.0019\n",
      "Epoch 6/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6463 - loss: 1.0263 - val_accuracy: 0.6576 - val_loss: 0.9896\n",
      "Epoch 7/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6477 - loss: 1.0128 - val_accuracy: 0.6584 - val_loss: 0.9752\n",
      "Epoch 8/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6577 - loss: 0.9909 - val_accuracy: 0.6631 - val_loss: 0.9702\n",
      "Epoch 9/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6592 - loss: 0.9722 - val_accuracy: 0.6616 - val_loss: 0.9634\n",
      "Epoch 10/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6644 - loss: 0.9618 - val_accuracy: 0.6644 - val_loss: 0.9622\n",
      "Epoch 11/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6672 - loss: 0.9500 - val_accuracy: 0.6663 - val_loss: 0.9587\n",
      "Epoch 12/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.9363 - val_accuracy: 0.6742 - val_loss: 0.9447\n",
      "Epoch 13/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6790 - loss: 0.9188 - val_accuracy: 0.6682 - val_loss: 0.9451\n",
      "Epoch 14/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6803 - loss: 0.9134 - val_accuracy: 0.6694 - val_loss: 0.9435\n",
      "Epoch 15/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6812 - loss: 0.9069 - val_accuracy: 0.6723 - val_loss: 0.9462\n",
      "Epoch 16/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6840 - loss: 0.9029 - val_accuracy: 0.6737 - val_loss: 0.9375\n",
      "Epoch 17/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6846 - loss: 0.8986 - val_accuracy: 0.6744 - val_loss: 0.9441\n",
      "Epoch 18/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6864 - loss: 0.8914 - val_accuracy: 0.6755 - val_loss: 0.9389\n",
      "Epoch 19/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6925 - loss: 0.8780 - val_accuracy: 0.6771 - val_loss: 0.9314\n",
      "Epoch 20/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6897 - loss: 0.8817 - val_accuracy: 0.6728 - val_loss: 0.9400\n",
      "Epoch 21/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6937 - loss: 0.8727 - val_accuracy: 0.6762 - val_loss: 0.9301\n",
      "Epoch 22/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6954 - loss: 0.8673 - val_accuracy: 0.6767 - val_loss: 0.9344\n",
      "Epoch 23/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6993 - loss: 0.8599 - val_accuracy: 0.6746 - val_loss: 0.9395\n",
      "Epoch 24/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6969 - loss: 0.8601 - val_accuracy: 0.6785 - val_loss: 0.9363\n",
      "Epoch 25/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7016 - loss: 0.8496 - val_accuracy: 0.6741 - val_loss: 0.9394\n",
      "Epoch 26/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7018 - loss: 0.8469 - val_accuracy: 0.6751 - val_loss: 0.9367\n",
      "Epoch 27/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6982 - loss: 0.8544 - val_accuracy: 0.6778 - val_loss: 0.9333\n",
      "Epoch 28/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7055 - loss: 0.8361 - val_accuracy: 0.6735 - val_loss: 0.9439\n",
      "Epoch 29/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7058 - loss: 0.8372 - val_accuracy: 0.6772 - val_loss: 0.9382\n",
      "Epoch 30/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7092 - loss: 0.8285 - val_accuracy: 0.6736 - val_loss: 0.9403\n",
      "Epoch 31/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7107 - loss: 0.8245 - val_accuracy: 0.6776 - val_loss: 0.9400\n",
      "Epoch 32/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7059 - loss: 0.8302 - val_accuracy: 0.6760 - val_loss: 0.9356\n",
      "Epoch 33/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7087 - loss: 0.8260 - val_accuracy: 0.6787 - val_loss: 0.9382\n",
      "Epoch 34/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7119 - loss: 0.8176 - val_accuracy: 0.6798 - val_loss: 0.9317\n",
      "Epoch 35/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7087 - loss: 0.8251 - val_accuracy: 0.6797 - val_loss: 0.9368\n",
      "Epoch 36/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7080 - loss: 0.8252 - val_accuracy: 0.6794 - val_loss: 0.9327\n",
      "Epoch 37/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7111 - loss: 0.8132 - val_accuracy: 0.6738 - val_loss: 0.9444\n",
      "Epoch 38/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7177 - loss: 0.8127 - val_accuracy: 0.6773 - val_loss: 0.9338\n",
      "Epoch 39/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7170 - loss: 0.8049 - val_accuracy: 0.6791 - val_loss: 0.9376\n",
      "Epoch 40/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7129 - loss: 0.8094 - val_accuracy: 0.6749 - val_loss: 0.9493\n",
      "Epoch 41/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7119 - loss: 0.8118 - val_accuracy: 0.6792 - val_loss: 0.9420\n",
      "Epoch 42/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7195 - loss: 0.7968 - val_accuracy: 0.6773 - val_loss: 0.9419\n",
      "Epoch 43/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7178 - loss: 0.8005 - val_accuracy: 0.6746 - val_loss: 0.9433\n",
      "Epoch 44/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7217 - loss: 0.7937 - val_accuracy: 0.6784 - val_loss: 0.9378\n",
      "Epoch 45/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7204 - loss: 0.7882 - val_accuracy: 0.6787 - val_loss: 0.9366\n",
      "Epoch 46/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7220 - loss: 0.7949 - val_accuracy: 0.6774 - val_loss: 0.9407\n",
      "Epoch 47/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7208 - loss: 0.7894 - val_accuracy: 0.6772 - val_loss: 0.9565\n",
      "Epoch 48/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7206 - loss: 0.7978 - val_accuracy: 0.6759 - val_loss: 0.9558\n",
      "Epoch 49/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7199 - loss: 0.7861 - val_accuracy: 0.6739 - val_loss: 0.9462\n",
      "Epoch 50/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7216 - loss: 0.7844 - val_accuracy: 0.6744 - val_loss: 0.9468\n",
      "Epoch 51/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.7793 - val_accuracy: 0.6779 - val_loss: 0.9547\n",
      "Epoch 52/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7249 - loss: 0.7816 - val_accuracy: 0.6792 - val_loss: 0.9423\n",
      "Epoch 53/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 0.7773 - val_accuracy: 0.6771 - val_loss: 0.9408\n",
      "Epoch 54/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.7808 - val_accuracy: 0.6785 - val_loss: 0.9435\n",
      "Epoch 55/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7261 - loss: 0.7816 - val_accuracy: 0.6778 - val_loss: 0.9533\n",
      "Epoch 56/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.7783 - val_accuracy: 0.6815 - val_loss: 0.9471\n",
      "Epoch 57/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7214 - loss: 0.7814 - val_accuracy: 0.6800 - val_loss: 0.9556\n",
      "Epoch 58/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 0.7746 - val_accuracy: 0.6796 - val_loss: 0.9554\n",
      "Epoch 59/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7231 - loss: 0.7756 - val_accuracy: 0.6758 - val_loss: 0.9548\n",
      "Epoch 60/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.7761 - val_accuracy: 0.6772 - val_loss: 0.9541\n",
      "Epoch 61/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7274 - loss: 0.7668 - val_accuracy: 0.6798 - val_loss: 0.9431\n",
      "Epoch 62/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.7702 - val_accuracy: 0.6772 - val_loss: 0.9583\n",
      "Epoch 63/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7286 - loss: 0.7726 - val_accuracy: 0.6800 - val_loss: 0.9518\n",
      "Epoch 64/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.7663 - val_accuracy: 0.6772 - val_loss: 0.9594\n",
      "Epoch 65/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.7700 - val_accuracy: 0.6747 - val_loss: 0.9526\n",
      "Epoch 66/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7329 - loss: 0.7620 - val_accuracy: 0.6788 - val_loss: 0.9500\n",
      "Epoch 67/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7309 - loss: 0.7628 - val_accuracy: 0.6784 - val_loss: 0.9622\n",
      "Epoch 68/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7337 - loss: 0.7582 - val_accuracy: 0.6767 - val_loss: 0.9548\n",
      "Epoch 69/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.7577 - val_accuracy: 0.6782 - val_loss: 0.9573\n",
      "Epoch 70/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7298 - loss: 0.7618 - val_accuracy: 0.6772 - val_loss: 0.9563\n",
      "Epoch 71/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.7580 - val_accuracy: 0.6790 - val_loss: 0.9508\n",
      "Epoch 72/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7336 - loss: 0.7501 - val_accuracy: 0.6766 - val_loss: 0.9536\n",
      "Epoch 73/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7318 - loss: 0.7581 - val_accuracy: 0.6770 - val_loss: 0.9598\n",
      "Epoch 74/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.7516 - val_accuracy: 0.6799 - val_loss: 0.9588\n",
      "Epoch 75/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.7512 - val_accuracy: 0.6812 - val_loss: 0.9581\n",
      "Epoch 76/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7277 - loss: 0.7627 - val_accuracy: 0.6753 - val_loss: 0.9562\n",
      "Epoch 77/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7351 - loss: 0.7523 - val_accuracy: 0.6772 - val_loss: 0.9562\n",
      "Epoch 78/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7350 - loss: 0.7499 - val_accuracy: 0.6786 - val_loss: 0.9612\n",
      "Epoch 79/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.7489 - val_accuracy: 0.6788 - val_loss: 0.9539\n",
      "Epoch 80/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7342 - loss: 0.7540 - val_accuracy: 0.6780 - val_loss: 0.9557\n",
      "Epoch 81/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.7501 - val_accuracy: 0.6764 - val_loss: 0.9632\n",
      "Epoch 82/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.7463 - val_accuracy: 0.6794 - val_loss: 0.9619\n",
      "Epoch 83/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.7562 - val_accuracy: 0.6810 - val_loss: 0.9598\n",
      "Epoch 84/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.7390 - val_accuracy: 0.6758 - val_loss: 0.9536\n",
      "Epoch 85/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.7455 - val_accuracy: 0.6788 - val_loss: 0.9616\n",
      "Epoch 86/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7380 - loss: 0.7423 - val_accuracy: 0.6777 - val_loss: 0.9662\n",
      "Epoch 87/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.7439 - val_accuracy: 0.6815 - val_loss: 0.9651\n",
      "Epoch 88/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.7408 - val_accuracy: 0.6797 - val_loss: 0.9538\n",
      "Epoch 89/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7373 - loss: 0.7439 - val_accuracy: 0.6812 - val_loss: 0.9627\n",
      "Epoch 90/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7397 - loss: 0.7408 - val_accuracy: 0.6758 - val_loss: 0.9698\n",
      "Epoch 91/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7437 - loss: 0.7281 - val_accuracy: 0.6804 - val_loss: 0.9644\n",
      "Epoch 92/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.7423 - val_accuracy: 0.6785 - val_loss: 0.9657\n",
      "Epoch 93/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7400 - loss: 0.7380 - val_accuracy: 0.6784 - val_loss: 0.9652\n",
      "Epoch 94/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.7433 - val_accuracy: 0.6793 - val_loss: 0.9638\n",
      "Epoch 95/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.7421 - val_accuracy: 0.6784 - val_loss: 0.9650\n",
      "Epoch 96/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.7370 - val_accuracy: 0.6770 - val_loss: 0.9707\n",
      "Epoch 97/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.7423 - val_accuracy: 0.6814 - val_loss: 0.9578\n",
      "Epoch 98/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.7378 - val_accuracy: 0.6772 - val_loss: 0.9634\n",
      "Epoch 99/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.7305 - val_accuracy: 0.6803 - val_loss: 0.9718\n",
      "Epoch 100/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.7373 - val_accuracy: 0.6769 - val_loss: 0.9673\n",
      "Epoch 101/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.7389 - val_accuracy: 0.6796 - val_loss: 0.9665\n",
      "Epoch 102/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.7341 - val_accuracy: 0.6778 - val_loss: 0.9692\n",
      "Epoch 103/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.7302 - val_accuracy: 0.6793 - val_loss: 0.9621\n",
      "Epoch 104/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.7266 - val_accuracy: 0.6806 - val_loss: 0.9737\n",
      "Epoch 105/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.7326 - val_accuracy: 0.6788 - val_loss: 0.9665\n",
      "Epoch 106/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7443 - loss: 0.7223 - val_accuracy: 0.6800 - val_loss: 0.9659\n",
      "Epoch 107/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7412 - loss: 0.7308 - val_accuracy: 0.6772 - val_loss: 0.9793\n",
      "Epoch 108/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7437 - loss: 0.7199 - val_accuracy: 0.6831 - val_loss: 0.9657\n",
      "Epoch 109/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.7267 - val_accuracy: 0.6787 - val_loss: 0.9609\n",
      "Epoch 110/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7393 - loss: 0.7329 - val_accuracy: 0.6775 - val_loss: 0.9706\n",
      "Epoch 111/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.7305 - val_accuracy: 0.6757 - val_loss: 0.9719\n",
      "Epoch 112/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.7336 - val_accuracy: 0.6803 - val_loss: 0.9731\n",
      "Epoch 113/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.7300 - val_accuracy: 0.6799 - val_loss: 0.9690\n",
      "Epoch 114/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.7272 - val_accuracy: 0.6763 - val_loss: 0.9680\n",
      "Epoch 115/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7445 - loss: 0.7193 - val_accuracy: 0.6815 - val_loss: 0.9725\n",
      "Epoch 116/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7394 - loss: 0.7258 - val_accuracy: 0.6765 - val_loss: 0.9715\n",
      "Epoch 117/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.7214 - val_accuracy: 0.6750 - val_loss: 0.9760\n",
      "Epoch 118/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7470 - loss: 0.7209 - val_accuracy: 0.6782 - val_loss: 0.9693\n",
      "Epoch 119/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7445 - loss: 0.7262 - val_accuracy: 0.6749 - val_loss: 0.9720\n",
      "Epoch 120/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.7101 - val_accuracy: 0.6778 - val_loss: 0.9830\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.6801 - loss: 0.9925\n",
      "test_accuracy: 67.78%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=120,batch_size=120,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4238 - loss: 1.6737 - val_accuracy: 0.5955 - val_loss: 1.1750\n",
      "Epoch 2/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.5723 - loss: 1.2341 - val_accuracy: 0.6173 - val_loss: 1.1008\n",
      "Epoch 3/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.5969 - loss: 1.1623 - val_accuracy: 0.6307 - val_loss: 1.0713\n",
      "Epoch 4/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6192 - loss: 1.1147 - val_accuracy: 0.6360 - val_loss: 1.0440\n",
      "Epoch 5/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.6242 - loss: 1.0792 - val_accuracy: 0.6472 - val_loss: 1.0208\n",
      "Epoch 6/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.6333 - loss: 1.0629 - val_accuracy: 0.6472 - val_loss: 1.0125\n",
      "Epoch 7/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.6407 - loss: 1.0329 - val_accuracy: 0.6499 - val_loss: 0.9990\n",
      "Epoch 8/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.6464 - loss: 1.0149 - val_accuracy: 0.6550 - val_loss: 0.9914\n",
      "Epoch 9/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6491 - loss: 1.0035 - val_accuracy: 0.6542 - val_loss: 0.9878\n",
      "Epoch 10/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6527 - loss: 0.9943 - val_accuracy: 0.6595 - val_loss: 0.9760\n",
      "Epoch 11/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6568 - loss: 0.9842 - val_accuracy: 0.6649 - val_loss: 0.9670\n",
      "Epoch 12/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6594 - loss: 0.9660 - val_accuracy: 0.6616 - val_loss: 0.9694\n",
      "Epoch 13/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6607 - loss: 0.9687 - val_accuracy: 0.6631 - val_loss: 0.9631\n",
      "Epoch 14/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.6691 - loss: 0.9534 - val_accuracy: 0.6632 - val_loss: 0.9752\n",
      "Epoch 15/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6658 - loss: 0.9552 - val_accuracy: 0.6692 - val_loss: 0.9599\n",
      "Epoch 16/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.6705 - loss: 0.9334 - val_accuracy: 0.6678 - val_loss: 0.9531\n",
      "Epoch 17/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.6739 - loss: 0.9299 - val_accuracy: 0.6692 - val_loss: 0.9488\n",
      "Epoch 18/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6696 - loss: 0.9368 - val_accuracy: 0.6686 - val_loss: 0.9516\n",
      "Epoch 19/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 0.6758 - loss: 0.9275 - val_accuracy: 0.6729 - val_loss: 0.9553\n",
      "Epoch 20/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.6790 - loss: 0.9141 - val_accuracy: 0.6703 - val_loss: 0.9471\n",
      "Epoch 21/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6785 - loss: 0.9106 - val_accuracy: 0.6700 - val_loss: 0.9483\n",
      "Epoch 22/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.6854 - loss: 0.8975 - val_accuracy: 0.6713 - val_loss: 0.9402\n",
      "Epoch 23/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6872 - loss: 0.8941 - val_accuracy: 0.6705 - val_loss: 0.9466\n",
      "Epoch 24/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.6808 - loss: 0.9034 - val_accuracy: 0.6742 - val_loss: 0.9425\n",
      "Epoch 25/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.6841 - loss: 0.8995 - val_accuracy: 0.6728 - val_loss: 0.9409\n",
      "Epoch 26/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.6869 - loss: 0.8916 - val_accuracy: 0.6753 - val_loss: 0.9401\n",
      "Epoch 27/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6882 - loss: 0.8913 - val_accuracy: 0.6725 - val_loss: 0.9403\n",
      "Epoch 28/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6884 - loss: 0.8932 - val_accuracy: 0.6758 - val_loss: 0.9336\n",
      "Epoch 29/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.6925 - loss: 0.8755 - val_accuracy: 0.6721 - val_loss: 0.9360\n",
      "Epoch 30/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6929 - loss: 0.8705 - val_accuracy: 0.6776 - val_loss: 0.9357\n",
      "Epoch 31/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.6956 - loss: 0.8695 - val_accuracy: 0.6720 - val_loss: 0.9330\n",
      "Epoch 32/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.6910 - loss: 0.8746 - val_accuracy: 0.6718 - val_loss: 0.9370\n",
      "Epoch 33/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6957 - loss: 0.8683 - val_accuracy: 0.6713 - val_loss: 0.9420\n",
      "Epoch 34/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6919 - loss: 0.8731 - val_accuracy: 0.6786 - val_loss: 0.9345\n",
      "Epoch 35/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6972 - loss: 0.8664 - val_accuracy: 0.6764 - val_loss: 0.9356\n",
      "Epoch 36/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6980 - loss: 0.8579 - val_accuracy: 0.6716 - val_loss: 0.9395\n",
      "Epoch 37/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.6933 - loss: 0.8659 - val_accuracy: 0.6737 - val_loss: 0.9385\n",
      "Epoch 38/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.6982 - loss: 0.8565 - val_accuracy: 0.6735 - val_loss: 0.9383\n",
      "Epoch 39/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.6992 - loss: 0.8592 - val_accuracy: 0.6731 - val_loss: 0.9368\n",
      "Epoch 40/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.6969 - loss: 0.8604 - val_accuracy: 0.6760 - val_loss: 0.9388\n",
      "Epoch 41/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6983 - loss: 0.8550 - val_accuracy: 0.6732 - val_loss: 0.9373\n",
      "Epoch 42/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7019 - loss: 0.8433 - val_accuracy: 0.6782 - val_loss: 0.9327\n",
      "Epoch 43/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7000 - loss: 0.8483 - val_accuracy: 0.6762 - val_loss: 0.9332\n",
      "Epoch 44/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7028 - loss: 0.8464 - val_accuracy: 0.6773 - val_loss: 0.9333\n",
      "Epoch 45/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7016 - loss: 0.8433 - val_accuracy: 0.6780 - val_loss: 0.9324\n",
      "Epoch 46/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7017 - loss: 0.8463 - val_accuracy: 0.6782 - val_loss: 0.9339\n",
      "Epoch 47/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7071 - loss: 0.8395 - val_accuracy: 0.6745 - val_loss: 0.9375\n",
      "Epoch 48/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7059 - loss: 0.8400 - val_accuracy: 0.6747 - val_loss: 0.9382\n",
      "Epoch 49/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7065 - loss: 0.8365 - val_accuracy: 0.6772 - val_loss: 0.9404\n",
      "Epoch 50/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7033 - loss: 0.8427 - val_accuracy: 0.6789 - val_loss: 0.9348\n",
      "Epoch 51/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7027 - loss: 0.8346 - val_accuracy: 0.6751 - val_loss: 0.9371\n",
      "Epoch 52/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7060 - loss: 0.8382 - val_accuracy: 0.6759 - val_loss: 0.9388\n",
      "Epoch 53/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7031 - loss: 0.8396 - val_accuracy: 0.6754 - val_loss: 0.9370\n",
      "Epoch 54/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7094 - loss: 0.8281 - val_accuracy: 0.6752 - val_loss: 0.9354\n",
      "Epoch 55/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7057 - loss: 0.8299 - val_accuracy: 0.6745 - val_loss: 0.9369\n",
      "Epoch 56/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7055 - loss: 0.8306 - val_accuracy: 0.6769 - val_loss: 0.9347\n",
      "Epoch 57/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7077 - loss: 0.8299 - val_accuracy: 0.6759 - val_loss: 0.9392\n",
      "Epoch 58/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7088 - loss: 0.8294 - val_accuracy: 0.6772 - val_loss: 0.9326\n",
      "Epoch 59/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7077 - loss: 0.8317 - val_accuracy: 0.6774 - val_loss: 0.9366\n",
      "Epoch 60/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7147 - loss: 0.8125 - val_accuracy: 0.6757 - val_loss: 0.9389\n",
      "Epoch 61/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7108 - loss: 0.8239 - val_accuracy: 0.6762 - val_loss: 0.9405\n",
      "Epoch 62/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7101 - loss: 0.8236 - val_accuracy: 0.6794 - val_loss: 0.9401\n",
      "Epoch 63/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7046 - loss: 0.8342 - val_accuracy: 0.6767 - val_loss: 0.9399\n",
      "Epoch 64/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7092 - loss: 0.8253 - val_accuracy: 0.6788 - val_loss: 0.9349\n",
      "Epoch 65/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7113 - loss: 0.8171 - val_accuracy: 0.6756 - val_loss: 0.9419\n",
      "Epoch 66/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7138 - loss: 0.8149 - val_accuracy: 0.6779 - val_loss: 0.9406\n",
      "Epoch 67/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.7130 - loss: 0.8191 - val_accuracy: 0.6766 - val_loss: 0.9408\n",
      "Epoch 68/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 0.7141 - loss: 0.8192 - val_accuracy: 0.6781 - val_loss: 0.9438\n",
      "Epoch 69/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7130 - loss: 0.8203 - val_accuracy: 0.6774 - val_loss: 0.9439\n",
      "Epoch 70/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7124 - loss: 0.8204 - val_accuracy: 0.6796 - val_loss: 0.9386\n",
      "Epoch 71/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7161 - loss: 0.8104 - val_accuracy: 0.6805 - val_loss: 0.9342\n",
      "Epoch 72/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7141 - loss: 0.8100 - val_accuracy: 0.6792 - val_loss: 0.9346\n",
      "Epoch 73/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7094 - loss: 0.8135 - val_accuracy: 0.6774 - val_loss: 0.9390\n",
      "Epoch 74/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7164 - loss: 0.8136 - val_accuracy: 0.6805 - val_loss: 0.9302\n",
      "Epoch 75/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7188 - loss: 0.8029 - val_accuracy: 0.6795 - val_loss: 0.9328\n",
      "Epoch 76/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7162 - loss: 0.8088 - val_accuracy: 0.6783 - val_loss: 0.9425\n",
      "Epoch 77/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7137 - loss: 0.8119 - val_accuracy: 0.6784 - val_loss: 0.9442\n",
      "Epoch 78/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7149 - loss: 0.8047 - val_accuracy: 0.6764 - val_loss: 0.9410\n",
      "Epoch 79/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7146 - loss: 0.8127 - val_accuracy: 0.6774 - val_loss: 0.9412\n",
      "Epoch 80/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.7188 - loss: 0.8045 - val_accuracy: 0.6800 - val_loss: 0.9317\n",
      "Epoch 81/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7123 - loss: 0.8145 - val_accuracy: 0.6799 - val_loss: 0.9391\n",
      "Epoch 82/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7127 - loss: 0.8143 - val_accuracy: 0.6772 - val_loss: 0.9417\n",
      "Epoch 83/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7175 - loss: 0.8046 - val_accuracy: 0.6771 - val_loss: 0.9378\n",
      "Epoch 84/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7166 - loss: 0.8029 - val_accuracy: 0.6792 - val_loss: 0.9401\n",
      "Epoch 85/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7200 - loss: 0.7955 - val_accuracy: 0.6791 - val_loss: 0.9379\n",
      "Epoch 86/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7181 - loss: 0.8009 - val_accuracy: 0.6800 - val_loss: 0.9382\n",
      "Epoch 87/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.7157 - loss: 0.8046 - val_accuracy: 0.6799 - val_loss: 0.9370\n",
      "Epoch 88/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7191 - loss: 0.8048 - val_accuracy: 0.6785 - val_loss: 0.9376\n",
      "Epoch 89/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7167 - loss: 0.7964 - val_accuracy: 0.6769 - val_loss: 0.9372\n",
      "Epoch 90/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7142 - loss: 0.8094 - val_accuracy: 0.6787 - val_loss: 0.9376\n",
      "Epoch 91/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7195 - loss: 0.7991 - val_accuracy: 0.6781 - val_loss: 0.9415\n",
      "Epoch 92/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7207 - loss: 0.7947 - val_accuracy: 0.6777 - val_loss: 0.9386\n",
      "Epoch 93/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7169 - loss: 0.8030 - val_accuracy: 0.6776 - val_loss: 0.9394\n",
      "Epoch 94/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7192 - loss: 0.7981 - val_accuracy: 0.6786 - val_loss: 0.9447\n",
      "Epoch 95/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7207 - loss: 0.7950 - val_accuracy: 0.6762 - val_loss: 0.9481\n",
      "Epoch 96/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7161 - loss: 0.8015 - val_accuracy: 0.6788 - val_loss: 0.9463\n",
      "Epoch 97/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7210 - loss: 0.7887 - val_accuracy: 0.6783 - val_loss: 0.9415\n",
      "Epoch 98/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7186 - loss: 0.7969 - val_accuracy: 0.6769 - val_loss: 0.9392\n",
      "Epoch 99/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7193 - loss: 0.8041 - val_accuracy: 0.6807 - val_loss: 0.9359\n",
      "Epoch 100/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7179 - loss: 0.7995 - val_accuracy: 0.6793 - val_loss: 0.9427\n",
      "Epoch 101/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7230 - loss: 0.7925 - val_accuracy: 0.6784 - val_loss: 0.9416\n",
      "Epoch 102/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7192 - loss: 0.8000 - val_accuracy: 0.6818 - val_loss: 0.9431\n",
      "Epoch 103/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7212 - loss: 0.7929 - val_accuracy: 0.6816 - val_loss: 0.9387\n",
      "Epoch 104/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7251 - loss: 0.7816 - val_accuracy: 0.6766 - val_loss: 0.9436\n",
      "Epoch 105/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7179 - loss: 0.8001 - val_accuracy: 0.6810 - val_loss: 0.9361\n",
      "Epoch 106/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7218 - loss: 0.7900 - val_accuracy: 0.6763 - val_loss: 0.9408\n",
      "Epoch 107/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7201 - loss: 0.7947 - val_accuracy: 0.6763 - val_loss: 0.9446\n",
      "Epoch 108/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.7240 - loss: 0.7937 - val_accuracy: 0.6792 - val_loss: 0.9433\n",
      "Epoch 109/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7229 - loss: 0.7849 - val_accuracy: 0.6792 - val_loss: 0.9412\n",
      "Epoch 110/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7204 - loss: 0.7857 - val_accuracy: 0.6781 - val_loss: 0.9454\n",
      "Epoch 111/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7242 - loss: 0.7898 - val_accuracy: 0.6791 - val_loss: 0.9493\n",
      "Epoch 112/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7272 - loss: 0.7784 - val_accuracy: 0.6742 - val_loss: 0.9467\n",
      "Epoch 113/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7192 - loss: 0.7889 - val_accuracy: 0.6768 - val_loss: 0.9434\n",
      "Epoch 114/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7182 - loss: 0.7909 - val_accuracy: 0.6773 - val_loss: 0.9469\n",
      "Epoch 115/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7255 - loss: 0.7785 - val_accuracy: 0.6781 - val_loss: 0.9452\n",
      "Epoch 116/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7170 - loss: 0.7939 - val_accuracy: 0.6786 - val_loss: 0.9442\n",
      "Epoch 117/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7242 - loss: 0.7861 - val_accuracy: 0.6792 - val_loss: 0.9433\n",
      "Epoch 118/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7209 - loss: 0.7900 - val_accuracy: 0.6760 - val_loss: 0.9491\n",
      "Epoch 119/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7260 - loss: 0.7787 - val_accuracy: 0.6736 - val_loss: 0.9536\n",
      "Epoch 120/120\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7240 - loss: 0.7847 - val_accuracy: 0.6748 - val_loss: 0.9451\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.6731 - loss: 0.9465\n",
      "test_accuracy: 67.48%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=120,batch_size=120,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4879 - loss: 1.5022 - val_accuracy: 0.6202 - val_loss: 1.1020\n",
      "Epoch 2/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 1.1148 - val_accuracy: 0.6494 - val_loss: 1.0241\n",
      "Epoch 3/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6421 - loss: 1.0338 - val_accuracy: 0.6561 - val_loss: 1.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6608 - loss: 0.9795 - val_accuracy: 0.6619 - val_loss: 0.9735\n",
      "Epoch 5/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.9256 - val_accuracy: 0.6663 - val_loss: 0.9585\n",
      "Epoch 6/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.9091 - val_accuracy: 0.6683 - val_loss: 0.9529\n",
      "Epoch 7/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.8785 - val_accuracy: 0.6765 - val_loss: 0.9315\n",
      "Epoch 8/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 0.8505 - val_accuracy: 0.6780 - val_loss: 0.9246\n",
      "Epoch 9/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.8314 - val_accuracy: 0.6809 - val_loss: 0.9231\n",
      "Epoch 10/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.8000 - val_accuracy: 0.6771 - val_loss: 0.9343\n",
      "Epoch 11/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.7890 - val_accuracy: 0.6820 - val_loss: 0.9222\n",
      "Epoch 12/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.7661 - val_accuracy: 0.6795 - val_loss: 0.9292\n",
      "Epoch 13/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.7472 - val_accuracy: 0.6824 - val_loss: 0.9326\n",
      "Epoch 14/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.7350 - val_accuracy: 0.6842 - val_loss: 0.9399\n",
      "Epoch 15/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.7093 - val_accuracy: 0.6879 - val_loss: 0.9257\n",
      "Epoch 16/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7551 - loss: 0.6958 - val_accuracy: 0.6898 - val_loss: 0.9330\n",
      "Epoch 17/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.6730 - val_accuracy: 0.6887 - val_loss: 0.9363\n",
      "Epoch 18/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.6691 - val_accuracy: 0.6850 - val_loss: 0.9449\n",
      "Epoch 19/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.6572 - val_accuracy: 0.6926 - val_loss: 0.9452\n",
      "Epoch 20/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.6349 - val_accuracy: 0.6898 - val_loss: 0.9496\n",
      "Epoch 21/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7754 - loss: 0.6319 - val_accuracy: 0.6897 - val_loss: 0.9603\n",
      "Epoch 22/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.6161 - val_accuracy: 0.6867 - val_loss: 0.9748\n",
      "Epoch 23/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.6090 - val_accuracy: 0.6845 - val_loss: 0.9993\n",
      "Epoch 24/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.6066 - val_accuracy: 0.6862 - val_loss: 0.9925\n",
      "Epoch 25/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.5901 - val_accuracy: 0.6879 - val_loss: 0.9808\n",
      "Epoch 26/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.5751 - val_accuracy: 0.6857 - val_loss: 1.0022\n",
      "Epoch 27/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7950 - loss: 0.5779 - val_accuracy: 0.6865 - val_loss: 1.0172\n",
      "Epoch 28/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.5630 - val_accuracy: 0.6855 - val_loss: 0.9939\n",
      "Epoch 29/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.5484 - val_accuracy: 0.6865 - val_loss: 1.0188\n",
      "Epoch 30/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.5412 - val_accuracy: 0.6844 - val_loss: 1.0262\n",
      "Epoch 31/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.5436 - val_accuracy: 0.6904 - val_loss: 1.0455\n",
      "Epoch 32/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5353 - val_accuracy: 0.6845 - val_loss: 1.0487\n",
      "Epoch 33/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.5338 - val_accuracy: 0.6820 - val_loss: 1.0454\n",
      "Epoch 34/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.5222 - val_accuracy: 0.6864 - val_loss: 1.0513\n",
      "Epoch 35/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.5102 - val_accuracy: 0.6854 - val_loss: 1.0455\n",
      "Epoch 36/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.5041 - val_accuracy: 0.6872 - val_loss: 1.0594\n",
      "Epoch 37/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.5114 - val_accuracy: 0.6889 - val_loss: 1.0583\n",
      "Epoch 38/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.5042 - val_accuracy: 0.6868 - val_loss: 1.0766\n",
      "Epoch 39/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8284 - loss: 0.4939 - val_accuracy: 0.6844 - val_loss: 1.1033\n",
      "Epoch 40/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4835 - val_accuracy: 0.6874 - val_loss: 1.0733\n",
      "Epoch 41/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.4908 - val_accuracy: 0.6876 - val_loss: 1.0940\n",
      "Epoch 42/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4827 - val_accuracy: 0.6851 - val_loss: 1.1085\n",
      "Epoch 43/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4733 - val_accuracy: 0.6839 - val_loss: 1.1111\n",
      "Epoch 44/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4701 - val_accuracy: 0.6900 - val_loss: 1.1068\n",
      "Epoch 45/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.4662 - val_accuracy: 0.6858 - val_loss: 1.1289\n",
      "Epoch 46/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.4613 - val_accuracy: 0.6826 - val_loss: 1.1293\n",
      "Epoch 47/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.4607 - val_accuracy: 0.6857 - val_loss: 1.1536\n",
      "Epoch 48/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.4521 - val_accuracy: 0.6833 - val_loss: 1.1505\n",
      "Epoch 49/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.4484 - val_accuracy: 0.6853 - val_loss: 1.1582\n",
      "Epoch 50/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.4554 - val_accuracy: 0.6826 - val_loss: 1.1696\n",
      "Epoch 51/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.4507 - val_accuracy: 0.6869 - val_loss: 1.1743\n",
      "Epoch 52/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4471 - val_accuracy: 0.6832 - val_loss: 1.1696\n",
      "Epoch 53/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4440 - val_accuracy: 0.6837 - val_loss: 1.1648\n",
      "Epoch 54/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4390 - val_accuracy: 0.6879 - val_loss: 1.1516\n",
      "Epoch 55/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.4256 - val_accuracy: 0.6870 - val_loss: 1.1689\n",
      "Epoch 56/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.4330 - val_accuracy: 0.6846 - val_loss: 1.1796\n",
      "Epoch 57/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.4342 - val_accuracy: 0.6839 - val_loss: 1.1954\n",
      "Epoch 58/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.4310 - val_accuracy: 0.6830 - val_loss: 1.1925\n",
      "Epoch 59/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.4250 - val_accuracy: 0.6833 - val_loss: 1.1861\n",
      "Epoch 60/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.4221 - val_accuracy: 0.6831 - val_loss: 1.1813\n",
      "Epoch 61/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8557 - loss: 0.4212 - val_accuracy: 0.6833 - val_loss: 1.1840\n",
      "Epoch 62/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.4173 - val_accuracy: 0.6838 - val_loss: 1.2204\n",
      "Epoch 63/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.4185 - val_accuracy: 0.6840 - val_loss: 1.2058\n",
      "Epoch 64/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.4098 - val_accuracy: 0.6854 - val_loss: 1.2037\n",
      "Epoch 65/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.4046 - val_accuracy: 0.6842 - val_loss: 1.2026\n",
      "Epoch 66/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.4160 - val_accuracy: 0.6885 - val_loss: 1.2259\n",
      "Epoch 67/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.4060 - val_accuracy: 0.6829 - val_loss: 1.2566\n",
      "Epoch 68/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.4036 - val_accuracy: 0.6854 - val_loss: 1.2123\n",
      "Epoch 69/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.4027 - val_accuracy: 0.6843 - val_loss: 1.2166\n",
      "Epoch 70/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.4021 - val_accuracy: 0.6855 - val_loss: 1.2363\n",
      "Epoch 71/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.4030 - val_accuracy: 0.6853 - val_loss: 1.2432\n",
      "Epoch 72/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3939 - val_accuracy: 0.6881 - val_loss: 1.2267\n",
      "Epoch 73/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3983 - val_accuracy: 0.6791 - val_loss: 1.2504\n",
      "Epoch 74/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3951 - val_accuracy: 0.6868 - val_loss: 1.2456\n",
      "Epoch 75/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3971 - val_accuracy: 0.6851 - val_loss: 1.2463\n",
      "Epoch 76/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.3947 - val_accuracy: 0.6847 - val_loss: 1.2469\n",
      "Epoch 77/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3927 - val_accuracy: 0.6856 - val_loss: 1.2472\n",
      "Epoch 78/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3916 - val_accuracy: 0.6834 - val_loss: 1.2656\n",
      "Epoch 79/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3883 - val_accuracy: 0.6830 - val_loss: 1.2700\n",
      "Epoch 80/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3846 - val_accuracy: 0.6816 - val_loss: 1.2938\n",
      "Epoch 81/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.3914 - val_accuracy: 0.6868 - val_loss: 1.2690\n",
      "Epoch 82/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3896 - val_accuracy: 0.6863 - val_loss: 1.2691\n",
      "Epoch 83/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3838 - val_accuracy: 0.6830 - val_loss: 1.2807\n",
      "Epoch 84/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3867 - val_accuracy: 0.6879 - val_loss: 1.2649\n",
      "Epoch 85/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3780 - val_accuracy: 0.6839 - val_loss: 1.2669\n",
      "Epoch 86/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8720 - loss: 0.3791 - val_accuracy: 0.6772 - val_loss: 1.2831\n",
      "Epoch 87/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3816 - val_accuracy: 0.6807 - val_loss: 1.2948\n",
      "Epoch 88/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.3799 - val_accuracy: 0.6848 - val_loss: 1.3146\n",
      "Epoch 89/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.3706 - val_accuracy: 0.6792 - val_loss: 1.2916\n",
      "Epoch 90/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 0.3638 - val_accuracy: 0.6856 - val_loss: 1.2868\n",
      "Epoch 91/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.3717 - val_accuracy: 0.6837 - val_loss: 1.2833\n",
      "Epoch 92/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.3741 - val_accuracy: 0.6848 - val_loss: 1.2808\n",
      "Epoch 93/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.3638 - val_accuracy: 0.6826 - val_loss: 1.2771\n",
      "Epoch 94/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.3670 - val_accuracy: 0.6820 - val_loss: 1.3234\n",
      "Epoch 95/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.3611 - val_accuracy: 0.6846 - val_loss: 1.3108\n",
      "Epoch 96/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.3625 - val_accuracy: 0.6818 - val_loss: 1.3035\n",
      "Epoch 97/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3682 - val_accuracy: 0.6860 - val_loss: 1.3017\n",
      "Epoch 98/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3619 - val_accuracy: 0.6812 - val_loss: 1.2828\n",
      "Epoch 99/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3628 - val_accuracy: 0.6848 - val_loss: 1.3082\n",
      "Epoch 100/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.3585 - val_accuracy: 0.6852 - val_loss: 1.3056\n",
      "Epoch 101/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3560 - val_accuracy: 0.6839 - val_loss: 1.3133\n",
      "Epoch 102/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.3514 - val_accuracy: 0.6814 - val_loss: 1.3355\n",
      "Epoch 103/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3528 - val_accuracy: 0.6829 - val_loss: 1.3216\n",
      "Epoch 104/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3600 - val_accuracy: 0.6846 - val_loss: 1.3145\n",
      "Epoch 105/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3576 - val_accuracy: 0.6806 - val_loss: 1.3179\n",
      "Epoch 106/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3546 - val_accuracy: 0.6825 - val_loss: 1.3205\n",
      "Epoch 107/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3538 - val_accuracy: 0.6852 - val_loss: 1.3274\n",
      "Epoch 108/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.3531 - val_accuracy: 0.6850 - val_loss: 1.3208\n",
      "Epoch 109/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3512 - val_accuracy: 0.6830 - val_loss: 1.3210\n",
      "Epoch 110/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.3500 - val_accuracy: 0.6867 - val_loss: 1.3367\n",
      "Epoch 111/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.3471 - val_accuracy: 0.6831 - val_loss: 1.3260\n",
      "Epoch 112/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.3481 - val_accuracy: 0.6842 - val_loss: 1.3375\n",
      "Epoch 113/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3422 - val_accuracy: 0.6786 - val_loss: 1.3607\n",
      "Epoch 114/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8829 - loss: 0.3522 - val_accuracy: 0.6835 - val_loss: 1.3233\n",
      "Epoch 115/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.3487 - val_accuracy: 0.6830 - val_loss: 1.3447\n",
      "Epoch 116/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3473 - val_accuracy: 0.6824 - val_loss: 1.3316\n",
      "Epoch 117/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.3506 - val_accuracy: 0.6847 - val_loss: 1.3393\n",
      "Epoch 118/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.3415 - val_accuracy: 0.6854 - val_loss: 1.3299\n",
      "Epoch 119/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3357 - val_accuracy: 0.6827 - val_loss: 1.3609\n",
      "Epoch 120/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.3327 - val_accuracy: 0.6824 - val_loss: 1.3664\n",
      "Epoch 121/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3416 - val_accuracy: 0.6808 - val_loss: 1.3440\n",
      "Epoch 122/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.3392 - val_accuracy: 0.6802 - val_loss: 1.3736\n",
      "Epoch 123/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3485 - val_accuracy: 0.6786 - val_loss: 1.3515\n",
      "Epoch 124/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.3390 - val_accuracy: 0.6827 - val_loss: 1.3556\n",
      "Epoch 125/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3343 - val_accuracy: 0.6851 - val_loss: 1.3703\n",
      "Epoch 126/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.3367 - val_accuracy: 0.6825 - val_loss: 1.3553\n",
      "Epoch 127/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.3366 - val_accuracy: 0.6844 - val_loss: 1.3440\n",
      "Epoch 128/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.3417 - val_accuracy: 0.6820 - val_loss: 1.3521\n",
      "Epoch 129/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3296 - val_accuracy: 0.6825 - val_loss: 1.3621\n",
      "Epoch 130/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.3298 - val_accuracy: 0.6815 - val_loss: 1.3818\n",
      "Epoch 131/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.3356 - val_accuracy: 0.6837 - val_loss: 1.3435\n",
      "Epoch 132/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.3350 - val_accuracy: 0.6801 - val_loss: 1.3875\n",
      "Epoch 133/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.3293 - val_accuracy: 0.6793 - val_loss: 1.3826\n",
      "Epoch 134/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.3373 - val_accuracy: 0.6823 - val_loss: 1.3560\n",
      "Epoch 135/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.3284 - val_accuracy: 0.6812 - val_loss: 1.4105\n",
      "Epoch 136/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3285 - val_accuracy: 0.6797 - val_loss: 1.3991\n",
      "Epoch 137/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.3321 - val_accuracy: 0.6786 - val_loss: 1.4112\n",
      "Epoch 138/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3356 - val_accuracy: 0.6829 - val_loss: 1.3735\n",
      "Epoch 139/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3316 - val_accuracy: 0.6805 - val_loss: 1.4142\n",
      "Epoch 140/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3273 - val_accuracy: 0.6837 - val_loss: 1.4365\n",
      "Epoch 141/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3276 - val_accuracy: 0.6796 - val_loss: 1.3955\n",
      "Epoch 142/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3249 - val_accuracy: 0.6851 - val_loss: 1.3570\n",
      "Epoch 143/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.3275 - val_accuracy: 0.6807 - val_loss: 1.3967\n",
      "Epoch 144/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3245 - val_accuracy: 0.6804 - val_loss: 1.4332\n",
      "Epoch 145/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3293 - val_accuracy: 0.6824 - val_loss: 1.4210\n",
      "Epoch 146/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.3208 - val_accuracy: 0.6806 - val_loss: 1.4092\n",
      "Epoch 147/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.3140 - val_accuracy: 0.6813 - val_loss: 1.4099\n",
      "Epoch 148/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3177 - val_accuracy: 0.6808 - val_loss: 1.4288\n",
      "Epoch 149/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.3227 - val_accuracy: 0.6807 - val_loss: 1.4097\n",
      "Epoch 150/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.3201 - val_accuracy: 0.6816 - val_loss: 1.3776\n",
      "Epoch 151/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3174 - val_accuracy: 0.6839 - val_loss: 1.4111\n",
      "Epoch 152/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.3234 - val_accuracy: 0.6807 - val_loss: 1.4047\n",
      "Epoch 153/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.3166 - val_accuracy: 0.6839 - val_loss: 1.3889\n",
      "Epoch 154/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.3236 - val_accuracy: 0.6792 - val_loss: 1.4100\n",
      "Epoch 155/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.3166 - val_accuracy: 0.6802 - val_loss: 1.4156\n",
      "Epoch 156/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.3168 - val_accuracy: 0.6834 - val_loss: 1.3927\n",
      "Epoch 157/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.3186 - val_accuracy: 0.6793 - val_loss: 1.4017\n",
      "Epoch 158/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3175 - val_accuracy: 0.6807 - val_loss: 1.3916\n",
      "Epoch 159/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3159 - val_accuracy: 0.6840 - val_loss: 1.4041\n",
      "Epoch 160/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.3101 - val_accuracy: 0.6809 - val_loss: 1.4087\n",
      "Epoch 161/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.3137 - val_accuracy: 0.6808 - val_loss: 1.4096\n",
      "Epoch 162/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3133 - val_accuracy: 0.6800 - val_loss: 1.4027\n",
      "Epoch 163/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.3165 - val_accuracy: 0.6803 - val_loss: 1.4233\n",
      "Epoch 164/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3159 - val_accuracy: 0.6835 - val_loss: 1.4054\n",
      "Epoch 165/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.3237 - val_accuracy: 0.6823 - val_loss: 1.4222\n",
      "Epoch 166/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.3128 - val_accuracy: 0.6773 - val_loss: 1.4160\n",
      "Epoch 167/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3079 - val_accuracy: 0.6809 - val_loss: 1.4316\n",
      "Epoch 168/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.3184 - val_accuracy: 0.6840 - val_loss: 1.3989\n",
      "Epoch 169/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.3118 - val_accuracy: 0.6796 - val_loss: 1.4611\n",
      "Epoch 170/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.3076 - val_accuracy: 0.6804 - val_loss: 1.4194\n",
      "Epoch 171/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.3081 - val_accuracy: 0.6861 - val_loss: 1.4437\n",
      "Epoch 172/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.3127 - val_accuracy: 0.6782 - val_loss: 1.4639\n",
      "Epoch 173/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.3113 - val_accuracy: 0.6860 - val_loss: 1.4762\n",
      "Epoch 174/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.3158 - val_accuracy: 0.6843 - val_loss: 1.4363\n",
      "Epoch 175/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.3131 - val_accuracy: 0.6847 - val_loss: 1.4469\n",
      "Epoch 176/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.3126 - val_accuracy: 0.6799 - val_loss: 1.3896\n",
      "Epoch 177/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.3094 - val_accuracy: 0.6826 - val_loss: 1.4344\n",
      "Epoch 178/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.3061 - val_accuracy: 0.6837 - val_loss: 1.4209\n",
      "Epoch 179/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3140 - val_accuracy: 0.6841 - val_loss: 1.4103\n",
      "Epoch 180/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.3071 - val_accuracy: 0.6816 - val_loss: 1.4129\n",
      "Epoch 181/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3035 - val_accuracy: 0.6810 - val_loss: 1.4344\n",
      "Epoch 182/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3045 - val_accuracy: 0.6768 - val_loss: 1.4451\n",
      "Epoch 183/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.3049 - val_accuracy: 0.6817 - val_loss: 1.4154\n",
      "Epoch 184/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3048 - val_accuracy: 0.6804 - val_loss: 1.4291\n",
      "Epoch 185/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8971 - loss: 0.3129 - val_accuracy: 0.6833 - val_loss: 1.4205\n",
      "Epoch 186/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.3039 - val_accuracy: 0.6815 - val_loss: 1.4242\n",
      "Epoch 187/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.3075 - val_accuracy: 0.6794 - val_loss: 1.4171\n",
      "Epoch 188/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.3043 - val_accuracy: 0.6781 - val_loss: 1.4928\n",
      "Epoch 189/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.3088 - val_accuracy: 0.6782 - val_loss: 1.4319\n",
      "Epoch 190/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2973 - val_accuracy: 0.6820 - val_loss: 1.4213\n",
      "Epoch 191/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.3086 - val_accuracy: 0.6798 - val_loss: 1.4405\n",
      "Epoch 192/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2951 - val_accuracy: 0.6801 - val_loss: 1.4671\n",
      "Epoch 193/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.3036 - val_accuracy: 0.6796 - val_loss: 1.4480\n",
      "Epoch 194/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.3080 - val_accuracy: 0.6836 - val_loss: 1.4681\n",
      "Epoch 195/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.3040 - val_accuracy: 0.6823 - val_loss: 1.4419\n",
      "Epoch 196/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.2985 - val_accuracy: 0.6832 - val_loss: 1.4582\n",
      "Epoch 197/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3038 - val_accuracy: 0.6834 - val_loss: 1.4107\n",
      "Epoch 198/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2981 - val_accuracy: 0.6804 - val_loss: 1.4483\n",
      "Epoch 199/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2984 - val_accuracy: 0.6813 - val_loss: 1.4714\n",
      "Epoch 200/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2945 - val_accuracy: 0.6815 - val_loss: 1.4496\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.6806 - loss: 1.4551\n",
      "test_accuracy: 68.15%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=200,batch_size=200,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4922 - loss: 1.5030 - val_accuracy: 0.6235 - val_loss: 1.0958\n",
      "Epoch 2/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 1.1095 - val_accuracy: 0.6446 - val_loss: 1.0298\n",
      "Epoch 3/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6471 - loss: 1.0193 - val_accuracy: 0.6576 - val_loss: 0.9851\n",
      "Epoch 4/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.9723 - val_accuracy: 0.6603 - val_loss: 0.9677\n",
      "Epoch 5/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.9355 - val_accuracy: 0.6709 - val_loss: 0.9469\n",
      "Epoch 6/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6865 - loss: 0.8995 - val_accuracy: 0.6721 - val_loss: 0.9415\n",
      "Epoch 7/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6960 - loss: 0.8629 - val_accuracy: 0.6770 - val_loss: 0.9312\n",
      "Epoch 8/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - loss: 0.8441 - val_accuracy: 0.6788 - val_loss: 0.9276\n",
      "Epoch 9/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.8200 - val_accuracy: 0.6831 - val_loss: 0.9156\n",
      "Epoch 10/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.7846 - val_accuracy: 0.6813 - val_loss: 0.9214\n",
      "Epoch 11/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.7749 - val_accuracy: 0.6832 - val_loss: 0.9212\n",
      "Epoch 12/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.7560 - val_accuracy: 0.6874 - val_loss: 0.9333\n",
      "Epoch 13/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.7336 - val_accuracy: 0.6903 - val_loss: 0.9229\n",
      "Epoch 14/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.7173 - val_accuracy: 0.6841 - val_loss: 0.9237\n",
      "Epoch 15/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.7026 - val_accuracy: 0.6869 - val_loss: 0.9278\n",
      "Epoch 16/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7590 - loss: 0.6801 - val_accuracy: 0.6904 - val_loss: 0.9308\n",
      "Epoch 17/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.6611 - val_accuracy: 0.6868 - val_loss: 0.9387\n",
      "Epoch 18/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.6566 - val_accuracy: 0.6861 - val_loss: 0.9417\n",
      "Epoch 19/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.6383 - val_accuracy: 0.6879 - val_loss: 0.9540\n",
      "Epoch 20/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.6275 - val_accuracy: 0.6869 - val_loss: 0.9504\n",
      "Epoch 21/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.6130 - val_accuracy: 0.6887 - val_loss: 0.9645\n",
      "Epoch 22/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6096 - val_accuracy: 0.6874 - val_loss: 0.9543\n",
      "Epoch 23/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5864 - val_accuracy: 0.6891 - val_loss: 0.9860\n",
      "Epoch 24/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7923 - loss: 0.5863 - val_accuracy: 0.6855 - val_loss: 0.9869\n",
      "Epoch 25/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.5597 - val_accuracy: 0.6899 - val_loss: 0.9819\n",
      "Epoch 26/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.5595 - val_accuracy: 0.6860 - val_loss: 0.9884\n",
      "Epoch 27/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.5558 - val_accuracy: 0.6899 - val_loss: 1.0085\n",
      "Epoch 28/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5375 - val_accuracy: 0.6875 - val_loss: 0.9996\n",
      "Epoch 29/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.5367 - val_accuracy: 0.6894 - val_loss: 1.0118\n",
      "Epoch 30/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.5254 - val_accuracy: 0.6887 - val_loss: 1.0342\n",
      "Epoch 31/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8174 - loss: 0.5245 - val_accuracy: 0.6886 - val_loss: 1.0227\n",
      "Epoch 32/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.5089 - val_accuracy: 0.6883 - val_loss: 1.0550\n",
      "Epoch 33/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.5062 - val_accuracy: 0.6852 - val_loss: 1.0421\n",
      "Epoch 34/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.5033 - val_accuracy: 0.6828 - val_loss: 1.0473\n",
      "Epoch 35/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4958 - val_accuracy: 0.6909 - val_loss: 1.0616\n",
      "Epoch 36/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4934 - val_accuracy: 0.6878 - val_loss: 1.0860\n",
      "Epoch 37/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4861 - val_accuracy: 0.6897 - val_loss: 1.0909\n",
      "Epoch 38/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.4794 - val_accuracy: 0.6878 - val_loss: 1.0919\n",
      "Epoch 39/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4685 - val_accuracy: 0.6904 - val_loss: 1.0979\n",
      "Epoch 40/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.4762 - val_accuracy: 0.6853 - val_loss: 1.0790\n",
      "Epoch 41/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.4672 - val_accuracy: 0.6837 - val_loss: 1.1235\n",
      "Epoch 42/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.4654 - val_accuracy: 0.6899 - val_loss: 1.1217\n",
      "Epoch 43/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8386 - loss: 0.4646 - val_accuracy: 0.6866 - val_loss: 1.1117\n",
      "Epoch 44/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.4441 - val_accuracy: 0.6860 - val_loss: 1.1131\n",
      "Epoch 45/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.4477 - val_accuracy: 0.6859 - val_loss: 1.1262\n",
      "Epoch 46/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.4461 - val_accuracy: 0.6876 - val_loss: 1.1114\n",
      "Epoch 47/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4409 - val_accuracy: 0.6852 - val_loss: 1.1362\n",
      "Epoch 48/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.4446 - val_accuracy: 0.6893 - val_loss: 1.1380\n",
      "Epoch 49/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.4393 - val_accuracy: 0.6878 - val_loss: 1.1396\n",
      "Epoch 50/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4279 - val_accuracy: 0.6865 - val_loss: 1.1519\n",
      "Epoch 51/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.4281 - val_accuracy: 0.6860 - val_loss: 1.1589\n",
      "Epoch 52/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.4278 - val_accuracy: 0.6869 - val_loss: 1.1502\n",
      "Epoch 53/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.4288 - val_accuracy: 0.6879 - val_loss: 1.1785\n",
      "Epoch 54/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.4213 - val_accuracy: 0.6895 - val_loss: 1.1883\n",
      "Epoch 55/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.4194 - val_accuracy: 0.6840 - val_loss: 1.1777\n",
      "Epoch 56/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.4168 - val_accuracy: 0.6864 - val_loss: 1.1800\n",
      "Epoch 57/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.4109 - val_accuracy: 0.6908 - val_loss: 1.1744\n",
      "Epoch 58/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.4114 - val_accuracy: 0.6847 - val_loss: 1.1806\n",
      "Epoch 59/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.4003 - val_accuracy: 0.6870 - val_loss: 1.1894\n",
      "Epoch 60/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.4068 - val_accuracy: 0.6894 - val_loss: 1.2084\n",
      "Epoch 61/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3960 - val_accuracy: 0.6849 - val_loss: 1.2060\n",
      "Epoch 62/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3992 - val_accuracy: 0.6891 - val_loss: 1.2316\n",
      "Epoch 63/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.4053 - val_accuracy: 0.6854 - val_loss: 1.2447\n",
      "Epoch 64/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.4008 - val_accuracy: 0.6884 - val_loss: 1.2089\n",
      "Epoch 65/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3935 - val_accuracy: 0.6864 - val_loss: 1.2376\n",
      "Epoch 66/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3971 - val_accuracy: 0.6872 - val_loss: 1.2307\n",
      "Epoch 67/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.3951 - val_accuracy: 0.6860 - val_loss: 1.2192\n",
      "Epoch 68/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3854 - val_accuracy: 0.6835 - val_loss: 1.2320\n",
      "Epoch 69/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3853 - val_accuracy: 0.6857 - val_loss: 1.2214\n",
      "Epoch 70/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3848 - val_accuracy: 0.6872 - val_loss: 1.2531\n",
      "Epoch 71/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3842 - val_accuracy: 0.6863 - val_loss: 1.2449\n",
      "Epoch 72/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3886 - val_accuracy: 0.6878 - val_loss: 1.2733\n",
      "Epoch 73/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3813 - val_accuracy: 0.6868 - val_loss: 1.2741\n",
      "Epoch 74/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3862 - val_accuracy: 0.6888 - val_loss: 1.2612\n",
      "Epoch 75/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3789 - val_accuracy: 0.6894 - val_loss: 1.2635\n",
      "Epoch 76/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3864 - val_accuracy: 0.6865 - val_loss: 1.2551\n",
      "Epoch 77/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3732 - val_accuracy: 0.6871 - val_loss: 1.2895\n",
      "Epoch 78/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.3743 - val_accuracy: 0.6859 - val_loss: 1.2739\n",
      "Epoch 79/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.3715 - val_accuracy: 0.6859 - val_loss: 1.2716\n",
      "Epoch 80/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.3706 - val_accuracy: 0.6860 - val_loss: 1.2894\n",
      "Epoch 81/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3591 - val_accuracy: 0.6914 - val_loss: 1.2963\n",
      "Epoch 82/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.3697 - val_accuracy: 0.6865 - val_loss: 1.3086\n",
      "Epoch 83/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.3707 - val_accuracy: 0.6895 - val_loss: 1.3049\n",
      "Epoch 84/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.3718 - val_accuracy: 0.6882 - val_loss: 1.2878\n",
      "Epoch 85/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.3588 - val_accuracy: 0.6837 - val_loss: 1.2993\n",
      "Epoch 86/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.3632 - val_accuracy: 0.6820 - val_loss: 1.3252\n",
      "Epoch 87/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3626 - val_accuracy: 0.6855 - val_loss: 1.3186\n",
      "Epoch 88/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.3599 - val_accuracy: 0.6874 - val_loss: 1.3182\n",
      "Epoch 89/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.3617 - val_accuracy: 0.6881 - val_loss: 1.3016\n",
      "Epoch 90/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.3599 - val_accuracy: 0.6837 - val_loss: 1.3071\n",
      "Epoch 91/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.3545 - val_accuracy: 0.6845 - val_loss: 1.3082\n",
      "Epoch 92/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3595 - val_accuracy: 0.6826 - val_loss: 1.3134\n",
      "Epoch 93/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3579 - val_accuracy: 0.6876 - val_loss: 1.2997\n",
      "Epoch 94/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.3499 - val_accuracy: 0.6882 - val_loss: 1.3125\n",
      "Epoch 95/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8829 - loss: 0.3539 - val_accuracy: 0.6834 - val_loss: 1.3084\n",
      "Epoch 96/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.3502 - val_accuracy: 0.6900 - val_loss: 1.3058\n",
      "Epoch 97/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.3453 - val_accuracy: 0.6845 - val_loss: 1.3019\n",
      "Epoch 98/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.3461 - val_accuracy: 0.6850 - val_loss: 1.3627\n",
      "Epoch 99/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3502 - val_accuracy: 0.6894 - val_loss: 1.3261\n",
      "Epoch 100/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3417 - val_accuracy: 0.6851 - val_loss: 1.3410\n",
      "Epoch 101/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8816 - loss: 0.3519 - val_accuracy: 0.6842 - val_loss: 1.3382\n",
      "Epoch 102/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.3493 - val_accuracy: 0.6821 - val_loss: 1.3364\n",
      "Epoch 103/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.3413 - val_accuracy: 0.6809 - val_loss: 1.3805\n",
      "Epoch 104/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3430 - val_accuracy: 0.6821 - val_loss: 1.3537\n",
      "Epoch 105/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.3424 - val_accuracy: 0.6839 - val_loss: 1.3787\n",
      "Epoch 106/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3424 - val_accuracy: 0.6876 - val_loss: 1.3384\n",
      "Epoch 107/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.3434 - val_accuracy: 0.6882 - val_loss: 1.3563\n",
      "Epoch 108/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.3502 - val_accuracy: 0.6886 - val_loss: 1.3652\n",
      "Epoch 109/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3428 - val_accuracy: 0.6851 - val_loss: 1.3502\n",
      "Epoch 110/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.3302 - val_accuracy: 0.6887 - val_loss: 1.3537\n",
      "Epoch 111/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.3346 - val_accuracy: 0.6870 - val_loss: 1.3866\n",
      "Epoch 112/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.3351 - val_accuracy: 0.6859 - val_loss: 1.3396\n",
      "Epoch 113/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.3315 - val_accuracy: 0.6880 - val_loss: 1.3640\n",
      "Epoch 114/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3318 - val_accuracy: 0.6850 - val_loss: 1.3661\n",
      "Epoch 115/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.3340 - val_accuracy: 0.6866 - val_loss: 1.3778\n",
      "Epoch 116/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3349 - val_accuracy: 0.6884 - val_loss: 1.3775\n",
      "Epoch 117/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3437 - val_accuracy: 0.6854 - val_loss: 1.3702\n",
      "Epoch 118/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.3349 - val_accuracy: 0.6862 - val_loss: 1.3711\n",
      "Epoch 119/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3369 - val_accuracy: 0.6857 - val_loss: 1.3805\n",
      "Epoch 120/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.3366 - val_accuracy: 0.6857 - val_loss: 1.3744\n",
      "Epoch 121/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.3255 - val_accuracy: 0.6909 - val_loss: 1.3670\n",
      "Epoch 122/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.3346 - val_accuracy: 0.6837 - val_loss: 1.3766\n",
      "Epoch 123/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.3311 - val_accuracy: 0.6849 - val_loss: 1.3727\n",
      "Epoch 124/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3261 - val_accuracy: 0.6865 - val_loss: 1.3971\n",
      "Epoch 125/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.3307 - val_accuracy: 0.6822 - val_loss: 1.4042\n",
      "Epoch 126/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.3242 - val_accuracy: 0.6867 - val_loss: 1.4235\n",
      "Epoch 127/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.3316 - val_accuracy: 0.6853 - val_loss: 1.4110\n",
      "Epoch 128/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.3218 - val_accuracy: 0.6840 - val_loss: 1.4176\n",
      "Epoch 129/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3278 - val_accuracy: 0.6866 - val_loss: 1.3619\n",
      "Epoch 130/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.3242 - val_accuracy: 0.6880 - val_loss: 1.3961\n",
      "Epoch 131/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.3209 - val_accuracy: 0.6840 - val_loss: 1.3686\n",
      "Epoch 132/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.3188 - val_accuracy: 0.6810 - val_loss: 1.4089\n",
      "Epoch 133/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3237 - val_accuracy: 0.6841 - val_loss: 1.4308\n",
      "Epoch 134/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.3203 - val_accuracy: 0.6851 - val_loss: 1.3978\n",
      "Epoch 135/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.3192 - val_accuracy: 0.6876 - val_loss: 1.3721\n",
      "Epoch 136/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.3101 - val_accuracy: 0.6873 - val_loss: 1.3604\n",
      "Epoch 137/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3200 - val_accuracy: 0.6858 - val_loss: 1.4046\n",
      "Epoch 138/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.3173 - val_accuracy: 0.6836 - val_loss: 1.4048\n",
      "Epoch 139/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.3205 - val_accuracy: 0.6861 - val_loss: 1.4249\n",
      "Epoch 140/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3211 - val_accuracy: 0.6859 - val_loss: 1.3935\n",
      "Epoch 141/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8945 - loss: 0.3188 - val_accuracy: 0.6885 - val_loss: 1.3863\n",
      "Epoch 142/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.3168 - val_accuracy: 0.6870 - val_loss: 1.4230\n",
      "Epoch 143/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.3177 - val_accuracy: 0.6867 - val_loss: 1.4294\n",
      "Epoch 144/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.3108 - val_accuracy: 0.6839 - val_loss: 1.4197\n",
      "Epoch 145/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.3199 - val_accuracy: 0.6840 - val_loss: 1.4446\n",
      "Epoch 146/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.3117 - val_accuracy: 0.6850 - val_loss: 1.4328\n",
      "Epoch 147/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8959 - loss: 0.3164 - val_accuracy: 0.6863 - val_loss: 1.4237\n",
      "Epoch 148/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.3097 - val_accuracy: 0.6840 - val_loss: 1.4309\n",
      "Epoch 149/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.3103 - val_accuracy: 0.6863 - val_loss: 1.4113\n",
      "Epoch 150/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.3156 - val_accuracy: 0.6845 - val_loss: 1.4334\n",
      "Epoch 151/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.3083 - val_accuracy: 0.6874 - val_loss: 1.4411\n",
      "Epoch 152/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3152 - val_accuracy: 0.6854 - val_loss: 1.4247\n",
      "Epoch 153/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.3083 - val_accuracy: 0.6876 - val_loss: 1.4460\n",
      "Epoch 154/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.3098 - val_accuracy: 0.6865 - val_loss: 1.4514\n",
      "Epoch 155/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3050 - val_accuracy: 0.6811 - val_loss: 1.4398\n",
      "Epoch 156/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.3109 - val_accuracy: 0.6877 - val_loss: 1.4257\n",
      "Epoch 157/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.3140 - val_accuracy: 0.6830 - val_loss: 1.4375\n",
      "Epoch 158/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2988 - val_accuracy: 0.6828 - val_loss: 1.4346\n",
      "Epoch 159/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.3066 - val_accuracy: 0.6862 - val_loss: 1.4395\n",
      "Epoch 160/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 0.3053 - val_accuracy: 0.6831 - val_loss: 1.4275\n",
      "Epoch 161/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3090 - val_accuracy: 0.6839 - val_loss: 1.4420\n",
      "Epoch 162/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.3097 - val_accuracy: 0.6808 - val_loss: 1.4228\n",
      "Epoch 163/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.3032 - val_accuracy: 0.6849 - val_loss: 1.4189\n",
      "Epoch 164/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.3042 - val_accuracy: 0.6869 - val_loss: 1.4337\n",
      "Epoch 165/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.3009 - val_accuracy: 0.6826 - val_loss: 1.4472\n",
      "Epoch 166/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.3087 - val_accuracy: 0.6843 - val_loss: 1.4350\n",
      "Epoch 167/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.3034 - val_accuracy: 0.6845 - val_loss: 1.4080\n",
      "Epoch 168/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.3019 - val_accuracy: 0.6817 - val_loss: 1.4209\n",
      "Epoch 169/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.3030 - val_accuracy: 0.6871 - val_loss: 1.4619\n",
      "Epoch 170/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2953 - val_accuracy: 0.6863 - val_loss: 1.4242\n",
      "Epoch 171/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.3023 - val_accuracy: 0.6880 - val_loss: 1.4693\n",
      "Epoch 172/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3062 - val_accuracy: 0.6829 - val_loss: 1.4524\n",
      "Epoch 173/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2984 - val_accuracy: 0.6821 - val_loss: 1.4370\n",
      "Epoch 174/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2986 - val_accuracy: 0.6855 - val_loss: 1.4560\n",
      "Epoch 175/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.3007 - val_accuracy: 0.6814 - val_loss: 1.4761\n",
      "Epoch 176/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.2929 - val_accuracy: 0.6843 - val_loss: 1.4879\n",
      "Epoch 177/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2977 - val_accuracy: 0.6819 - val_loss: 1.4346\n",
      "Epoch 178/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2970 - val_accuracy: 0.6843 - val_loss: 1.4831\n",
      "Epoch 179/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.3015 - val_accuracy: 0.6850 - val_loss: 1.4610\n",
      "Epoch 180/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.2995 - val_accuracy: 0.6843 - val_loss: 1.4631\n",
      "Epoch 181/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2987 - val_accuracy: 0.6843 - val_loss: 1.4371\n",
      "Epoch 182/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2923 - val_accuracy: 0.6846 - val_loss: 1.4713\n",
      "Epoch 183/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2974 - val_accuracy: 0.6852 - val_loss: 1.4592\n",
      "Epoch 184/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2967 - val_accuracy: 0.6818 - val_loss: 1.4721\n",
      "Epoch 185/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.3036 - val_accuracy: 0.6855 - val_loss: 1.4297\n",
      "Epoch 186/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2907 - val_accuracy: 0.6811 - val_loss: 1.5044\n",
      "Epoch 187/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9039 - loss: 0.2924 - val_accuracy: 0.6798 - val_loss: 1.4614\n",
      "Epoch 188/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2976 - val_accuracy: 0.6839 - val_loss: 1.4739\n",
      "Epoch 189/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2927 - val_accuracy: 0.6830 - val_loss: 1.4751\n",
      "Epoch 190/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2958 - val_accuracy: 0.6859 - val_loss: 1.4361\n",
      "Epoch 191/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.2961 - val_accuracy: 0.6840 - val_loss: 1.4497\n",
      "Epoch 192/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2914 - val_accuracy: 0.6809 - val_loss: 1.4963\n",
      "Epoch 193/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.3010 - val_accuracy: 0.6848 - val_loss: 1.4612\n",
      "Epoch 194/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.2930 - val_accuracy: 0.6850 - val_loss: 1.4847\n",
      "Epoch 195/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2898 - val_accuracy: 0.6842 - val_loss: 1.4877\n",
      "Epoch 196/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2945 - val_accuracy: 0.6845 - val_loss: 1.4651\n",
      "Epoch 197/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2916 - val_accuracy: 0.6832 - val_loss: 1.4657\n",
      "Epoch 198/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2958 - val_accuracy: 0.6849 - val_loss: 1.4805\n",
      "Epoch 199/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.2943 - val_accuracy: 0.6836 - val_loss: 1.4649\n",
      "Epoch 200/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2904 - val_accuracy: 0.6804 - val_loss: 1.4781\n",
      "Epoch 201/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2918 - val_accuracy: 0.6819 - val_loss: 1.4834\n",
      "Epoch 202/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.2913 - val_accuracy: 0.6857 - val_loss: 1.5091\n",
      "Epoch 203/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2881 - val_accuracy: 0.6838 - val_loss: 1.5085\n",
      "Epoch 204/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2852 - val_accuracy: 0.6824 - val_loss: 1.5272\n",
      "Epoch 205/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2820 - val_accuracy: 0.6826 - val_loss: 1.5150\n",
      "Epoch 206/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2868 - val_accuracy: 0.6854 - val_loss: 1.4716\n",
      "Epoch 207/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2948 - val_accuracy: 0.6850 - val_loss: 1.4596\n",
      "Epoch 208/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2849 - val_accuracy: 0.6829 - val_loss: 1.4896\n",
      "Epoch 209/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2895 - val_accuracy: 0.6818 - val_loss: 1.5146\n",
      "Epoch 210/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.2996 - val_accuracy: 0.6825 - val_loss: 1.5250\n",
      "Epoch 211/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.2868 - val_accuracy: 0.6868 - val_loss: 1.5106\n",
      "Epoch 212/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2856 - val_accuracy: 0.6865 - val_loss: 1.5106\n",
      "Epoch 213/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2898 - val_accuracy: 0.6852 - val_loss: 1.4559\n",
      "Epoch 214/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2856 - val_accuracy: 0.6855 - val_loss: 1.5043\n",
      "Epoch 215/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2888 - val_accuracy: 0.6863 - val_loss: 1.4985\n",
      "Epoch 216/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2846 - val_accuracy: 0.6851 - val_loss: 1.4896\n",
      "Epoch 217/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2935 - val_accuracy: 0.6864 - val_loss: 1.4984\n",
      "Epoch 218/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2853 - val_accuracy: 0.6833 - val_loss: 1.4919\n",
      "Epoch 219/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2897 - val_accuracy: 0.6841 - val_loss: 1.4951\n",
      "Epoch 220/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2765 - val_accuracy: 0.6832 - val_loss: 1.5288\n",
      "Epoch 221/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.2850 - val_accuracy: 0.6848 - val_loss: 1.5167\n",
      "Epoch 222/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2804 - val_accuracy: 0.6836 - val_loss: 1.5057\n",
      "Epoch 223/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2916 - val_accuracy: 0.6814 - val_loss: 1.4992\n",
      "Epoch 224/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2802 - val_accuracy: 0.6859 - val_loss: 1.5208\n",
      "Epoch 225/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2848 - val_accuracy: 0.6847 - val_loss: 1.5279\n",
      "Epoch 226/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2807 - val_accuracy: 0.6846 - val_loss: 1.5024\n",
      "Epoch 227/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2780 - val_accuracy: 0.6850 - val_loss: 1.5231\n",
      "Epoch 228/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2817 - val_accuracy: 0.6860 - val_loss: 1.5244\n",
      "Epoch 229/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.2824 - val_accuracy: 0.6863 - val_loss: 1.5185\n",
      "Epoch 230/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9095 - loss: 0.2841 - val_accuracy: 0.6846 - val_loss: 1.5139\n",
      "Epoch 231/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2855 - val_accuracy: 0.6847 - val_loss: 1.5406\n",
      "Epoch 232/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9091 - loss: 0.2797 - val_accuracy: 0.6794 - val_loss: 1.5575\n",
      "Epoch 233/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2797 - val_accuracy: 0.6842 - val_loss: 1.5396\n",
      "Epoch 234/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2816 - val_accuracy: 0.6819 - val_loss: 1.4835\n",
      "Epoch 235/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2768 - val_accuracy: 0.6830 - val_loss: 1.5179\n",
      "Epoch 236/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2733 - val_accuracy: 0.6823 - val_loss: 1.5381\n",
      "Epoch 237/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2840 - val_accuracy: 0.6815 - val_loss: 1.5230\n",
      "Epoch 238/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2777 - val_accuracy: 0.6845 - val_loss: 1.5299\n",
      "Epoch 239/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2820 - val_accuracy: 0.6830 - val_loss: 1.4947\n",
      "Epoch 240/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2757 - val_accuracy: 0.6805 - val_loss: 1.5210\n",
      "Epoch 241/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2759 - val_accuracy: 0.6786 - val_loss: 1.4815\n",
      "Epoch 242/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2800 - val_accuracy: 0.6830 - val_loss: 1.5139\n",
      "Epoch 243/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2835 - val_accuracy: 0.6781 - val_loss: 1.5185\n",
      "Epoch 244/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2811 - val_accuracy: 0.6802 - val_loss: 1.5186\n",
      "Epoch 245/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2801 - val_accuracy: 0.6832 - val_loss: 1.5110\n",
      "Epoch 246/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2731 - val_accuracy: 0.6829 - val_loss: 1.5029\n",
      "Epoch 247/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2756 - val_accuracy: 0.6881 - val_loss: 1.5022\n",
      "Epoch 248/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2755 - val_accuracy: 0.6827 - val_loss: 1.5577\n",
      "Epoch 249/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2756 - val_accuracy: 0.6846 - val_loss: 1.5364\n",
      "Epoch 250/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2765 - val_accuracy: 0.6839 - val_loss: 1.5635\n",
      "Epoch 251/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2741 - val_accuracy: 0.6824 - val_loss: 1.5181\n",
      "Epoch 252/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2746 - val_accuracy: 0.6830 - val_loss: 1.5310\n",
      "Epoch 253/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2761 - val_accuracy: 0.6827 - val_loss: 1.5570\n",
      "Epoch 254/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.2712 - val_accuracy: 0.6827 - val_loss: 1.5125\n",
      "Epoch 255/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2676 - val_accuracy: 0.6839 - val_loss: 1.6104\n",
      "Epoch 256/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2823 - val_accuracy: 0.6845 - val_loss: 1.5007\n",
      "Epoch 257/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2740 - val_accuracy: 0.6841 - val_loss: 1.5461\n",
      "Epoch 258/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2747 - val_accuracy: 0.6806 - val_loss: 1.5624\n",
      "Epoch 259/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2831 - val_accuracy: 0.6817 - val_loss: 1.5224\n",
      "Epoch 260/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2788 - val_accuracy: 0.6844 - val_loss: 1.5460\n",
      "Epoch 261/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.2770 - val_accuracy: 0.6847 - val_loss: 1.5284\n",
      "Epoch 262/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2721 - val_accuracy: 0.6820 - val_loss: 1.5864\n",
      "Epoch 263/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2721 - val_accuracy: 0.6793 - val_loss: 1.5487\n",
      "Epoch 264/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2758 - val_accuracy: 0.6782 - val_loss: 1.5512\n",
      "Epoch 265/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2733 - val_accuracy: 0.6796 - val_loss: 1.5219\n",
      "Epoch 266/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2776 - val_accuracy: 0.6848 - val_loss: 1.5542\n",
      "Epoch 267/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2788 - val_accuracy: 0.6823 - val_loss: 1.5192\n",
      "Epoch 268/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2718 - val_accuracy: 0.6821 - val_loss: 1.5182\n",
      "Epoch 269/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2745 - val_accuracy: 0.6835 - val_loss: 1.5411\n",
      "Epoch 270/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2681 - val_accuracy: 0.6815 - val_loss: 1.5692\n",
      "Epoch 271/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2732 - val_accuracy: 0.6845 - val_loss: 1.5560\n",
      "Epoch 272/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2748 - val_accuracy: 0.6840 - val_loss: 1.5700\n",
      "Epoch 273/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2774 - val_accuracy: 0.6855 - val_loss: 1.5372\n",
      "Epoch 274/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2740 - val_accuracy: 0.6810 - val_loss: 1.5391\n",
      "Epoch 275/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2685 - val_accuracy: 0.6818 - val_loss: 1.5276\n",
      "Epoch 276/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2721 - val_accuracy: 0.6815 - val_loss: 1.5280\n",
      "Epoch 277/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2769 - val_accuracy: 0.6815 - val_loss: 1.5692\n",
      "Epoch 278/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.2726 - val_accuracy: 0.6837 - val_loss: 1.5739\n",
      "Epoch 279/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2715 - val_accuracy: 0.6822 - val_loss: 1.5652\n",
      "Epoch 280/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2659 - val_accuracy: 0.6802 - val_loss: 1.5599\n",
      "Epoch 281/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2745 - val_accuracy: 0.6791 - val_loss: 1.5587\n",
      "Epoch 282/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2756 - val_accuracy: 0.6784 - val_loss: 1.5475\n",
      "Epoch 283/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2745 - val_accuracy: 0.6814 - val_loss: 1.5751\n",
      "Epoch 284/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.2666 - val_accuracy: 0.6799 - val_loss: 1.5568\n",
      "Epoch 285/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.2736 - val_accuracy: 0.6799 - val_loss: 1.5640\n",
      "Epoch 286/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2673 - val_accuracy: 0.6747 - val_loss: 1.6016\n",
      "Epoch 287/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2651 - val_accuracy: 0.6783 - val_loss: 1.5869\n",
      "Epoch 288/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2631 - val_accuracy: 0.6793 - val_loss: 1.5388\n",
      "Epoch 289/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2717 - val_accuracy: 0.6818 - val_loss: 1.5627\n",
      "Epoch 290/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2686 - val_accuracy: 0.6825 - val_loss: 1.5791\n",
      "Epoch 291/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2699 - val_accuracy: 0.6834 - val_loss: 1.5886\n",
      "Epoch 292/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2651 - val_accuracy: 0.6802 - val_loss: 1.5552\n",
      "Epoch 293/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2722 - val_accuracy: 0.6811 - val_loss: 1.5509\n",
      "Epoch 294/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2702 - val_accuracy: 0.6797 - val_loss: 1.5926\n",
      "Epoch 295/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2652 - val_accuracy: 0.6843 - val_loss: 1.6077\n",
      "Epoch 296/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2591 - val_accuracy: 0.6793 - val_loss: 1.5840\n",
      "Epoch 297/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2697 - val_accuracy: 0.6827 - val_loss: 1.5738\n",
      "Epoch 298/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2666 - val_accuracy: 0.6796 - val_loss: 1.5792\n",
      "Epoch 299/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2659 - val_accuracy: 0.6816 - val_loss: 1.5579\n",
      "Epoch 300/300\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.2634 - val_accuracy: 0.6856 - val_loss: 1.5609\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.6818 - loss: 1.5658\n",
      "test_accuracy: 68.56%\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=300,batch_size=300,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4833 - loss: 1.5087 - val_accuracy: 0.6261 - val_loss: 1.0919\n",
      "Epoch 2/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6251 - loss: 1.0871 - val_accuracy: 0.6501 - val_loss: 1.0229\n",
      "Epoch 3/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6481 - loss: 1.0112 - val_accuracy: 0.6594 - val_loss: 0.9900\n",
      "Epoch 4/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6672 - loss: 0.9523 - val_accuracy: 0.6577 - val_loss: 0.9694\n",
      "Epoch 5/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6797 - loss: 0.9129 - val_accuracy: 0.6701 - val_loss: 0.9506\n",
      "Epoch 6/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6897 - loss: 0.8778 - val_accuracy: 0.6697 - val_loss: 0.9516\n",
      "Epoch 7/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7009 - loss: 0.8487 - val_accuracy: 0.6760 - val_loss: 0.9309\n",
      "Epoch 8/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7153 - loss: 0.8133 - val_accuracy: 0.6741 - val_loss: 0.9350\n",
      "Epoch 9/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7209 - loss: 0.7890 - val_accuracy: 0.6766 - val_loss: 0.9210\n",
      "Epoch 10/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7294 - loss: 0.7661 - val_accuracy: 0.6825 - val_loss: 0.9219\n",
      "Epoch 11/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7409 - loss: 0.7375 - val_accuracy: 0.6828 - val_loss: 0.9291\n",
      "Epoch 12/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7411 - loss: 0.7298 - val_accuracy: 0.6800 - val_loss: 0.9252\n",
      "Epoch 13/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7561 - loss: 0.6915 - val_accuracy: 0.6819 - val_loss: 0.9268\n",
      "Epoch 14/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7646 - loss: 0.6660 - val_accuracy: 0.6855 - val_loss: 0.9338\n",
      "Epoch 15/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7661 - loss: 0.6540 - val_accuracy: 0.6844 - val_loss: 0.9475\n",
      "Epoch 16/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7797 - loss: 0.6322 - val_accuracy: 0.6878 - val_loss: 0.9546\n",
      "Epoch 17/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7844 - loss: 0.6147 - val_accuracy: 0.6788 - val_loss: 0.9777\n",
      "Epoch 18/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7849 - loss: 0.6061 - val_accuracy: 0.6881 - val_loss: 0.9660\n",
      "Epoch 19/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7968 - loss: 0.5789 - val_accuracy: 0.6852 - val_loss: 0.9748\n",
      "Epoch 20/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7987 - loss: 0.5717 - val_accuracy: 0.6856 - val_loss: 0.9875\n",
      "Epoch 21/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8050 - loss: 0.5548 - val_accuracy: 0.6866 - val_loss: 0.9991\n",
      "Epoch 22/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8113 - loss: 0.5410 - val_accuracy: 0.6835 - val_loss: 1.0053\n",
      "Epoch 23/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8167 - loss: 0.5268 - val_accuracy: 0.6872 - val_loss: 1.0045\n",
      "Epoch 24/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8204 - loss: 0.5153 - val_accuracy: 0.6861 - val_loss: 1.0318\n",
      "Epoch 25/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8246 - loss: 0.5039 - val_accuracy: 0.6886 - val_loss: 1.0176\n",
      "Epoch 26/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8301 - loss: 0.4936 - val_accuracy: 0.6850 - val_loss: 1.0382\n",
      "Epoch 27/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8337 - loss: 0.4816 - val_accuracy: 0.6903 - val_loss: 1.0582\n",
      "Epoch 28/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8361 - loss: 0.4758 - val_accuracy: 0.6880 - val_loss: 1.0678\n",
      "Epoch 29/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8403 - loss: 0.4627 - val_accuracy: 0.6850 - val_loss: 1.0726\n",
      "Epoch 30/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8483 - loss: 0.4447 - val_accuracy: 0.6870 - val_loss: 1.0849\n",
      "Epoch 31/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8493 - loss: 0.4409 - val_accuracy: 0.6852 - val_loss: 1.1055\n",
      "Epoch 32/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8512 - loss: 0.4345 - val_accuracy: 0.6854 - val_loss: 1.1179\n",
      "Epoch 33/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8521 - loss: 0.4323 - val_accuracy: 0.6867 - val_loss: 1.1080\n",
      "Epoch 34/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8558 - loss: 0.4250 - val_accuracy: 0.6911 - val_loss: 1.1182\n",
      "Epoch 35/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8586 - loss: 0.4150 - val_accuracy: 0.6855 - val_loss: 1.1130\n",
      "Epoch 36/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8650 - loss: 0.3973 - val_accuracy: 0.6826 - val_loss: 1.1481\n",
      "Epoch 37/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8663 - loss: 0.3975 - val_accuracy: 0.6839 - val_loss: 1.1457\n",
      "Epoch 38/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8679 - loss: 0.3892 - val_accuracy: 0.6880 - val_loss: 1.1513\n",
      "Epoch 39/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8681 - loss: 0.3854 - val_accuracy: 0.6874 - val_loss: 1.1942\n",
      "Epoch 40/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8712 - loss: 0.3846 - val_accuracy: 0.6874 - val_loss: 1.1910\n",
      "Epoch 41/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8719 - loss: 0.3787 - val_accuracy: 0.6863 - val_loss: 1.2159\n",
      "Epoch 42/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8757 - loss: 0.3738 - val_accuracy: 0.6866 - val_loss: 1.2238\n",
      "Epoch 43/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8757 - loss: 0.3709 - val_accuracy: 0.6872 - val_loss: 1.1939\n",
      "Epoch 44/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8776 - loss: 0.3660 - val_accuracy: 0.6890 - val_loss: 1.1839\n",
      "Epoch 45/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8780 - loss: 0.3629 - val_accuracy: 0.6846 - val_loss: 1.2253\n",
      "Epoch 46/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8789 - loss: 0.3582 - val_accuracy: 0.6857 - val_loss: 1.2157\n",
      "Epoch 47/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8825 - loss: 0.3515 - val_accuracy: 0.6859 - val_loss: 1.2226\n",
      "Epoch 48/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8820 - loss: 0.3550 - val_accuracy: 0.6882 - val_loss: 1.2464\n",
      "Epoch 49/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8862 - loss: 0.3419 - val_accuracy: 0.6921 - val_loss: 1.2553\n",
      "Epoch 50/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8856 - loss: 0.3417 - val_accuracy: 0.6850 - val_loss: 1.2685\n",
      "Epoch 51/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8865 - loss: 0.3402 - val_accuracy: 0.6859 - val_loss: 1.2634\n",
      "Epoch 52/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8889 - loss: 0.3356 - val_accuracy: 0.6914 - val_loss: 1.2504\n",
      "Epoch 53/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8893 - loss: 0.3320 - val_accuracy: 0.6852 - val_loss: 1.2804\n",
      "Epoch 54/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8925 - loss: 0.3267 - val_accuracy: 0.6903 - val_loss: 1.2646\n",
      "Epoch 55/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8932 - loss: 0.3276 - val_accuracy: 0.6867 - val_loss: 1.2689\n",
      "Epoch 56/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8916 - loss: 0.3235 - val_accuracy: 0.6877 - val_loss: 1.2812\n",
      "Epoch 57/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8909 - loss: 0.3270 - val_accuracy: 0.6886 - val_loss: 1.3163\n",
      "Epoch 58/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8975 - loss: 0.3161 - val_accuracy: 0.6898 - val_loss: 1.2670\n",
      "Epoch 59/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8926 - loss: 0.3247 - val_accuracy: 0.6817 - val_loss: 1.2959\n",
      "Epoch 60/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8946 - loss: 0.3173 - val_accuracy: 0.6851 - val_loss: 1.3154\n",
      "Epoch 61/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8971 - loss: 0.3118 - val_accuracy: 0.6868 - val_loss: 1.3150\n",
      "Epoch 62/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8974 - loss: 0.3106 - val_accuracy: 0.6896 - val_loss: 1.3440\n",
      "Epoch 63/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8973 - loss: 0.3125 - val_accuracy: 0.6869 - val_loss: 1.3579\n",
      "Epoch 64/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8977 - loss: 0.3160 - val_accuracy: 0.6840 - val_loss: 1.3075\n",
      "Epoch 65/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9019 - loss: 0.3034 - val_accuracy: 0.6853 - val_loss: 1.3460\n",
      "Epoch 66/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9011 - loss: 0.3017 - val_accuracy: 0.6815 - val_loss: 1.3689\n",
      "Epoch 67/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9003 - loss: 0.3054 - val_accuracy: 0.6797 - val_loss: 1.3630\n",
      "Epoch 68/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9008 - loss: 0.3012 - val_accuracy: 0.6869 - val_loss: 1.3581\n",
      "Epoch 69/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9016 - loss: 0.3036 - val_accuracy: 0.6837 - val_loss: 1.3491\n",
      "Epoch 70/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8997 - loss: 0.3078 - val_accuracy: 0.6860 - val_loss: 1.3680\n",
      "Epoch 71/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9047 - loss: 0.2986 - val_accuracy: 0.6845 - val_loss: 1.3473\n",
      "Epoch 72/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9061 - loss: 0.2939 - val_accuracy: 0.6838 - val_loss: 1.4093\n",
      "Epoch 73/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9049 - loss: 0.2939 - val_accuracy: 0.6836 - val_loss: 1.3674\n",
      "Epoch 74/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9041 - loss: 0.2970 - val_accuracy: 0.6825 - val_loss: 1.3385\n",
      "Epoch 75/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9074 - loss: 0.2909 - val_accuracy: 0.6866 - val_loss: 1.4091\n",
      "Epoch 76/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9063 - loss: 0.2894 - val_accuracy: 0.6849 - val_loss: 1.3604\n",
      "Epoch 77/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9047 - loss: 0.2924 - val_accuracy: 0.6835 - val_loss: 1.3654\n",
      "Epoch 78/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9056 - loss: 0.2872 - val_accuracy: 0.6853 - val_loss: 1.3935\n",
      "Epoch 79/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9058 - loss: 0.2907 - val_accuracy: 0.6865 - val_loss: 1.3847\n",
      "Epoch 80/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9075 - loss: 0.2885 - val_accuracy: 0.6853 - val_loss: 1.4405\n",
      "Epoch 81/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9083 - loss: 0.2850 - val_accuracy: 0.6902 - val_loss: 1.4398\n",
      "Epoch 82/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9075 - loss: 0.2838 - val_accuracy: 0.6881 - val_loss: 1.4188\n",
      "Epoch 83/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9103 - loss: 0.2797 - val_accuracy: 0.6837 - val_loss: 1.3808\n",
      "Epoch 84/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9084 - loss: 0.2844 - val_accuracy: 0.6865 - val_loss: 1.4710\n",
      "Epoch 85/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9110 - loss: 0.2789 - val_accuracy: 0.6837 - val_loss: 1.4545\n",
      "Epoch 86/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9079 - loss: 0.2843 - val_accuracy: 0.6836 - val_loss: 1.4213\n",
      "Epoch 87/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9093 - loss: 0.2800 - val_accuracy: 0.6860 - val_loss: 1.4248\n",
      "Epoch 88/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9094 - loss: 0.2838 - val_accuracy: 0.6834 - val_loss: 1.4420\n",
      "Epoch 89/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9120 - loss: 0.2759 - val_accuracy: 0.6862 - val_loss: 1.4614\n",
      "Epoch 90/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9117 - loss: 0.2768 - val_accuracy: 0.6882 - val_loss: 1.4238\n",
      "Epoch 91/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9120 - loss: 0.2739 - val_accuracy: 0.6780 - val_loss: 1.4466\n",
      "Epoch 92/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9124 - loss: 0.2717 - val_accuracy: 0.6829 - val_loss: 1.4355\n",
      "Epoch 93/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9095 - loss: 0.2789 - val_accuracy: 0.6846 - val_loss: 1.4822\n",
      "Epoch 94/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9127 - loss: 0.2712 - val_accuracy: 0.6849 - val_loss: 1.4536\n",
      "Epoch 95/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9147 - loss: 0.2682 - val_accuracy: 0.6830 - val_loss: 1.4426\n",
      "Epoch 96/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9147 - loss: 0.2665 - val_accuracy: 0.6862 - val_loss: 1.5176\n",
      "Epoch 97/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9141 - loss: 0.2705 - val_accuracy: 0.6858 - val_loss: 1.4795\n",
      "Epoch 98/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9133 - loss: 0.2704 - val_accuracy: 0.6870 - val_loss: 1.4239\n",
      "Epoch 99/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9149 - loss: 0.2667 - val_accuracy: 0.6879 - val_loss: 1.4519\n",
      "Epoch 100/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9148 - loss: 0.2694 - val_accuracy: 0.6876 - val_loss: 1.4990\n",
      "Epoch 101/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9140 - loss: 0.2640 - val_accuracy: 0.6859 - val_loss: 1.5043\n",
      "Epoch 102/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9157 - loss: 0.2638 - val_accuracy: 0.6864 - val_loss: 1.4504\n",
      "Epoch 103/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9151 - loss: 0.2691 - val_accuracy: 0.6862 - val_loss: 1.5227\n",
      "Epoch 104/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9176 - loss: 0.2605 - val_accuracy: 0.6802 - val_loss: 1.5244\n",
      "Epoch 105/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9159 - loss: 0.2670 - val_accuracy: 0.6841 - val_loss: 1.5403\n",
      "Epoch 106/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9139 - loss: 0.2672 - val_accuracy: 0.6843 - val_loss: 1.4956\n",
      "Epoch 107/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9145 - loss: 0.2683 - val_accuracy: 0.6851 - val_loss: 1.5008\n",
      "Epoch 108/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9168 - loss: 0.2612 - val_accuracy: 0.6849 - val_loss: 1.4515\n",
      "Epoch 109/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9142 - loss: 0.2676 - val_accuracy: 0.6850 - val_loss: 1.5349\n",
      "Epoch 110/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9158 - loss: 0.2600 - val_accuracy: 0.6873 - val_loss: 1.5385\n",
      "Epoch 111/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9219 - loss: 0.2487 - val_accuracy: 0.6857 - val_loss: 1.5186\n",
      "Epoch 112/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9183 - loss: 0.2613 - val_accuracy: 0.6828 - val_loss: 1.5494\n",
      "Epoch 113/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9155 - loss: 0.2654 - val_accuracy: 0.6870 - val_loss: 1.5220\n",
      "Epoch 114/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9145 - loss: 0.2681 - val_accuracy: 0.6798 - val_loss: 1.5301\n",
      "Epoch 115/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9184 - loss: 0.2600 - val_accuracy: 0.6815 - val_loss: 1.4959\n",
      "Epoch 116/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9188 - loss: 0.2571 - val_accuracy: 0.6836 - val_loss: 1.5312\n",
      "Epoch 117/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9163 - loss: 0.2664 - val_accuracy: 0.6833 - val_loss: 1.5039\n",
      "Epoch 118/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9179 - loss: 0.2585 - val_accuracy: 0.6844 - val_loss: 1.5517\n",
      "Epoch 119/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9169 - loss: 0.2588 - val_accuracy: 0.6823 - val_loss: 1.5081\n",
      "Epoch 120/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9177 - loss: 0.2579 - val_accuracy: 0.6822 - val_loss: 1.5578\n",
      "Epoch 121/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9186 - loss: 0.2583 - val_accuracy: 0.6803 - val_loss: 1.5857\n",
      "Epoch 122/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9203 - loss: 0.2530 - val_accuracy: 0.6840 - val_loss: 1.5449\n",
      "Epoch 123/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9200 - loss: 0.2534 - val_accuracy: 0.6866 - val_loss: 1.4892\n",
      "Epoch 124/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9222 - loss: 0.2502 - val_accuracy: 0.6906 - val_loss: 1.5413\n",
      "Epoch 125/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9222 - loss: 0.2493 - val_accuracy: 0.6833 - val_loss: 1.5533\n",
      "Epoch 126/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9205 - loss: 0.2514 - val_accuracy: 0.6829 - val_loss: 1.5325\n",
      "Epoch 127/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9186 - loss: 0.2533 - val_accuracy: 0.6816 - val_loss: 1.5271\n",
      "Epoch 128/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9196 - loss: 0.2531 - val_accuracy: 0.6850 - val_loss: 1.5236\n",
      "Epoch 129/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9198 - loss: 0.2554 - val_accuracy: 0.6794 - val_loss: 1.5665\n",
      "Epoch 130/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9227 - loss: 0.2479 - val_accuracy: 0.6863 - val_loss: 1.5582\n",
      "Epoch 131/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9205 - loss: 0.2543 - val_accuracy: 0.6805 - val_loss: 1.6182\n",
      "Epoch 132/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9232 - loss: 0.2460 - val_accuracy: 0.6838 - val_loss: 1.5965\n",
      "Epoch 133/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9201 - loss: 0.2535 - val_accuracy: 0.6815 - val_loss: 1.6180\n",
      "Epoch 134/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9218 - loss: 0.2476 - val_accuracy: 0.6809 - val_loss: 1.5773\n",
      "Epoch 135/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9208 - loss: 0.2543 - val_accuracy: 0.6798 - val_loss: 1.5899\n",
      "Epoch 136/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9189 - loss: 0.2529 - val_accuracy: 0.6856 - val_loss: 1.5617\n",
      "Epoch 137/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9212 - loss: 0.2537 - val_accuracy: 0.6837 - val_loss: 1.6076\n",
      "Epoch 138/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9209 - loss: 0.2524 - val_accuracy: 0.6825 - val_loss: 1.6038\n",
      "Epoch 139/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9219 - loss: 0.2548 - val_accuracy: 0.6833 - val_loss: 1.5785\n",
      "Epoch 140/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9221 - loss: 0.2490 - val_accuracy: 0.6850 - val_loss: 1.6068\n",
      "Epoch 141/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9196 - loss: 0.2565 - val_accuracy: 0.6830 - val_loss: 1.6308\n",
      "Epoch 142/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9217 - loss: 0.2547 - val_accuracy: 0.6820 - val_loss: 1.6538\n",
      "Epoch 143/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9210 - loss: 0.2547 - val_accuracy: 0.6862 - val_loss: 1.6150\n",
      "Epoch 144/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9233 - loss: 0.2465 - val_accuracy: 0.6822 - val_loss: 1.6413\n",
      "Epoch 145/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9238 - loss: 0.2411 - val_accuracy: 0.6783 - val_loss: 1.6435\n",
      "Epoch 146/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9245 - loss: 0.2423 - val_accuracy: 0.6840 - val_loss: 1.6053\n",
      "Epoch 147/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9204 - loss: 0.2485 - val_accuracy: 0.6828 - val_loss: 1.6366\n",
      "Epoch 148/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9238 - loss: 0.2431 - val_accuracy: 0.6835 - val_loss: 1.5501\n",
      "Epoch 149/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9240 - loss: 0.2454 - val_accuracy: 0.6806 - val_loss: 1.6889\n",
      "Epoch 150/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9269 - loss: 0.2387 - val_accuracy: 0.6846 - val_loss: 1.6274\n",
      "Epoch 151/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9258 - loss: 0.2405 - val_accuracy: 0.6818 - val_loss: 1.6560\n",
      "Epoch 152/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9202 - loss: 0.2541 - val_accuracy: 0.6856 - val_loss: 1.6506\n",
      "Epoch 153/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9233 - loss: 0.2497 - val_accuracy: 0.6857 - val_loss: 1.6264\n",
      "Epoch 154/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9212 - loss: 0.2481 - val_accuracy: 0.6844 - val_loss: 1.6617\n",
      "Epoch 155/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9196 - loss: 0.2604 - val_accuracy: 0.6834 - val_loss: 1.6971\n",
      "Epoch 156/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9232 - loss: 0.2461 - val_accuracy: 0.6856 - val_loss: 1.6627\n",
      "Epoch 157/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9225 - loss: 0.2466 - val_accuracy: 0.6853 - val_loss: 1.6869\n",
      "Epoch 158/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9261 - loss: 0.2361 - val_accuracy: 0.6861 - val_loss: 1.6731\n",
      "Epoch 159/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9237 - loss: 0.2458 - val_accuracy: 0.6821 - val_loss: 1.6679\n",
      "Epoch 160/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9240 - loss: 0.2465 - val_accuracy: 0.6823 - val_loss: 1.6094\n",
      "Epoch 161/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9237 - loss: 0.2474 - val_accuracy: 0.6807 - val_loss: 1.6363\n",
      "Epoch 162/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9238 - loss: 0.2431 - val_accuracy: 0.6838 - val_loss: 1.6924\n",
      "Epoch 163/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9213 - loss: 0.2485 - val_accuracy: 0.6825 - val_loss: 1.7006\n",
      "Epoch 164/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9245 - loss: 0.2447 - val_accuracy: 0.6807 - val_loss: 1.6436\n",
      "Epoch 165/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9276 - loss: 0.2353 - val_accuracy: 0.6844 - val_loss: 1.6779\n",
      "Epoch 166/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9236 - loss: 0.2473 - val_accuracy: 0.6824 - val_loss: 1.6006\n",
      "Epoch 167/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9244 - loss: 0.2466 - val_accuracy: 0.6845 - val_loss: 1.6752\n",
      "Epoch 168/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9230 - loss: 0.2467 - val_accuracy: 0.6874 - val_loss: 1.7109\n",
      "Epoch 169/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9249 - loss: 0.2403 - val_accuracy: 0.6874 - val_loss: 1.6877\n",
      "Epoch 170/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9254 - loss: 0.2399 - val_accuracy: 0.6835 - val_loss: 1.6575\n",
      "Epoch 171/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9239 - loss: 0.2437 - val_accuracy: 0.6793 - val_loss: 1.6499\n",
      "Epoch 172/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9248 - loss: 0.2437 - val_accuracy: 0.6812 - val_loss: 1.6111\n",
      "Epoch 173/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9251 - loss: 0.2396 - val_accuracy: 0.6818 - val_loss: 1.7018\n",
      "Epoch 174/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9253 - loss: 0.2377 - val_accuracy: 0.6822 - val_loss: 1.7008\n",
      "Epoch 175/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9236 - loss: 0.2462 - val_accuracy: 0.6847 - val_loss: 1.6326\n",
      "Epoch 176/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9259 - loss: 0.2405 - val_accuracy: 0.6816 - val_loss: 1.6232\n",
      "Epoch 177/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9274 - loss: 0.2342 - val_accuracy: 0.6882 - val_loss: 1.6867\n",
      "Epoch 178/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9243 - loss: 0.2481 - val_accuracy: 0.6875 - val_loss: 1.6666\n",
      "Epoch 179/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9264 - loss: 0.2365 - val_accuracy: 0.6834 - val_loss: 1.7224\n",
      "Epoch 180/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9230 - loss: 0.2418 - val_accuracy: 0.6793 - val_loss: 1.6896\n",
      "Epoch 181/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9244 - loss: 0.2451 - val_accuracy: 0.6793 - val_loss: 1.6440\n",
      "Epoch 182/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9245 - loss: 0.2395 - val_accuracy: 0.6835 - val_loss: 1.6925\n",
      "Epoch 183/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9279 - loss: 0.2328 - val_accuracy: 0.6803 - val_loss: 1.7096\n",
      "Epoch 184/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9265 - loss: 0.2381 - val_accuracy: 0.6800 - val_loss: 1.7113\n",
      "Epoch 185/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9240 - loss: 0.2438 - val_accuracy: 0.6813 - val_loss: 1.7700\n",
      "Epoch 186/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9273 - loss: 0.2372 - val_accuracy: 0.6768 - val_loss: 1.7060\n",
      "Epoch 187/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9242 - loss: 0.2399 - val_accuracy: 0.6829 - val_loss: 1.7280\n",
      "Epoch 188/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9259 - loss: 0.2393 - val_accuracy: 0.6784 - val_loss: 1.7165\n",
      "Epoch 189/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9256 - loss: 0.2374 - val_accuracy: 0.6811 - val_loss: 1.6551\n",
      "Epoch 190/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9270 - loss: 0.2374 - val_accuracy: 0.6801 - val_loss: 1.6666\n",
      "Epoch 191/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9255 - loss: 0.2398 - val_accuracy: 0.6794 - val_loss: 1.7241\n",
      "Epoch 192/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9250 - loss: 0.2443 - val_accuracy: 0.6818 - val_loss: 1.7195\n",
      "Epoch 193/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9260 - loss: 0.2362 - val_accuracy: 0.6822 - val_loss: 1.7699\n",
      "Epoch 194/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9238 - loss: 0.2453 - val_accuracy: 0.6818 - val_loss: 1.7908\n",
      "Epoch 195/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9269 - loss: 0.2365 - val_accuracy: 0.6793 - val_loss: 1.7784\n",
      "Epoch 196/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9283 - loss: 0.2313 - val_accuracy: 0.6806 - val_loss: 1.7394\n",
      "Epoch 197/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9272 - loss: 0.2357 - val_accuracy: 0.6854 - val_loss: 1.6932\n",
      "Epoch 198/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9252 - loss: 0.2404 - val_accuracy: 0.6848 - val_loss: 1.8049\n",
      "Epoch 199/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9264 - loss: 0.2423 - val_accuracy: 0.6821 - val_loss: 1.8167\n",
      "Epoch 200/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9263 - loss: 0.2388 - val_accuracy: 0.6856 - val_loss: 1.6925\n",
      "Epoch 201/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9258 - loss: 0.2368 - val_accuracy: 0.6818 - val_loss: 1.7468\n",
      "Epoch 202/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9270 - loss: 0.2373 - val_accuracy: 0.6882 - val_loss: 1.7606\n",
      "Epoch 203/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9254 - loss: 0.2404 - val_accuracy: 0.6837 - val_loss: 1.7384\n",
      "Epoch 204/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9267 - loss: 0.2345 - val_accuracy: 0.6809 - val_loss: 1.6706\n",
      "Epoch 205/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9280 - loss: 0.2334 - val_accuracy: 0.6810 - val_loss: 1.7830\n",
      "Epoch 206/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9260 - loss: 0.2402 - val_accuracy: 0.6870 - val_loss: 1.7278\n",
      "Epoch 207/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9277 - loss: 0.2346 - val_accuracy: 0.6826 - val_loss: 1.7203\n",
      "Epoch 208/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9273 - loss: 0.2358 - val_accuracy: 0.6822 - val_loss: 1.7428\n",
      "Epoch 209/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9259 - loss: 0.2408 - val_accuracy: 0.6816 - val_loss: 1.6909\n",
      "Epoch 210/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9284 - loss: 0.2330 - val_accuracy: 0.6847 - val_loss: 1.7398\n",
      "Epoch 211/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9260 - loss: 0.2420 - val_accuracy: 0.6822 - val_loss: 1.7058\n",
      "Epoch 212/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9261 - loss: 0.2387 - val_accuracy: 0.6777 - val_loss: 1.7148\n",
      "Epoch 213/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9256 - loss: 0.2372 - val_accuracy: 0.6804 - val_loss: 1.7366\n",
      "Epoch 214/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9262 - loss: 0.2373 - val_accuracy: 0.6781 - val_loss: 1.8370\n",
      "Epoch 215/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9271 - loss: 0.2372 - val_accuracy: 0.6840 - val_loss: 1.7674\n",
      "Epoch 216/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9237 - loss: 0.2459 - val_accuracy: 0.6822 - val_loss: 1.7816\n",
      "Epoch 217/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9290 - loss: 0.2303 - val_accuracy: 0.6825 - val_loss: 1.7900\n",
      "Epoch 218/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9292 - loss: 0.2299 - val_accuracy: 0.6820 - val_loss: 1.7954\n",
      "Epoch 219/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.2313 - val_accuracy: 0.6827 - val_loss: 1.7372\n",
      "Epoch 220/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9263 - loss: 0.2417 - val_accuracy: 0.6839 - val_loss: 1.7884\n",
      "Epoch 221/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9283 - loss: 0.2342 - val_accuracy: 0.6835 - val_loss: 1.8060\n",
      "Epoch 222/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9296 - loss: 0.2335 - val_accuracy: 0.6805 - val_loss: 1.8045\n",
      "Epoch 223/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9328 - loss: 0.2215 - val_accuracy: 0.6862 - val_loss: 1.8033\n",
      "Epoch 224/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9279 - loss: 0.2338 - val_accuracy: 0.6860 - val_loss: 1.7579\n",
      "Epoch 225/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9304 - loss: 0.2307 - val_accuracy: 0.6826 - val_loss: 1.8602\n",
      "Epoch 226/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.2254 - val_accuracy: 0.6877 - val_loss: 1.7767\n",
      "Epoch 227/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.2288 - val_accuracy: 0.6836 - val_loss: 1.8159\n",
      "Epoch 228/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9279 - loss: 0.2337 - val_accuracy: 0.6811 - val_loss: 1.8443\n",
      "Epoch 229/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9269 - loss: 0.2372 - val_accuracy: 0.6822 - val_loss: 1.8646\n",
      "Epoch 230/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9268 - loss: 0.2392 - val_accuracy: 0.6859 - val_loss: 1.7824\n",
      "Epoch 231/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9283 - loss: 0.2340 - val_accuracy: 0.6850 - val_loss: 1.7988\n",
      "Epoch 232/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9266 - loss: 0.2344 - val_accuracy: 0.6845 - val_loss: 1.8243\n",
      "Epoch 233/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9285 - loss: 0.2353 - val_accuracy: 0.6806 - val_loss: 1.7661\n",
      "Epoch 234/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9271 - loss: 0.2384 - val_accuracy: 0.6816 - val_loss: 1.8257\n",
      "Epoch 235/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.2255 - val_accuracy: 0.6811 - val_loss: 1.7852\n",
      "Epoch 236/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9282 - loss: 0.2320 - val_accuracy: 0.6837 - val_loss: 1.8931\n",
      "Epoch 237/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9281 - loss: 0.2317 - val_accuracy: 0.6781 - val_loss: 1.7489\n",
      "Epoch 238/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9277 - loss: 0.2317 - val_accuracy: 0.6856 - val_loss: 1.8777\n",
      "Epoch 239/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9287 - loss: 0.2342 - val_accuracy: 0.6819 - val_loss: 1.8505\n",
      "Epoch 240/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9295 - loss: 0.2298 - val_accuracy: 0.6814 - val_loss: 1.8302\n",
      "Epoch 241/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9280 - loss: 0.2324 - val_accuracy: 0.6803 - val_loss: 1.7310\n",
      "Epoch 242/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9302 - loss: 0.2267 - val_accuracy: 0.6835 - val_loss: 1.8520\n",
      "Epoch 243/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9289 - loss: 0.2355 - val_accuracy: 0.6829 - val_loss: 1.7759\n",
      "Epoch 244/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9269 - loss: 0.2394 - val_accuracy: 0.6847 - val_loss: 1.9184\n",
      "Epoch 245/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9279 - loss: 0.2371 - val_accuracy: 0.6847 - val_loss: 1.8528\n",
      "Epoch 246/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.2286 - val_accuracy: 0.6841 - val_loss: 1.8214\n",
      "Epoch 247/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9293 - loss: 0.2327 - val_accuracy: 0.6850 - val_loss: 1.8759\n",
      "Epoch 248/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9284 - loss: 0.2353 - val_accuracy: 0.6873 - val_loss: 1.8634\n",
      "Epoch 249/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9303 - loss: 0.2288 - val_accuracy: 0.6844 - val_loss: 1.9442\n",
      "Epoch 250/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9295 - loss: 0.2322 - val_accuracy: 0.6859 - val_loss: 1.9346\n",
      "Epoch 251/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9320 - loss: 0.2238 - val_accuracy: 0.6842 - val_loss: 1.8197\n",
      "Epoch 252/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9301 - loss: 0.2383 - val_accuracy: 0.6817 - val_loss: 1.8266\n",
      "Epoch 253/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9304 - loss: 0.2275 - val_accuracy: 0.6814 - val_loss: 1.9102\n",
      "Epoch 254/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9321 - loss: 0.2218 - val_accuracy: 0.6815 - val_loss: 1.8412\n",
      "Epoch 255/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9291 - loss: 0.2321 - val_accuracy: 0.6813 - val_loss: 1.7937\n",
      "Epoch 256/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9299 - loss: 0.2261 - val_accuracy: 0.6813 - val_loss: 1.8719\n",
      "Epoch 257/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9282 - loss: 0.2373 - val_accuracy: 0.6813 - val_loss: 1.8634\n",
      "Epoch 258/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9301 - loss: 0.2309 - val_accuracy: 0.6833 - val_loss: 1.8988\n",
      "Epoch 259/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9305 - loss: 0.2237 - val_accuracy: 0.6821 - val_loss: 1.8648\n",
      "Epoch 260/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9290 - loss: 0.2361 - val_accuracy: 0.6796 - val_loss: 1.8539\n",
      "Epoch 261/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9302 - loss: 0.2295 - val_accuracy: 0.6809 - val_loss: 1.7991\n",
      "Epoch 262/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9325 - loss: 0.2238 - val_accuracy: 0.6827 - val_loss: 1.8981\n",
      "Epoch 263/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9299 - loss: 0.2325 - val_accuracy: 0.6856 - val_loss: 1.9437\n",
      "Epoch 264/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9292 - loss: 0.2293 - val_accuracy: 0.6795 - val_loss: 1.8436\n",
      "Epoch 265/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9265 - loss: 0.2389 - val_accuracy: 0.6820 - val_loss: 1.9023\n",
      "Epoch 266/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9316 - loss: 0.2213 - val_accuracy: 0.6771 - val_loss: 1.9296\n",
      "Epoch 267/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9306 - loss: 0.2270 - val_accuracy: 0.6799 - val_loss: 1.8358\n",
      "Epoch 268/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9314 - loss: 0.2246 - val_accuracy: 0.6810 - val_loss: 1.8586\n",
      "Epoch 269/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9341 - loss: 0.2158 - val_accuracy: 0.6831 - val_loss: 1.8633\n",
      "Epoch 270/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9294 - loss: 0.2282 - val_accuracy: 0.6824 - val_loss: 1.9201\n",
      "Epoch 271/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9300 - loss: 0.2244 - val_accuracy: 0.6823 - val_loss: 1.8678\n",
      "Epoch 272/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9317 - loss: 0.2211 - val_accuracy: 0.6775 - val_loss: 1.8377\n",
      "Epoch 273/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9319 - loss: 0.2240 - val_accuracy: 0.6830 - val_loss: 1.9023\n",
      "Epoch 274/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.2312 - val_accuracy: 0.6802 - val_loss: 1.9817\n",
      "Epoch 275/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9309 - loss: 0.2277 - val_accuracy: 0.6815 - val_loss: 1.8429\n",
      "Epoch 276/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9322 - loss: 0.2229 - val_accuracy: 0.6834 - val_loss: 1.9586\n",
      "Epoch 277/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9310 - loss: 0.2320 - val_accuracy: 0.6811 - val_loss: 1.9402\n",
      "Epoch 278/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9307 - loss: 0.2311 - val_accuracy: 0.6817 - val_loss: 1.8979\n",
      "Epoch 279/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9302 - loss: 0.2311 - val_accuracy: 0.6849 - val_loss: 1.8980\n",
      "Epoch 280/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9309 - loss: 0.2286 - val_accuracy: 0.6786 - val_loss: 1.8793\n",
      "Epoch 281/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9308 - loss: 0.2305 - val_accuracy: 0.6804 - val_loss: 1.9048\n",
      "Epoch 282/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9317 - loss: 0.2261 - val_accuracy: 0.6789 - val_loss: 1.8717\n",
      "Epoch 283/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.2273 - val_accuracy: 0.6804 - val_loss: 1.8603\n",
      "Epoch 284/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9299 - loss: 0.2303 - val_accuracy: 0.6762 - val_loss: 1.8916\n",
      "Epoch 285/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.2274 - val_accuracy: 0.6808 - val_loss: 2.0428\n",
      "Epoch 286/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9292 - loss: 0.2308 - val_accuracy: 0.6830 - val_loss: 1.9086\n",
      "Epoch 287/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9291 - loss: 0.2328 - val_accuracy: 0.6797 - val_loss: 1.9996\n",
      "Epoch 288/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9316 - loss: 0.2256 - val_accuracy: 0.6824 - val_loss: 1.9760\n",
      "Epoch 289/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9322 - loss: 0.2305 - val_accuracy: 0.6804 - val_loss: 1.9106\n",
      "Epoch 290/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9297 - loss: 0.2288 - val_accuracy: 0.6811 - val_loss: 1.9090\n",
      "Epoch 291/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9320 - loss: 0.2243 - val_accuracy: 0.6799 - val_loss: 1.9262\n",
      "Epoch 292/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9329 - loss: 0.2242 - val_accuracy: 0.6811 - val_loss: 1.8616\n",
      "Epoch 293/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9314 - loss: 0.2279 - val_accuracy: 0.6800 - val_loss: 1.9387\n",
      "Epoch 294/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9323 - loss: 0.2217 - val_accuracy: 0.6778 - val_loss: 1.9927\n",
      "Epoch 295/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9301 - loss: 0.2333 - val_accuracy: 0.6806 - val_loss: 1.8908\n",
      "Epoch 296/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9310 - loss: 0.2214 - val_accuracy: 0.6804 - val_loss: 1.9722\n",
      "Epoch 297/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.2230 - val_accuracy: 0.6798 - val_loss: 2.0047\n",
      "Epoch 298/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.2278 - val_accuracy: 0.6793 - val_loss: 1.9772\n",
      "Epoch 299/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9313 - loss: 0.2214 - val_accuracy: 0.6791 - val_loss: 1.8719\n",
      "Epoch 300/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9285 - loss: 0.2361 - val_accuracy: 0.6781 - val_loss: 1.8561\n",
      "Epoch 301/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.2306 - val_accuracy: 0.6802 - val_loss: 1.9687\n",
      "Epoch 302/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9323 - loss: 0.2240 - val_accuracy: 0.6767 - val_loss: 1.9387\n",
      "Epoch 303/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9325 - loss: 0.2252 - val_accuracy: 0.6812 - val_loss: 1.9975\n",
      "Epoch 304/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.2289 - val_accuracy: 0.6847 - val_loss: 1.9839\n",
      "Epoch 305/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9336 - loss: 0.2229 - val_accuracy: 0.6774 - val_loss: 2.0027\n",
      "Epoch 306/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9302 - loss: 0.2342 - val_accuracy: 0.6746 - val_loss: 1.9512\n",
      "Epoch 307/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9314 - loss: 0.2277 - val_accuracy: 0.6793 - val_loss: 2.0756\n",
      "Epoch 308/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.2252 - val_accuracy: 0.6802 - val_loss: 1.8828\n",
      "Epoch 309/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9320 - loss: 0.2273 - val_accuracy: 0.6830 - val_loss: 1.9643\n",
      "Epoch 310/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9322 - loss: 0.2262 - val_accuracy: 0.6813 - val_loss: 2.0599\n",
      "Epoch 311/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9328 - loss: 0.2186 - val_accuracy: 0.6799 - val_loss: 2.0044\n",
      "Epoch 312/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9323 - loss: 0.2265 - val_accuracy: 0.6783 - val_loss: 1.9444\n",
      "Epoch 313/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9309 - loss: 0.2305 - val_accuracy: 0.6811 - val_loss: 2.0075\n",
      "Epoch 314/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9309 - loss: 0.2254 - val_accuracy: 0.6804 - val_loss: 1.9856\n",
      "Epoch 315/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.2217 - val_accuracy: 0.6812 - val_loss: 1.9463\n",
      "Epoch 316/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9347 - loss: 0.2178 - val_accuracy: 0.6779 - val_loss: 1.9842\n",
      "Epoch 317/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9315 - loss: 0.2272 - val_accuracy: 0.6780 - val_loss: 1.9263\n",
      "Epoch 318/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9314 - loss: 0.2278 - val_accuracy: 0.6800 - val_loss: 2.0045\n",
      "Epoch 319/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9330 - loss: 0.2190 - val_accuracy: 0.6792 - val_loss: 1.9705\n",
      "Epoch 320/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9331 - loss: 0.2254 - val_accuracy: 0.6828 - val_loss: 1.8733\n",
      "Epoch 321/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.2223 - val_accuracy: 0.6833 - val_loss: 2.0058\n",
      "Epoch 322/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.2269 - val_accuracy: 0.6825 - val_loss: 1.9939\n",
      "Epoch 323/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9316 - loss: 0.2267 - val_accuracy: 0.6788 - val_loss: 2.1057\n",
      "Epoch 324/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.2257 - val_accuracy: 0.6830 - val_loss: 1.9331\n",
      "Epoch 325/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9332 - loss: 0.2223 - val_accuracy: 0.6805 - val_loss: 1.9782\n",
      "Epoch 326/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.2239 - val_accuracy: 0.6802 - val_loss: 2.0193\n",
      "Epoch 327/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9335 - loss: 0.2210 - val_accuracy: 0.6819 - val_loss: 1.9643\n",
      "Epoch 328/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9322 - loss: 0.2240 - val_accuracy: 0.6818 - val_loss: 1.9504\n",
      "Epoch 329/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9332 - loss: 0.2216 - val_accuracy: 0.6787 - val_loss: 2.0459\n",
      "Epoch 330/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9337 - loss: 0.2257 - val_accuracy: 0.6793 - val_loss: 1.9426\n",
      "Epoch 331/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9331 - loss: 0.2218 - val_accuracy: 0.6791 - val_loss: 1.9445\n",
      "Epoch 332/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9345 - loss: 0.2198 - val_accuracy: 0.6778 - val_loss: 1.9671\n",
      "Epoch 333/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.2228 - val_accuracy: 0.6819 - val_loss: 1.9081\n",
      "Epoch 334/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9312 - loss: 0.2281 - val_accuracy: 0.6818 - val_loss: 1.9039\n",
      "Epoch 335/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.2233 - val_accuracy: 0.6805 - val_loss: 1.9586\n",
      "Epoch 336/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9321 - loss: 0.2240 - val_accuracy: 0.6787 - val_loss: 2.0601\n",
      "Epoch 337/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9341 - loss: 0.2176 - val_accuracy: 0.6807 - val_loss: 1.9831\n",
      "Epoch 338/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9322 - loss: 0.2243 - val_accuracy: 0.6807 - val_loss: 2.0274\n",
      "Epoch 339/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9315 - loss: 0.2270 - val_accuracy: 0.6793 - val_loss: 1.9677\n",
      "Epoch 340/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.2253 - val_accuracy: 0.6808 - val_loss: 1.9763\n",
      "Epoch 341/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9333 - loss: 0.2209 - val_accuracy: 0.6781 - val_loss: 2.0572\n",
      "Epoch 342/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9344 - loss: 0.2196 - val_accuracy: 0.6803 - val_loss: 2.0746\n",
      "Epoch 343/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9317 - loss: 0.2284 - val_accuracy: 0.6781 - val_loss: 1.9194\n",
      "Epoch 344/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9340 - loss: 0.2192 - val_accuracy: 0.6839 - val_loss: 1.9771\n",
      "Epoch 345/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9347 - loss: 0.2187 - val_accuracy: 0.6776 - val_loss: 1.8615\n",
      "Epoch 346/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9326 - loss: 0.2203 - val_accuracy: 0.6834 - val_loss: 1.9706\n",
      "Epoch 347/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9331 - loss: 0.2229 - val_accuracy: 0.6815 - val_loss: 1.9585\n",
      "Epoch 348/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9337 - loss: 0.2216 - val_accuracy: 0.6790 - val_loss: 1.9828\n",
      "Epoch 349/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9325 - loss: 0.2230 - val_accuracy: 0.6852 - val_loss: 1.9595\n",
      "Epoch 350/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.2272 - val_accuracy: 0.6814 - val_loss: 1.9919\n",
      "Epoch 351/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9318 - loss: 0.2261 - val_accuracy: 0.6812 - val_loss: 1.9956\n",
      "Epoch 352/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.2231 - val_accuracy: 0.6767 - val_loss: 2.0581\n",
      "Epoch 353/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9336 - loss: 0.2207 - val_accuracy: 0.6769 - val_loss: 1.9735\n",
      "Epoch 354/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9323 - loss: 0.2237 - val_accuracy: 0.6774 - val_loss: 2.0154\n",
      "Epoch 355/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.2252 - val_accuracy: 0.6800 - val_loss: 1.9318\n",
      "Epoch 356/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9336 - loss: 0.2194 - val_accuracy: 0.6809 - val_loss: 2.0137\n",
      "Epoch 357/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9339 - loss: 0.2196 - val_accuracy: 0.6845 - val_loss: 2.0930\n",
      "Epoch 358/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9340 - loss: 0.2193 - val_accuracy: 0.6819 - val_loss: 1.9836\n",
      "Epoch 359/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.2257 - val_accuracy: 0.6809 - val_loss: 1.9573\n",
      "Epoch 360/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9321 - loss: 0.2236 - val_accuracy: 0.6826 - val_loss: 2.0494\n",
      "Epoch 361/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9352 - loss: 0.2146 - val_accuracy: 0.6813 - val_loss: 1.9323\n",
      "Epoch 362/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.2246 - val_accuracy: 0.6803 - val_loss: 2.0592\n",
      "Epoch 363/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9320 - loss: 0.2254 - val_accuracy: 0.6794 - val_loss: 2.0638\n",
      "Epoch 364/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9355 - loss: 0.2169 - val_accuracy: 0.6821 - val_loss: 2.0351\n",
      "Epoch 365/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9350 - loss: 0.2145 - val_accuracy: 0.6809 - val_loss: 2.0163\n",
      "Epoch 366/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9327 - loss: 0.2235 - val_accuracy: 0.6853 - val_loss: 1.9615\n",
      "Epoch 367/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9326 - loss: 0.2224 - val_accuracy: 0.6844 - val_loss: 1.9753\n",
      "Epoch 368/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9344 - loss: 0.2176 - val_accuracy: 0.6818 - val_loss: 2.0377\n",
      "Epoch 369/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9342 - loss: 0.2236 - val_accuracy: 0.6848 - val_loss: 1.9873\n",
      "Epoch 370/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.2309 - val_accuracy: 0.6834 - val_loss: 2.1047\n",
      "Epoch 371/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9324 - loss: 0.2276 - val_accuracy: 0.6847 - val_loss: 2.0797\n",
      "Epoch 372/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9349 - loss: 0.2211 - val_accuracy: 0.6824 - val_loss: 1.9602\n",
      "Epoch 373/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9325 - loss: 0.2199 - val_accuracy: 0.6821 - val_loss: 1.9567\n",
      "Epoch 374/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9342 - loss: 0.2176 - val_accuracy: 0.6834 - val_loss: 2.0303\n",
      "Epoch 375/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9347 - loss: 0.2193 - val_accuracy: 0.6836 - val_loss: 1.9637\n",
      "Epoch 376/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9324 - loss: 0.2283 - val_accuracy: 0.6799 - val_loss: 2.0750\n",
      "Epoch 377/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9301 - loss: 0.2327 - val_accuracy: 0.6821 - val_loss: 1.9385\n",
      "Epoch 378/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.2218 - val_accuracy: 0.6805 - val_loss: 1.8785\n",
      "Epoch 379/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9337 - loss: 0.2194 - val_accuracy: 0.6795 - val_loss: 1.9677\n",
      "Epoch 380/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9338 - loss: 0.2211 - val_accuracy: 0.6791 - val_loss: 1.9351\n",
      "Epoch 381/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9355 - loss: 0.2161 - val_accuracy: 0.6775 - val_loss: 2.0547\n",
      "Epoch 382/500\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9343 - loss: 0.2237 - val_accuracy: 0.6803 - val_loss: 1.9933\n",
      "Epoch 383/500\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9345 - loss: 0.2176"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)  \n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 14\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(xtrain_sift,y_trainc,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(xtest_sift,y_testc))\n\u001b[0;32m     16\u001b[0m tloss,tacc\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(xtest_sift,y_testc)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtacc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:344\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    335\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    336\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m     )\n\u001b[1;32m--> 344\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    345\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    346\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    347\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    348\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    349\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    350\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    351\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    352\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m )\n\u001b[0;32m    354\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    356\u001b[0m }\n\u001b[0;32m    357\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:432\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    431\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 432\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    433\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(512,activation='relu',input_shape=(128,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5122,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(xtrain_sift,y_trainc,epochs=500,batch_size=600,validation_data=(xtest_sift,y_testc))\n",
    "\n",
    "tloss,tacc=model.evaluate(xtest_sift,y_testc)\n",
    "print(f'test_accuracy:{tacc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgRWq1CZXJgq"
   },
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MSNWZrLXKu5",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "4ae10a78-58fa-4a8f-b475-5c89f41a2e3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12905\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_T38N8CzXNwu"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Jk71AJvkXOku"
   },
   "outputs": [],
   "source": [
    "xtrain2=xtrain/255\n",
    "xtest2=xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "XAYizq0mXPm4",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f2082229-6a12-4b6b-fa34-3376817f0e80",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.7747 - val_accuracy: 0.8403 - val_loss: 0.4423\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.4606 - val_accuracy: 0.8512 - val_loss: 0.4163\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4198 - val_accuracy: 0.8539 - val_loss: 0.3915\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3920 - val_accuracy: 0.8678 - val_loss: 0.3670\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.3704 - val_accuracy: 0.8630 - val_loss: 0.3703\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3651 - val_accuracy: 0.8703 - val_loss: 0.3606\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3552 - val_accuracy: 0.8671 - val_loss: 0.3640\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8763 - loss: 0.3409 - val_accuracy: 0.8773 - val_loss: 0.3514\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.3292 - val_accuracy: 0.8756 - val_loss: 0.3380\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.3277 - val_accuracy: 0.8726 - val_loss: 0.3492\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.3263 - val_accuracy: 0.8808 - val_loss: 0.3417\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.3183 - val_accuracy: 0.8750 - val_loss: 0.3430\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.3147 - val_accuracy: 0.8783 - val_loss: 0.3412\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.3082 - val_accuracy: 0.8844 - val_loss: 0.3305\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.3030 - val_accuracy: 0.8805 - val_loss: 0.3349\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3069 - val_accuracy: 0.8836 - val_loss: 0.3272\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2952 - val_accuracy: 0.8833 - val_loss: 0.3347\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2963 - val_accuracy: 0.8781 - val_loss: 0.3436\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.2942 - val_accuracy: 0.8839 - val_loss: 0.3331\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2907 - val_accuracy: 0.8849 - val_loss: 0.3367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22fa050fa10>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(xtrain2,y_trainc,epochs=20,batch_size=32,validation_data=(xtest2,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzjlFW_8XQtq",
    "outputId": "a911fba3-30a2-429b-869a-e4e9d5c403e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.8848 - loss: 0.3350\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VKYWVMDIE7M",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combination 2: change the hyperparameter to LR  = 0.1 ; batch size =4  optimizer = SGD , activation function. = sigmoid and the loss function is MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "8acaddKiIH5e",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "SqO7jrhZIK1-"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.1),loss='mae',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JVGoFBzdIMvO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fd54f7f5-03c2-496a-8193-45e749bb9e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 876us/step - accuracy: 0.1205 - loss: 0.1769 - val_accuracy: 0.1994 - val_loss: 0.1592\n",
      "Epoch 2/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 859us/step - accuracy: 0.2506 - loss: 0.1532 - val_accuracy: 0.2870 - val_loss: 0.1435\n",
      "Epoch 3/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 851us/step - accuracy: 0.2845 - loss: 0.1442 - val_accuracy: 0.2934 - val_loss: 0.1416\n",
      "Epoch 4/4\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 849us/step - accuracy: 0.2924 - loss: 0.1420 - val_accuracy: 0.2950 - val_loss: 0.1412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22fa095d8b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(xtrain2,y_trainc,epochs=4,batch_size=4,validation_data=(xtest2,y_testc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trNzMP6pIPGH",
    "outputId": "93e3f80d-8b5d-4dab-f63e-c389ba6aa1f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.2997 - loss: 0.1403\n"
     ]
    }
   ],
   "source": [
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S3a7mZBJTYW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### combination 3: tanh , rmsprop, 16, 0.01, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCN1YU8hJeKk",
    "outputId": "ee77639d-bdaf-4805-e543-121e46fa8ec0"
   },
   "outputs": [],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='tanh'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='tanh'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='tanh'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "48pgGDCXJeAV"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer= RMSprop(learning_rate=0.01),loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMJigF8HKOkC",
    "outputId": "8b43704e-328e-44f7-ea0f-4601a92a4110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3690 - loss: 0.0895 - val_accuracy: 0.4965 - val_loss: 0.0669\n",
      "Epoch 2/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: 0.0694 - val_accuracy: 0.5398 - val_loss: 0.0630\n",
      "Epoch 3/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5192 - loss: 0.0684 - val_accuracy: 0.5283 - val_loss: 0.0696\n",
      "Epoch 4/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.5260 - loss: 0.0676 - val_accuracy: 0.5579 - val_loss: 0.0647\n",
      "Epoch 5/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5195 - loss: 0.0687 - val_accuracy: 0.5369 - val_loss: 0.0650\n",
      "Epoch 6/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5188 - loss: 0.0682 - val_accuracy: 0.5361 - val_loss: 0.0691\n",
      "Epoch 7/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.5252 - loss: 0.0680 - val_accuracy: 0.4498 - val_loss: 0.0679\n",
      "Epoch 8/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.0675 - val_accuracy: 0.5359 - val_loss: 0.0634\n",
      "Epoch 9/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5320 - loss: 0.0672 - val_accuracy: 0.5481 - val_loss: 0.0613\n",
      "Epoch 10/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5309 - loss: 0.0673 - val_accuracy: 0.5791 - val_loss: 0.0589\n",
      "Epoch 11/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5377 - loss: 0.0667 - val_accuracy: 0.5878 - val_loss: 0.0573\n",
      "Epoch 12/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5308 - loss: 0.0673 - val_accuracy: 0.5577 - val_loss: 0.0637\n",
      "Epoch 13/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5369 - loss: 0.0667 - val_accuracy: 0.5644 - val_loss: 0.0586\n",
      "Epoch 14/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.0666 - val_accuracy: 0.5489 - val_loss: 0.0659\n",
      "Epoch 15/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5365 - loss: 0.0662 - val_accuracy: 0.5808 - val_loss: 0.0607\n",
      "Epoch 16/16\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.5302 - loss: 0.0677 - val_accuracy: 0.5540 - val_loss: 0.0617\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.5534 - loss: 0.0618\n"
     ]
    }
   ],
   "source": [
    "model2.fit(xtrain2,y_trainc,epochs=16,batch_size=16,validation_data=(xtest2,y_testc))\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3no0gEN8JZX_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### combination 4: 0.001 , batch 8 , sgd , sigmoid, huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8z4g5uEJerg",
    "outputId": "6b944097-47f2-4b1d-c993-029a5dddce1c"
   },
   "outputs": [],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='sigmoid'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "G2JIlRtVJekK"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001),loss=tf.keras.losses.Huber(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGaC0uINKO2u",
    "outputId": "ec8ae0b7-df25-49aa-9914-2176446b67bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 953us/step - accuracy: 0.1027 - loss: 0.0469 - val_accuracy: 0.0991 - val_loss: 0.0454\n",
      "Epoch 2/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 946us/step - accuracy: 0.1002 - loss: 0.0464 - val_accuracy: 0.0987 - val_loss: 0.0452\n",
      "Epoch 3/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 957us/step - accuracy: 0.1007 - loss: 0.0462 - val_accuracy: 0.0975 - val_loss: 0.0451\n",
      "Epoch 4/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 971us/step - accuracy: 0.0975 - loss: 0.0462 - val_accuracy: 0.0984 - val_loss: 0.0451\n",
      "Epoch 5/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973us/step - accuracy: 0.0954 - loss: 0.0462 - val_accuracy: 0.1012 - val_loss: 0.0450\n",
      "Epoch 6/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 0.0461 - val_accuracy: 0.1193 - val_loss: 0.0450\n",
      "Epoch 7/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 0.0461 - val_accuracy: 0.1430 - val_loss: 0.0450\n",
      "Epoch 8/8\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.0980 - loss: 0.0461 - val_accuracy: 0.1451 - val_loss: 0.0450\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.1437 - loss: 0.0450\n"
     ]
    }
   ],
   "source": [
    "model2.fit(xtrain2,y_trainc,epochs=8,batch_size=8,validation_data=(xtest2,y_testc))\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is for tuneing for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# load dataset\n",
    "data=tf.keras.datasets.fashion_mnist\n",
    "(xtrain,ytrain),(xtest,ytest)=data.load_data()\n",
    "y_trainc=to_categorical(ytrain,10)\n",
    "y_testc=to_categorical(ytest,10)\n",
    "xtrain2=xtrain/255\n",
    "xtest2=xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.7783 - val_accuracy: 0.8297 - val_loss: 0.4672\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.4546 - val_accuracy: 0.8568 - val_loss: 0.3920\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4174 - val_accuracy: 0.8546 - val_loss: 0.3936\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3965 - val_accuracy: 0.8597 - val_loss: 0.3820\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.3786 - val_accuracy: 0.8656 - val_loss: 0.3799\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3708 - val_accuracy: 0.8590 - val_loss: 0.3763\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3613 - val_accuracy: 0.8673 - val_loss: 0.3628\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3477 - val_accuracy: 0.8657 - val_loss: 0.3652\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.3357 - val_accuracy: 0.8771 - val_loss: 0.3375\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3289 - val_accuracy: 0.8754 - val_loss: 0.3522\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.3230 - val_accuracy: 0.8828 - val_loss: 0.3352\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3189 - val_accuracy: 0.8730 - val_loss: 0.3504\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3221 - val_accuracy: 0.8744 - val_loss: 0.3519\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.3135 - val_accuracy: 0.8843 - val_loss: 0.3310\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3035 - val_accuracy: 0.8791 - val_loss: 0.3350\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.3005 - val_accuracy: 0.8859 - val_loss: 0.3295\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.3049 - val_accuracy: 0.8845 - val_loss: 0.3327\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2960 - val_accuracy: 0.8807 - val_loss: 0.3348\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2934 - val_accuracy: 0.8824 - val_loss: 0.3368\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2922 - val_accuracy: 0.8835 - val_loss: 0.3213\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2922 - val_accuracy: 0.8906 - val_loss: 0.3236\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2793 - val_accuracy: 0.8874 - val_loss: 0.3272\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2878 - val_accuracy: 0.8809 - val_loss: 0.3354\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2810 - val_accuracy: 0.8864 - val_loss: 0.3276\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.2726 - val_accuracy: 0.8862 - val_loss: 0.3291\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.2789 - val_accuracy: 0.8870 - val_loss: 0.3370\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2756 - val_accuracy: 0.8880 - val_loss: 0.3396\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2684 - val_accuracy: 0.8848 - val_loss: 0.3339\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2741 - val_accuracy: 0.8872 - val_loss: 0.3316\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2650 - val_accuracy: 0.8853 - val_loss: 0.3442\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2680 - val_accuracy: 0.8874 - val_loss: 0.3463\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2626 - val_accuracy: 0.8910 - val_loss: 0.3344\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8902 - loss: 0.3370\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=32,batch_size=32,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.7078 - val_accuracy: 0.8391 - val_loss: 0.4465\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.4238 - val_accuracy: 0.8352 - val_loss: 0.4754\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.3859 - val_accuracy: 0.8609 - val_loss: 0.3869\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3589 - val_accuracy: 0.8607 - val_loss: 0.3886\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.3506 - val_accuracy: 0.8672 - val_loss: 0.3736\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.3303 - val_accuracy: 0.8674 - val_loss: 0.3589\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3168 - val_accuracy: 0.8664 - val_loss: 0.3649\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3158 - val_accuracy: 0.8799 - val_loss: 0.3319\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3033 - val_accuracy: 0.8806 - val_loss: 0.3228\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.2950 - val_accuracy: 0.8792 - val_loss: 0.3303\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.2883 - val_accuracy: 0.8812 - val_loss: 0.3254\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2803 - val_accuracy: 0.8844 - val_loss: 0.3221\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2794 - val_accuracy: 0.8828 - val_loss: 0.3281\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2734 - val_accuracy: 0.8867 - val_loss: 0.3229\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2692 - val_accuracy: 0.8842 - val_loss: 0.3245\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2672 - val_accuracy: 0.8825 - val_loss: 0.3339\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2663 - val_accuracy: 0.8822 - val_loss: 0.3362\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2568 - val_accuracy: 0.8892 - val_loss: 0.3188\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2548 - val_accuracy: 0.8870 - val_loss: 0.3309\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2504 - val_accuracy: 0.8840 - val_loss: 0.3237\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.8829 - loss: 0.3203\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=20,batch_size=32,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.6892 - val_accuracy: 0.8403 - val_loss: 0.4392\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.4300 - val_accuracy: 0.8483 - val_loss: 0.4385\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3894 - val_accuracy: 0.8592 - val_loss: 0.3850\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3568 - val_accuracy: 0.8732 - val_loss: 0.3572\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3485 - val_accuracy: 0.8692 - val_loss: 0.3580\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.3357 - val_accuracy: 0.8743 - val_loss: 0.3485\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.3163 - val_accuracy: 0.8760 - val_loss: 0.3561\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3087 - val_accuracy: 0.8765 - val_loss: 0.3428\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.3074 - val_accuracy: 0.8789 - val_loss: 0.3372\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2985 - val_accuracy: 0.8888 - val_loss: 0.3254\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.2849 - val_accuracy: 0.8820 - val_loss: 0.3421\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2811 - val_accuracy: 0.8792 - val_loss: 0.3399\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2819 - val_accuracy: 0.8880 - val_loss: 0.3244\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2771 - val_accuracy: 0.8803 - val_loss: 0.3377\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2656 - val_accuracy: 0.8871 - val_loss: 0.3160\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2659 - val_accuracy: 0.8874 - val_loss: 0.3233\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2654 - val_accuracy: 0.8897 - val_loss: 0.3323\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2646 - val_accuracy: 0.8884 - val_loss: 0.3243\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2547 - val_accuracy: 0.8902 - val_loss: 0.3276\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2571 - val_accuracy: 0.8888 - val_loss: 0.3241\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2437 - val_accuracy: 0.8845 - val_loss: 0.3388\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2397 - val_accuracy: 0.8889 - val_loss: 0.3331\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2424 - val_accuracy: 0.8807 - val_loss: 0.3579\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2432 - val_accuracy: 0.8892 - val_loss: 0.3391\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2435 - val_accuracy: 0.8881 - val_loss: 0.3292\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2361 - val_accuracy: 0.8869 - val_loss: 0.3570\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2447 - val_accuracy: 0.8891 - val_loss: 0.3590\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2315 - val_accuracy: 0.8929 - val_loss: 0.3379\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2361 - val_accuracy: 0.8893 - val_loss: 0.3474\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2249 - val_accuracy: 0.8883 - val_loss: 0.3475\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2228 - val_accuracy: 0.8825 - val_loss: 0.3539\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2225 - val_accuracy: 0.8900 - val_loss: 0.3517\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8899 - loss: 0.3382\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=32,batch_size=32,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7130 - loss: 0.7950 - val_accuracy: 0.8302 - val_loss: 0.4646\n",
      "Epoch 2/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8423 - loss: 0.4429 - val_accuracy: 0.8561 - val_loss: 0.3986\n",
      "Epoch 3/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8578 - loss: 0.4017 - val_accuracy: 0.8602 - val_loss: 0.3838\n",
      "Epoch 4/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3757 - val_accuracy: 0.8684 - val_loss: 0.3685\n",
      "Epoch 5/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8712 - loss: 0.3557 - val_accuracy: 0.8680 - val_loss: 0.3701\n",
      "Epoch 6/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.3467 - val_accuracy: 0.8759 - val_loss: 0.3530\n",
      "Epoch 7/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.3307 - val_accuracy: 0.8744 - val_loss: 0.3526\n",
      "Epoch 8/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.3213 - val_accuracy: 0.8732 - val_loss: 0.3538\n",
      "Epoch 9/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8859 - loss: 0.3155 - val_accuracy: 0.8749 - val_loss: 0.3534\n",
      "Epoch 10/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.3150 - val_accuracy: 0.8765 - val_loss: 0.3471\n",
      "Epoch 11/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8864 - loss: 0.3051 - val_accuracy: 0.8815 - val_loss: 0.3427\n",
      "Epoch 12/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.2971 - val_accuracy: 0.8802 - val_loss: 0.3404\n",
      "Epoch 13/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.2925 - val_accuracy: 0.8856 - val_loss: 0.3363\n",
      "Epoch 14/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8941 - loss: 0.2896 - val_accuracy: 0.8836 - val_loss: 0.3241\n",
      "Epoch 15/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.2825 - val_accuracy: 0.8841 - val_loss: 0.3300\n",
      "Epoch 16/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2781 - val_accuracy: 0.8806 - val_loss: 0.3346\n",
      "Epoch 17/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2767 - val_accuracy: 0.8836 - val_loss: 0.3328\n",
      "Epoch 18/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.2698 - val_accuracy: 0.8861 - val_loss: 0.3312\n",
      "Epoch 19/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.2648 - val_accuracy: 0.8887 - val_loss: 0.3283\n",
      "Epoch 20/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.2679 - val_accuracy: 0.8903 - val_loss: 0.3243\n",
      "Epoch 21/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2555 - val_accuracy: 0.8844 - val_loss: 0.3427\n",
      "Epoch 22/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2615 - val_accuracy: 0.8892 - val_loss: 0.3336\n",
      "Epoch 23/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2505 - val_accuracy: 0.8897 - val_loss: 0.3402\n",
      "Epoch 24/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2555 - val_accuracy: 0.8875 - val_loss: 0.3425\n",
      "Epoch 25/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2513 - val_accuracy: 0.8893 - val_loss: 0.3305\n",
      "Epoch 26/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2516 - val_accuracy: 0.8883 - val_loss: 0.3275\n",
      "Epoch 27/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2418 - val_accuracy: 0.8898 - val_loss: 0.3414\n",
      "Epoch 28/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2371 - val_accuracy: 0.8892 - val_loss: 0.3338\n",
      "Epoch 29/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2422 - val_accuracy: 0.8911 - val_loss: 0.3389\n",
      "Epoch 30/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2397 - val_accuracy: 0.8887 - val_loss: 0.3485\n",
      "Epoch 31/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2404 - val_accuracy: 0.8933 - val_loss: 0.3280\n",
      "Epoch 32/32\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2323 - val_accuracy: 0.8948 - val_loss: 0.3306\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8938 - loss: 0.3337\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=32,batch_size=32,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8188 - val_accuracy: 0.8471 - val_loss: 0.4356\n",
      "Epoch 2/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8425 - loss: 0.4401 - val_accuracy: 0.8547 - val_loss: 0.3976\n",
      "Epoch 3/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3993 - val_accuracy: 0.8565 - val_loss: 0.3877\n",
      "Epoch 4/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.3685 - val_accuracy: 0.8675 - val_loss: 0.3623\n",
      "Epoch 5/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.3506 - val_accuracy: 0.8757 - val_loss: 0.3474\n",
      "Epoch 6/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.3424 - val_accuracy: 0.8754 - val_loss: 0.3460\n",
      "Epoch 7/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3287 - val_accuracy: 0.8785 - val_loss: 0.3457\n",
      "Epoch 8/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8845 - loss: 0.3183 - val_accuracy: 0.8776 - val_loss: 0.3412\n",
      "Epoch 9/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8880 - loss: 0.3075 - val_accuracy: 0.8776 - val_loss: 0.3494\n",
      "Epoch 10/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.3058 - val_accuracy: 0.8778 - val_loss: 0.3486\n",
      "Epoch 11/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2928 - val_accuracy: 0.8788 - val_loss: 0.3359\n",
      "Epoch 12/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2844 - val_accuracy: 0.8824 - val_loss: 0.3310\n",
      "Epoch 13/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.2856 - val_accuracy: 0.8825 - val_loss: 0.3284\n",
      "Epoch 14/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2754 - val_accuracy: 0.8797 - val_loss: 0.3269\n",
      "Epoch 15/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2738 - val_accuracy: 0.8882 - val_loss: 0.3225\n",
      "Epoch 16/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2690 - val_accuracy: 0.8871 - val_loss: 0.3265\n",
      "Epoch 17/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9026 - loss: 0.2640 - val_accuracy: 0.8845 - val_loss: 0.3277\n",
      "Epoch 18/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2585 - val_accuracy: 0.8873 - val_loss: 0.3336\n",
      "Epoch 19/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2560 - val_accuracy: 0.8869 - val_loss: 0.3201\n",
      "Epoch 20/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2528 - val_accuracy: 0.8891 - val_loss: 0.3177\n",
      "Epoch 21/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2505 - val_accuracy: 0.8902 - val_loss: 0.3219\n",
      "Epoch 22/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2410 - val_accuracy: 0.8855 - val_loss: 0.3247\n",
      "Epoch 23/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2419 - val_accuracy: 0.8874 - val_loss: 0.3340\n",
      "Epoch 24/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2384 - val_accuracy: 0.8906 - val_loss: 0.3249\n",
      "Epoch 25/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2341 - val_accuracy: 0.8855 - val_loss: 0.3282\n",
      "Epoch 26/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2307 - val_accuracy: 0.8904 - val_loss: 0.3228\n",
      "Epoch 27/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2328 - val_accuracy: 0.8867 - val_loss: 0.3215\n",
      "Epoch 28/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2305 - val_accuracy: 0.8914 - val_loss: 0.3160\n",
      "Epoch 29/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2278 - val_accuracy: 0.8877 - val_loss: 0.3373\n",
      "Epoch 30/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2210 - val_accuracy: 0.8933 - val_loss: 0.3158\n",
      "Epoch 31/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2197 - val_accuracy: 0.8893 - val_loss: 0.3221\n",
      "Epoch 32/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2204 - val_accuracy: 0.8904 - val_loss: 0.3172\n",
      "Epoch 33/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2171 - val_accuracy: 0.8931 - val_loss: 0.3208\n",
      "Epoch 34/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2145 - val_accuracy: 0.8914 - val_loss: 0.3256\n",
      "Epoch 35/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2105 - val_accuracy: 0.8914 - val_loss: 0.3290\n",
      "Epoch 36/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9207 - loss: 0.2087 - val_accuracy: 0.8931 - val_loss: 0.3224\n",
      "Epoch 37/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2075 - val_accuracy: 0.8943 - val_loss: 0.3277\n",
      "Epoch 38/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2059 - val_accuracy: 0.8927 - val_loss: 0.3300\n",
      "Epoch 39/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2018 - val_accuracy: 0.8869 - val_loss: 0.3438\n",
      "Epoch 40/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2020 - val_accuracy: 0.8936 - val_loss: 0.3451\n",
      "Epoch 41/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2050 - val_accuracy: 0.8935 - val_loss: 0.3359\n",
      "Epoch 42/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.1996 - val_accuracy: 0.8914 - val_loss: 0.3396\n",
      "Epoch 43/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.1988 - val_accuracy: 0.8928 - val_loss: 0.3328\n",
      "Epoch 44/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.1972 - val_accuracy: 0.8951 - val_loss: 0.3311\n",
      "Epoch 45/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.1959 - val_accuracy: 0.8936 - val_loss: 0.3412\n",
      "Epoch 46/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.1929 - val_accuracy: 0.8942 - val_loss: 0.3384\n",
      "Epoch 47/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.1922 - val_accuracy: 0.8931 - val_loss: 0.3221\n",
      "Epoch 48/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.1888 - val_accuracy: 0.8917 - val_loss: 0.3343\n",
      "Epoch 49/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.1907 - val_accuracy: 0.8937 - val_loss: 0.3312\n",
      "Epoch 50/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.1899 - val_accuracy: 0.8912 - val_loss: 0.3300\n",
      "Epoch 51/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.1851 - val_accuracy: 0.8949 - val_loss: 0.3413\n",
      "Epoch 52/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1866 - val_accuracy: 0.8941 - val_loss: 0.3398\n",
      "Epoch 53/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1838 - val_accuracy: 0.8946 - val_loss: 0.3319\n",
      "Epoch 54/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.1806 - val_accuracy: 0.8909 - val_loss: 0.3540\n",
      "Epoch 55/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1836 - val_accuracy: 0.8959 - val_loss: 0.3467\n",
      "Epoch 56/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.1767 - val_accuracy: 0.8947 - val_loss: 0.3479\n",
      "Epoch 57/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1768 - val_accuracy: 0.8949 - val_loss: 0.3416\n",
      "Epoch 58/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.1784 - val_accuracy: 0.8928 - val_loss: 0.3603\n",
      "Epoch 59/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1790 - val_accuracy: 0.8957 - val_loss: 0.3395\n",
      "Epoch 60/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.1761 - val_accuracy: 0.8955 - val_loss: 0.3519\n",
      "Epoch 61/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.1792 - val_accuracy: 0.8943 - val_loss: 0.3516\n",
      "Epoch 62/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.1738 - val_accuracy: 0.8938 - val_loss: 0.3532\n",
      "Epoch 63/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1749 - val_accuracy: 0.8956 - val_loss: 0.3432\n",
      "Epoch 64/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.1757 - val_accuracy: 0.8925 - val_loss: 0.3620\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8924 - loss: 0.3702\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=64,batch_size=64,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6902 - loss: 0.8846 - val_accuracy: 0.8444 - val_loss: 0.4268\n",
      "Epoch 2/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.4562 - val_accuracy: 0.8560 - val_loss: 0.4012\n",
      "Epoch 3/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 0.4069 - val_accuracy: 0.8607 - val_loss: 0.3815\n",
      "Epoch 4/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.3764 - val_accuracy: 0.8554 - val_loss: 0.4001\n",
      "Epoch 5/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8695 - loss: 0.3627 - val_accuracy: 0.8661 - val_loss: 0.3665\n",
      "Epoch 6/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.3454 - val_accuracy: 0.8747 - val_loss: 0.3524\n",
      "Epoch 7/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8793 - loss: 0.3370 - val_accuracy: 0.8666 - val_loss: 0.3618\n",
      "Epoch 8/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.3319 - val_accuracy: 0.8803 - val_loss: 0.3392\n",
      "Epoch 9/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8846 - loss: 0.3207 - val_accuracy: 0.8781 - val_loss: 0.3525\n",
      "Epoch 10/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3073 - val_accuracy: 0.8717 - val_loss: 0.3573\n",
      "Epoch 11/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8906 - loss: 0.3030 - val_accuracy: 0.8849 - val_loss: 0.3284\n",
      "Epoch 12/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.2918 - val_accuracy: 0.8843 - val_loss: 0.3292\n",
      "Epoch 13/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.2864 - val_accuracy: 0.8793 - val_loss: 0.3367\n",
      "Epoch 14/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.2898 - val_accuracy: 0.8885 - val_loss: 0.3224\n",
      "Epoch 15/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.2788 - val_accuracy: 0.8842 - val_loss: 0.3304\n",
      "Epoch 16/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2739 - val_accuracy: 0.8831 - val_loss: 0.3309\n",
      "Epoch 17/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.2746 - val_accuracy: 0.8850 - val_loss: 0.3320\n",
      "Epoch 18/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.2737 - val_accuracy: 0.8797 - val_loss: 0.3607\n",
      "Epoch 19/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.2638 - val_accuracy: 0.8772 - val_loss: 0.3425\n",
      "Epoch 20/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2560 - val_accuracy: 0.8890 - val_loss: 0.3234\n",
      "Epoch 21/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2551 - val_accuracy: 0.8867 - val_loss: 0.3208\n",
      "Epoch 22/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.2470 - val_accuracy: 0.8902 - val_loss: 0.3188\n",
      "Epoch 23/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.2484 - val_accuracy: 0.8832 - val_loss: 0.3533\n",
      "Epoch 24/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2493 - val_accuracy: 0.8880 - val_loss: 0.3324\n",
      "Epoch 25/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2436 - val_accuracy: 0.8918 - val_loss: 0.3254\n",
      "Epoch 26/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2439 - val_accuracy: 0.8860 - val_loss: 0.3317\n",
      "Epoch 27/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2343 - val_accuracy: 0.8916 - val_loss: 0.3147\n",
      "Epoch 28/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2405 - val_accuracy: 0.8950 - val_loss: 0.3269\n",
      "Epoch 29/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2305 - val_accuracy: 0.8900 - val_loss: 0.3377\n",
      "Epoch 30/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2332 - val_accuracy: 0.8870 - val_loss: 0.3436\n",
      "Epoch 31/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2292 - val_accuracy: 0.8895 - val_loss: 0.3382\n",
      "Epoch 32/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2228 - val_accuracy: 0.8853 - val_loss: 0.3365\n",
      "Epoch 33/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2260 - val_accuracy: 0.8891 - val_loss: 0.3398\n",
      "Epoch 34/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2278 - val_accuracy: 0.8874 - val_loss: 0.3395\n",
      "Epoch 35/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2187 - val_accuracy: 0.8941 - val_loss: 0.3288\n",
      "Epoch 36/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2199 - val_accuracy: 0.8908 - val_loss: 0.3354\n",
      "Epoch 37/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2166 - val_accuracy: 0.8910 - val_loss: 0.3289\n",
      "Epoch 38/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2095 - val_accuracy: 0.8944 - val_loss: 0.3234\n",
      "Epoch 39/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9210 - loss: 0.2132 - val_accuracy: 0.8937 - val_loss: 0.3320\n",
      "Epoch 40/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2069 - val_accuracy: 0.8910 - val_loss: 0.3292\n",
      "Epoch 41/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2090 - val_accuracy: 0.8962 - val_loss: 0.3341\n",
      "Epoch 42/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2038 - val_accuracy: 0.8925 - val_loss: 0.3378\n",
      "Epoch 43/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2036 - val_accuracy: 0.8951 - val_loss: 0.3316\n",
      "Epoch 44/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2049 - val_accuracy: 0.8918 - val_loss: 0.3370\n",
      "Epoch 45/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.1975 - val_accuracy: 0.8934 - val_loss: 0.3241\n",
      "Epoch 46/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2057 - val_accuracy: 0.8926 - val_loss: 0.3471\n",
      "Epoch 47/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2038 - val_accuracy: 0.8949 - val_loss: 0.3338\n",
      "Epoch 48/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.1918 - val_accuracy: 0.8915 - val_loss: 0.3502\n",
      "Epoch 49/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2010 - val_accuracy: 0.8942 - val_loss: 0.3418\n",
      "Epoch 50/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.1923 - val_accuracy: 0.8953 - val_loss: 0.3472\n",
      "Epoch 51/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1941 - val_accuracy: 0.8950 - val_loss: 0.3350\n",
      "Epoch 52/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.1854 - val_accuracy: 0.8975 - val_loss: 0.3462\n",
      "Epoch 53/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1923 - val_accuracy: 0.8952 - val_loss: 0.3509\n",
      "Epoch 54/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.1926 - val_accuracy: 0.8931 - val_loss: 0.3490\n",
      "Epoch 55/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9318 - loss: 0.1854 - val_accuracy: 0.8897 - val_loss: 0.3671\n",
      "Epoch 56/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1828 - val_accuracy: 0.8864 - val_loss: 0.3355\n",
      "Epoch 57/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.1846 - val_accuracy: 0.8950 - val_loss: 0.3656\n",
      "Epoch 58/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1836 - val_accuracy: 0.8923 - val_loss: 0.3573\n",
      "Epoch 59/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1821 - val_accuracy: 0.8966 - val_loss: 0.3398\n",
      "Epoch 60/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9317 - loss: 0.1846 - val_accuracy: 0.8976 - val_loss: 0.3535\n",
      "Epoch 61/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1810 - val_accuracy: 0.8928 - val_loss: 0.3529\n",
      "Epoch 62/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1834 - val_accuracy: 0.8959 - val_loss: 0.3464\n",
      "Epoch 63/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.1796 - val_accuracy: 0.8947 - val_loss: 0.3462\n",
      "Epoch 64/64\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.1768 - val_accuracy: 0.8972 - val_loss: 0.3539\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8970 - loss: 0.3683\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=64,batch_size=64,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6346 - loss: 1.0560 - val_accuracy: 0.8359 - val_loss: 0.4616\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8259 - loss: 0.4970 - val_accuracy: 0.8556 - val_loss: 0.4151\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.4459 - val_accuracy: 0.8624 - val_loss: 0.3876\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8537 - loss: 0.4096 - val_accuracy: 0.8646 - val_loss: 0.3768\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8620 - loss: 0.3914 - val_accuracy: 0.8696 - val_loss: 0.3678\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.3730 - val_accuracy: 0.8683 - val_loss: 0.3703\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8701 - loss: 0.3625 - val_accuracy: 0.8727 - val_loss: 0.3514\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8768 - loss: 0.3494 - val_accuracy: 0.8707 - val_loss: 0.3525\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.3480 - val_accuracy: 0.8745 - val_loss: 0.3521\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.3342 - val_accuracy: 0.8777 - val_loss: 0.3435\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3279 - val_accuracy: 0.8750 - val_loss: 0.3442\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.3198 - val_accuracy: 0.8798 - val_loss: 0.3396\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8917 - loss: 0.3058 - val_accuracy: 0.8772 - val_loss: 0.3434\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8909 - loss: 0.3073 - val_accuracy: 0.8778 - val_loss: 0.3414\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8886 - loss: 0.3088 - val_accuracy: 0.8826 - val_loss: 0.3310\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.2974 - val_accuracy: 0.8834 - val_loss: 0.3275\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2886 - val_accuracy: 0.8792 - val_loss: 0.3352\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.2961 - val_accuracy: 0.8834 - val_loss: 0.3290\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2833 - val_accuracy: 0.8802 - val_loss: 0.3383\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.2903 - val_accuracy: 0.8852 - val_loss: 0.3303\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2810 - val_accuracy: 0.8856 - val_loss: 0.3296\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2841 - val_accuracy: 0.8802 - val_loss: 0.3403\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.2766 - val_accuracy: 0.8889 - val_loss: 0.3227\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.2748 - val_accuracy: 0.8844 - val_loss: 0.3252\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.2653 - val_accuracy: 0.8853 - val_loss: 0.3208\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.2705 - val_accuracy: 0.8828 - val_loss: 0.3353\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.2723 - val_accuracy: 0.8881 - val_loss: 0.3208\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2599 - val_accuracy: 0.8874 - val_loss: 0.3181\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2585 - val_accuracy: 0.8862 - val_loss: 0.3349\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.2633 - val_accuracy: 0.8867 - val_loss: 0.3256\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2609 - val_accuracy: 0.8877 - val_loss: 0.3332\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2554 - val_accuracy: 0.8789 - val_loss: 0.3433\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2590 - val_accuracy: 0.8885 - val_loss: 0.3195\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2509 - val_accuracy: 0.8864 - val_loss: 0.3252\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2466 - val_accuracy: 0.8865 - val_loss: 0.3262\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2453 - val_accuracy: 0.8855 - val_loss: 0.3278\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2418 - val_accuracy: 0.8877 - val_loss: 0.3213\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2453 - val_accuracy: 0.8868 - val_loss: 0.3357\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2426 - val_accuracy: 0.8857 - val_loss: 0.3283\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2382 - val_accuracy: 0.8918 - val_loss: 0.3228\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2380 - val_accuracy: 0.8867 - val_loss: 0.3329\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2374 - val_accuracy: 0.8909 - val_loss: 0.3295\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2338 - val_accuracy: 0.8886 - val_loss: 0.3367\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2409 - val_accuracy: 0.8905 - val_loss: 0.3269\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2257 - val_accuracy: 0.8926 - val_loss: 0.3306\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2299 - val_accuracy: 0.8842 - val_loss: 0.3378\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2307 - val_accuracy: 0.8889 - val_loss: 0.3327\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2228 - val_accuracy: 0.8887 - val_loss: 0.3309\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2269 - val_accuracy: 0.8888 - val_loss: 0.3340\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2228 - val_accuracy: 0.8892 - val_loss: 0.3343\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2177 - val_accuracy: 0.8887 - val_loss: 0.3302\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2210 - val_accuracy: 0.8910 - val_loss: 0.3358\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2278 - val_accuracy: 0.8877 - val_loss: 0.3480\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2248 - val_accuracy: 0.8864 - val_loss: 0.3490\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2230 - val_accuracy: 0.8936 - val_loss: 0.3244\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2159 - val_accuracy: 0.8919 - val_loss: 0.3321\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2154 - val_accuracy: 0.8906 - val_loss: 0.3357\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2265 - val_accuracy: 0.8904 - val_loss: 0.3392\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.2137 - val_accuracy: 0.8903 - val_loss: 0.3339\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2126 - val_accuracy: 0.8910 - val_loss: 0.3377\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2108 - val_accuracy: 0.8886 - val_loss: 0.3354\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2182 - val_accuracy: 0.8906 - val_loss: 0.3308\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2117 - val_accuracy: 0.8881 - val_loss: 0.3451\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2089 - val_accuracy: 0.8922 - val_loss: 0.3362\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2113 - val_accuracy: 0.8888 - val_loss: 0.3538\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9223 - loss: 0.2086 - val_accuracy: 0.8930 - val_loss: 0.3289\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2093 - val_accuracy: 0.8919 - val_loss: 0.3326\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.2067 - val_accuracy: 0.8910 - val_loss: 0.3464\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2070 - val_accuracy: 0.8908 - val_loss: 0.3411\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2039 - val_accuracy: 0.8911 - val_loss: 0.3388\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2040 - val_accuracy: 0.8880 - val_loss: 0.3489\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2055 - val_accuracy: 0.8916 - val_loss: 0.3575\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2063 - val_accuracy: 0.8885 - val_loss: 0.3496\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2035 - val_accuracy: 0.8889 - val_loss: 0.3458\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1971 - val_accuracy: 0.8889 - val_loss: 0.3530\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.1988 - val_accuracy: 0.8911 - val_loss: 0.3462\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2019 - val_accuracy: 0.8896 - val_loss: 0.3411\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.1985 - val_accuracy: 0.8891 - val_loss: 0.3606\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1962 - val_accuracy: 0.8915 - val_loss: 0.3487\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.1962 - val_accuracy: 0.8912 - val_loss: 0.3641\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1958 - val_accuracy: 0.8927 - val_loss: 0.3439\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9310 - loss: 0.1893 - val_accuracy: 0.8925 - val_loss: 0.3473\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1912 - val_accuracy: 0.8944 - val_loss: 0.3510\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.1956 - val_accuracy: 0.8896 - val_loss: 0.3623\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1974 - val_accuracy: 0.8912 - val_loss: 0.3529\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1923 - val_accuracy: 0.8944 - val_loss: 0.3404\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1913 - val_accuracy: 0.8940 - val_loss: 0.3484\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1887 - val_accuracy: 0.8913 - val_loss: 0.3546\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.1855 - val_accuracy: 0.8941 - val_loss: 0.3389\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.1863 - val_accuracy: 0.8898 - val_loss: 0.3581\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1895 - val_accuracy: 0.8909 - val_loss: 0.3659\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.1929 - val_accuracy: 0.8928 - val_loss: 0.3573\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1900 - val_accuracy: 0.8942 - val_loss: 0.3604\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9363 - loss: 0.1767 - val_accuracy: 0.8895 - val_loss: 0.3715\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.1839 - val_accuracy: 0.8856 - val_loss: 0.3813\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1873 - val_accuracy: 0.8899 - val_loss: 0.3764\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.1926 - val_accuracy: 0.8927 - val_loss: 0.3718\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9346 - loss: 0.1793 - val_accuracy: 0.8920 - val_loss: 0.3525\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1825 - val_accuracy: 0.8882 - val_loss: 0.3796\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.1887 - val_accuracy: 0.8938 - val_loss: 0.3513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8926 - loss: 0.3658\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6484 - loss: 0.9955 - val_accuracy: 0.8303 - val_loss: 0.4735\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8266 - loss: 0.4851 - val_accuracy: 0.8577 - val_loss: 0.3986\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.4124 - val_accuracy: 0.8620 - val_loss: 0.3910\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8583 - loss: 0.3980 - val_accuracy: 0.8654 - val_loss: 0.3681\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3701 - val_accuracy: 0.8689 - val_loss: 0.3670\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8705 - loss: 0.3596 - val_accuracy: 0.8715 - val_loss: 0.3560\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8754 - loss: 0.3471 - val_accuracy: 0.8693 - val_loss: 0.3708\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.3382 - val_accuracy: 0.8738 - val_loss: 0.3450\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.3272 - val_accuracy: 0.8793 - val_loss: 0.3395\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.3230 - val_accuracy: 0.8778 - val_loss: 0.3347\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.3135 - val_accuracy: 0.8777 - val_loss: 0.3411\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8895 - loss: 0.3024 - val_accuracy: 0.8805 - val_loss: 0.3316\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8907 - loss: 0.2979 - val_accuracy: 0.8820 - val_loss: 0.3396\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8923 - loss: 0.2977 - val_accuracy: 0.8780 - val_loss: 0.3331\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.2915 - val_accuracy: 0.8839 - val_loss: 0.3310\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8949 - loss: 0.2856 - val_accuracy: 0.8841 - val_loss: 0.3339\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.2841 - val_accuracy: 0.8858 - val_loss: 0.3274\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8965 - loss: 0.2818 - val_accuracy: 0.8802 - val_loss: 0.3392\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2752 - val_accuracy: 0.8863 - val_loss: 0.3194\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9002 - loss: 0.2721 - val_accuracy: 0.8841 - val_loss: 0.3415\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2719 - val_accuracy: 0.8839 - val_loss: 0.3404\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.2638 - val_accuracy: 0.8826 - val_loss: 0.3274\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.2657 - val_accuracy: 0.8869 - val_loss: 0.3234\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.2617 - val_accuracy: 0.8864 - val_loss: 0.3212\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2688 - val_accuracy: 0.8846 - val_loss: 0.3298\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2602 - val_accuracy: 0.8878 - val_loss: 0.3249\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9065 - loss: 0.2598 - val_accuracy: 0.8889 - val_loss: 0.3137\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2526 - val_accuracy: 0.8901 - val_loss: 0.3211\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.2502 - val_accuracy: 0.8881 - val_loss: 0.3345\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2498 - val_accuracy: 0.8899 - val_loss: 0.3204\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2449 - val_accuracy: 0.8868 - val_loss: 0.3200\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2479 - val_accuracy: 0.8886 - val_loss: 0.3222\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2416 - val_accuracy: 0.8825 - val_loss: 0.3398\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2420 - val_accuracy: 0.8900 - val_loss: 0.3252\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2435 - val_accuracy: 0.8843 - val_loss: 0.3343\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2393 - val_accuracy: 0.8847 - val_loss: 0.3357\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2347 - val_accuracy: 0.8867 - val_loss: 0.3326\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2378 - val_accuracy: 0.8895 - val_loss: 0.3252\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2335 - val_accuracy: 0.8876 - val_loss: 0.3282\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2331 - val_accuracy: 0.8890 - val_loss: 0.3331\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2343 - val_accuracy: 0.8854 - val_loss: 0.3291\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2382 - val_accuracy: 0.8884 - val_loss: 0.3301\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2277 - val_accuracy: 0.8897 - val_loss: 0.3207\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2275 - val_accuracy: 0.8923 - val_loss: 0.3281\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2266 - val_accuracy: 0.8850 - val_loss: 0.3405\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2257 - val_accuracy: 0.8933 - val_loss: 0.3256\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2220 - val_accuracy: 0.8893 - val_loss: 0.3268\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2192 - val_accuracy: 0.8904 - val_loss: 0.3284\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2189 - val_accuracy: 0.8915 - val_loss: 0.3302\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2167 - val_accuracy: 0.8867 - val_loss: 0.3442\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2223 - val_accuracy: 0.8942 - val_loss: 0.3238\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2174 - val_accuracy: 0.8908 - val_loss: 0.3370\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2155 - val_accuracy: 0.8856 - val_loss: 0.3339\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2158 - val_accuracy: 0.8903 - val_loss: 0.3256\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2157 - val_accuracy: 0.8861 - val_loss: 0.3340\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2190 - val_accuracy: 0.8874 - val_loss: 0.3401\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2098 - val_accuracy: 0.8903 - val_loss: 0.3333\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2101 - val_accuracy: 0.8930 - val_loss: 0.3227\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2101 - val_accuracy: 0.8914 - val_loss: 0.3295\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2086 - val_accuracy: 0.8843 - val_loss: 0.3464\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2054 - val_accuracy: 0.8916 - val_loss: 0.3251\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2075 - val_accuracy: 0.8920 - val_loss: 0.3349\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2048 - val_accuracy: 0.8922 - val_loss: 0.3445\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2008 - val_accuracy: 0.8903 - val_loss: 0.3393\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2073 - val_accuracy: 0.8906 - val_loss: 0.3314\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2103 - val_accuracy: 0.8912 - val_loss: 0.3312\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.1942 - val_accuracy: 0.8940 - val_loss: 0.3369\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2018 - val_accuracy: 0.8924 - val_loss: 0.3308\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2039 - val_accuracy: 0.8874 - val_loss: 0.3520\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.1980 - val_accuracy: 0.8931 - val_loss: 0.3395\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2018 - val_accuracy: 0.8921 - val_loss: 0.3306\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.1964 - val_accuracy: 0.8898 - val_loss: 0.3434\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1992 - val_accuracy: 0.8912 - val_loss: 0.3409\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2048 - val_accuracy: 0.8918 - val_loss: 0.3357\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1961 - val_accuracy: 0.8936 - val_loss: 0.3348\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1971 - val_accuracy: 0.8856 - val_loss: 0.3518\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.1961 - val_accuracy: 0.8877 - val_loss: 0.3572\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.1994 - val_accuracy: 0.8904 - val_loss: 0.3535\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1933 - val_accuracy: 0.8878 - val_loss: 0.3558\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9310 - loss: 0.1877 - val_accuracy: 0.8906 - val_loss: 0.3477\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1860 - val_accuracy: 0.8941 - val_loss: 0.3392\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1875 - val_accuracy: 0.8914 - val_loss: 0.3548\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.1913 - val_accuracy: 0.8876 - val_loss: 0.3558\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1853 - val_accuracy: 0.8880 - val_loss: 0.3652\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1908 - val_accuracy: 0.8916 - val_loss: 0.3579\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9317 - loss: 0.1852 - val_accuracy: 0.8898 - val_loss: 0.3470\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9317 - loss: 0.1834 - val_accuracy: 0.8907 - val_loss: 0.3592\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9347 - loss: 0.1823 - val_accuracy: 0.8914 - val_loss: 0.3440\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.1854 - val_accuracy: 0.8934 - val_loss: 0.3545\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.1809 - val_accuracy: 0.8909 - val_loss: 0.3481\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.1887 - val_accuracy: 0.8905 - val_loss: 0.3497\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.1822 - val_accuracy: 0.8910 - val_loss: 0.3493\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1797 - val_accuracy: 0.8914 - val_loss: 0.3509\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.1825 - val_accuracy: 0.8925 - val_loss: 0.3529\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.1842 - val_accuracy: 0.8923 - val_loss: 0.3597\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1796 - val_accuracy: 0.8907 - val_loss: 0.3435\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1768 - val_accuracy: 0.8939 - val_loss: 0.3469\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9358 - loss: 0.1779 - val_accuracy: 0.8884 - val_loss: 0.3614\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.1793 - val_accuracy: 0.8908 - val_loss: 0.3619\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1786 - val_accuracy: 0.8925 - val_loss: 0.3586\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8934 - loss: 0.3655\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6665 - loss: 0.9217 - val_accuracy: 0.8429 - val_loss: 0.4397\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.4608 - val_accuracy: 0.8581 - val_loss: 0.3939\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8531 - loss: 0.4138 - val_accuracy: 0.8655 - val_loss: 0.3743\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3872 - val_accuracy: 0.8659 - val_loss: 0.3660\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8665 - loss: 0.3685 - val_accuracy: 0.8716 - val_loss: 0.3597\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.3463 - val_accuracy: 0.8713 - val_loss: 0.3601\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.3358 - val_accuracy: 0.8738 - val_loss: 0.3501\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8820 - loss: 0.3262 - val_accuracy: 0.8747 - val_loss: 0.3443\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.3164 - val_accuracy: 0.8775 - val_loss: 0.3380\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.3080 - val_accuracy: 0.8792 - val_loss: 0.3324\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.3078 - val_accuracy: 0.8800 - val_loss: 0.3362\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.2998 - val_accuracy: 0.8788 - val_loss: 0.3336\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.2849 - val_accuracy: 0.8858 - val_loss: 0.3199\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2848 - val_accuracy: 0.8849 - val_loss: 0.3310\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.2814 - val_accuracy: 0.8853 - val_loss: 0.3253\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8965 - loss: 0.2794 - val_accuracy: 0.8852 - val_loss: 0.3276\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2741 - val_accuracy: 0.8868 - val_loss: 0.3287\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.2636 - val_accuracy: 0.8844 - val_loss: 0.3216\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.2628 - val_accuracy: 0.8859 - val_loss: 0.3215\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.2639 - val_accuracy: 0.8839 - val_loss: 0.3298\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.2607 - val_accuracy: 0.8881 - val_loss: 0.3188\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.2571 - val_accuracy: 0.8850 - val_loss: 0.3245\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2563 - val_accuracy: 0.8882 - val_loss: 0.3252\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2529 - val_accuracy: 0.8870 - val_loss: 0.3234\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2440 - val_accuracy: 0.8909 - val_loss: 0.3154\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2470 - val_accuracy: 0.8902 - val_loss: 0.3210\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2441 - val_accuracy: 0.8860 - val_loss: 0.3225\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2421 - val_accuracy: 0.8865 - val_loss: 0.3240\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2364 - val_accuracy: 0.8893 - val_loss: 0.3224\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2395 - val_accuracy: 0.8845 - val_loss: 0.3555\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2352 - val_accuracy: 0.8919 - val_loss: 0.3225\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2339 - val_accuracy: 0.8916 - val_loss: 0.3275\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2363 - val_accuracy: 0.8926 - val_loss: 0.3243\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2256 - val_accuracy: 0.8891 - val_loss: 0.3274\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2274 - val_accuracy: 0.8920 - val_loss: 0.3265\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2220 - val_accuracy: 0.8891 - val_loss: 0.3220\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2206 - val_accuracy: 0.8908 - val_loss: 0.3261\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2221 - val_accuracy: 0.8862 - val_loss: 0.3361\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2205 - val_accuracy: 0.8845 - val_loss: 0.3345\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2236 - val_accuracy: 0.8903 - val_loss: 0.3220\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2183 - val_accuracy: 0.8931 - val_loss: 0.3268\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2121 - val_accuracy: 0.8899 - val_loss: 0.3239\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2078 - val_accuracy: 0.8896 - val_loss: 0.3344\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2203 - val_accuracy: 0.8929 - val_loss: 0.3113\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9212 - loss: 0.2119 - val_accuracy: 0.8895 - val_loss: 0.3299\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2103 - val_accuracy: 0.8917 - val_loss: 0.3241\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2110 - val_accuracy: 0.8916 - val_loss: 0.3293\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2109 - val_accuracy: 0.8927 - val_loss: 0.3264\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2069 - val_accuracy: 0.8897 - val_loss: 0.3321\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2052 - val_accuracy: 0.8900 - val_loss: 0.3349\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2082 - val_accuracy: 0.8903 - val_loss: 0.3324\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2015 - val_accuracy: 0.8937 - val_loss: 0.3288\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2008 - val_accuracy: 0.8916 - val_loss: 0.3396\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.1975 - val_accuracy: 0.8893 - val_loss: 0.3387\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1987 - val_accuracy: 0.8926 - val_loss: 0.3273\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1988 - val_accuracy: 0.8894 - val_loss: 0.3356\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1938 - val_accuracy: 0.8931 - val_loss: 0.3390\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2001 - val_accuracy: 0.8873 - val_loss: 0.3465\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.1985 - val_accuracy: 0.8928 - val_loss: 0.3426\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1918 - val_accuracy: 0.8945 - val_loss: 0.3463\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.1988 - val_accuracy: 0.8931 - val_loss: 0.3317\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1891 - val_accuracy: 0.8936 - val_loss: 0.3403\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1934 - val_accuracy: 0.8921 - val_loss: 0.3329\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.1921 - val_accuracy: 0.8927 - val_loss: 0.3454\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1896 - val_accuracy: 0.8975 - val_loss: 0.3259\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1901 - val_accuracy: 0.8904 - val_loss: 0.3448\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1918 - val_accuracy: 0.8944 - val_loss: 0.3413\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.1854 - val_accuracy: 0.8890 - val_loss: 0.3353\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1889 - val_accuracy: 0.8931 - val_loss: 0.3370\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9343 - loss: 0.1783 - val_accuracy: 0.8922 - val_loss: 0.3444\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1862 - val_accuracy: 0.8947 - val_loss: 0.3352\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.1841 - val_accuracy: 0.8919 - val_loss: 0.3383\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.1813 - val_accuracy: 0.8957 - val_loss: 0.3311\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.1829 - val_accuracy: 0.8914 - val_loss: 0.3350\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1758 - val_accuracy: 0.8904 - val_loss: 0.3502\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1808 - val_accuracy: 0.8932 - val_loss: 0.3465\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1782 - val_accuracy: 0.8929 - val_loss: 0.3401\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1752 - val_accuracy: 0.8962 - val_loss: 0.3373\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1777 - val_accuracy: 0.8912 - val_loss: 0.3615\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1779 - val_accuracy: 0.8921 - val_loss: 0.3486\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1774 - val_accuracy: 0.8919 - val_loss: 0.3539\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.1706 - val_accuracy: 0.8917 - val_loss: 0.3627\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.1732 - val_accuracy: 0.8918 - val_loss: 0.3553\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1732 - val_accuracy: 0.8917 - val_loss: 0.3522\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9366 - loss: 0.1688 - val_accuracy: 0.8896 - val_loss: 0.3517\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9366 - loss: 0.1746 - val_accuracy: 0.8963 - val_loss: 0.3474\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1673 - val_accuracy: 0.8915 - val_loss: 0.3608\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1798 - val_accuracy: 0.8927 - val_loss: 0.3527\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1641 - val_accuracy: 0.8952 - val_loss: 0.3530\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1684 - val_accuracy: 0.8945 - val_loss: 0.3426\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.1685 - val_accuracy: 0.8944 - val_loss: 0.3484\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1685 - val_accuracy: 0.8931 - val_loss: 0.3536\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1751 - val_accuracy: 0.8934 - val_loss: 0.3550\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9363 - loss: 0.1705 - val_accuracy: 0.8874 - val_loss: 0.3759\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9364 - loss: 0.1696 - val_accuracy: 0.8909 - val_loss: 0.3552\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.1670 - val_accuracy: 0.8912 - val_loss: 0.3576\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1610 - val_accuracy: 0.8909 - val_loss: 0.3669\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9409 - loss: 0.1631 - val_accuracy: 0.8977 - val_loss: 0.3499\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9381 - loss: 0.1663 - val_accuracy: 0.8928 - val_loss: 0.3680\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.1608 - val_accuracy: 0.8917 - val_loss: 0.3540\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8911 - loss: 0.3684\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6827 - loss: 0.8821 - val_accuracy: 0.8383 - val_loss: 0.4464\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8379 - loss: 0.4495 - val_accuracy: 0.8501 - val_loss: 0.4117\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.4034 - val_accuracy: 0.8657 - val_loss: 0.3826\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8635 - loss: 0.3794 - val_accuracy: 0.8662 - val_loss: 0.3722\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8674 - loss: 0.3602 - val_accuracy: 0.8699 - val_loss: 0.3540\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.3499 - val_accuracy: 0.8713 - val_loss: 0.3496\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3345 - val_accuracy: 0.8712 - val_loss: 0.3546\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8831 - loss: 0.3197 - val_accuracy: 0.8662 - val_loss: 0.3647\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.3188 - val_accuracy: 0.8722 - val_loss: 0.3468\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8848 - loss: 0.3100 - val_accuracy: 0.8824 - val_loss: 0.3316\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3049 - val_accuracy: 0.8772 - val_loss: 0.3374\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.2978 - val_accuracy: 0.8813 - val_loss: 0.3329\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.2883 - val_accuracy: 0.8815 - val_loss: 0.3318\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.2871 - val_accuracy: 0.8870 - val_loss: 0.3178\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2744 - val_accuracy: 0.8872 - val_loss: 0.3268\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2747 - val_accuracy: 0.8807 - val_loss: 0.3325\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.2711 - val_accuracy: 0.8842 - val_loss: 0.3288\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.2684 - val_accuracy: 0.8824 - val_loss: 0.3337\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.2672 - val_accuracy: 0.8852 - val_loss: 0.3333\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.2628 - val_accuracy: 0.8883 - val_loss: 0.3200\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.2592 - val_accuracy: 0.8864 - val_loss: 0.3323\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2555 - val_accuracy: 0.8879 - val_loss: 0.3165\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.2533 - val_accuracy: 0.8851 - val_loss: 0.3308\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2529 - val_accuracy: 0.8905 - val_loss: 0.3157\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2434 - val_accuracy: 0.8883 - val_loss: 0.3175\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.2449 - val_accuracy: 0.8885 - val_loss: 0.3241\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.2437 - val_accuracy: 0.8856 - val_loss: 0.3214\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2384 - val_accuracy: 0.8883 - val_loss: 0.3211\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2400 - val_accuracy: 0.8865 - val_loss: 0.3145\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2348 - val_accuracy: 0.8891 - val_loss: 0.3200\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2279 - val_accuracy: 0.8927 - val_loss: 0.3140\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2326 - val_accuracy: 0.8882 - val_loss: 0.3265\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2284 - val_accuracy: 0.8901 - val_loss: 0.3158\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2321 - val_accuracy: 0.8859 - val_loss: 0.3362\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2348 - val_accuracy: 0.8865 - val_loss: 0.3250\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2178 - val_accuracy: 0.8919 - val_loss: 0.3159\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2225 - val_accuracy: 0.8902 - val_loss: 0.3260\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2203 - val_accuracy: 0.8919 - val_loss: 0.3343\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2236 - val_accuracy: 0.8924 - val_loss: 0.3258\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2219 - val_accuracy: 0.8940 - val_loss: 0.3209\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2135 - val_accuracy: 0.8880 - val_loss: 0.3282\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2128 - val_accuracy: 0.8912 - val_loss: 0.3325\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2119 - val_accuracy: 0.8879 - val_loss: 0.3213\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.2089 - val_accuracy: 0.8933 - val_loss: 0.3189\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2141 - val_accuracy: 0.8939 - val_loss: 0.3223\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2089 - val_accuracy: 0.8950 - val_loss: 0.3265\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2084 - val_accuracy: 0.8903 - val_loss: 0.3243\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2027 - val_accuracy: 0.8929 - val_loss: 0.3247\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9219 - loss: 0.2067 - val_accuracy: 0.8907 - val_loss: 0.3401\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2041 - val_accuracy: 0.8946 - val_loss: 0.3320\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2075 - val_accuracy: 0.8948 - val_loss: 0.3373\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.2091 - val_accuracy: 0.8907 - val_loss: 0.3439\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.1994 - val_accuracy: 0.8914 - val_loss: 0.3375\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.1943 - val_accuracy: 0.8945 - val_loss: 0.3270\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2037 - val_accuracy: 0.8908 - val_loss: 0.3389\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.1991 - val_accuracy: 0.8881 - val_loss: 0.3478\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.1972 - val_accuracy: 0.8910 - val_loss: 0.3532\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2001 - val_accuracy: 0.8949 - val_loss: 0.3523\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.1992 - val_accuracy: 0.8936 - val_loss: 0.3311\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1887 - val_accuracy: 0.8937 - val_loss: 0.3355\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.1876 - val_accuracy: 0.8940 - val_loss: 0.3299\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.1869 - val_accuracy: 0.8932 - val_loss: 0.3317\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1861 - val_accuracy: 0.8893 - val_loss: 0.3381\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1870 - val_accuracy: 0.8923 - val_loss: 0.3386\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.1918 - val_accuracy: 0.8932 - val_loss: 0.3377\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.1831 - val_accuracy: 0.8923 - val_loss: 0.3373\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.1878 - val_accuracy: 0.8936 - val_loss: 0.3441\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.1834 - val_accuracy: 0.8939 - val_loss: 0.3407\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1809 - val_accuracy: 0.8948 - val_loss: 0.3317\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.1834 - val_accuracy: 0.8963 - val_loss: 0.3375\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.1803 - val_accuracy: 0.8953 - val_loss: 0.3494\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1874 - val_accuracy: 0.8887 - val_loss: 0.3506\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.1862 - val_accuracy: 0.8929 - val_loss: 0.3346\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.1831 - val_accuracy: 0.8907 - val_loss: 0.3568\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1826 - val_accuracy: 0.8930 - val_loss: 0.3436\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1807 - val_accuracy: 0.8935 - val_loss: 0.3550\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1798 - val_accuracy: 0.8918 - val_loss: 0.3546\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9331 - loss: 0.1804 - val_accuracy: 0.8924 - val_loss: 0.3761\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9327 - loss: 0.1817 - val_accuracy: 0.8942 - val_loss: 0.3547\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1788 - val_accuracy: 0.8910 - val_loss: 0.3487\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.1771 - val_accuracy: 0.8957 - val_loss: 0.3549\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1705 - val_accuracy: 0.8941 - val_loss: 0.3597\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1753 - val_accuracy: 0.8916 - val_loss: 0.3512\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.1773 - val_accuracy: 0.8878 - val_loss: 0.3698\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9344 - loss: 0.1736 - val_accuracy: 0.8916 - val_loss: 0.3582\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9331 - loss: 0.1753 - val_accuracy: 0.8932 - val_loss: 0.3540\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1726 - val_accuracy: 0.8946 - val_loss: 0.3465\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1669 - val_accuracy: 0.8943 - val_loss: 0.3426\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.1743 - val_accuracy: 0.8928 - val_loss: 0.3588\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9364 - loss: 0.1698 - val_accuracy: 0.8966 - val_loss: 0.3720\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.1684 - val_accuracy: 0.8937 - val_loss: 0.3611\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1680 - val_accuracy: 0.8954 - val_loss: 0.3530\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1715 - val_accuracy: 0.8951 - val_loss: 0.3614\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.1644 - val_accuracy: 0.8972 - val_loss: 0.3610\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1662 - val_accuracy: 0.8881 - val_loss: 0.3625\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.1715 - val_accuracy: 0.8950 - val_loss: 0.3523\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.1658 - val_accuracy: 0.8931 - val_loss: 0.3586\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1637 - val_accuracy: 0.8933 - val_loss: 0.3529\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1666 - val_accuracy: 0.8923 - val_loss: 0.3653\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1592 - val_accuracy: 0.8957 - val_loss: 0.3589\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8951 - loss: 0.3597\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.8395 - val_accuracy: 0.8398 - val_loss: 0.4435\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8459 - loss: 0.4303 - val_accuracy: 0.8588 - val_loss: 0.3838\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3843 - val_accuracy: 0.8613 - val_loss: 0.3763\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.3676 - val_accuracy: 0.8604 - val_loss: 0.3711\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.3517 - val_accuracy: 0.8722 - val_loss: 0.3503\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8796 - loss: 0.3263 - val_accuracy: 0.8773 - val_loss: 0.3439\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.3241 - val_accuracy: 0.8741 - val_loss: 0.3397\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.3147 - val_accuracy: 0.8757 - val_loss: 0.3448\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.3128 - val_accuracy: 0.8802 - val_loss: 0.3409\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3059 - val_accuracy: 0.8801 - val_loss: 0.3337\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.2876 - val_accuracy: 0.8857 - val_loss: 0.3192\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.2875 - val_accuracy: 0.8804 - val_loss: 0.3277\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8935 - loss: 0.2857 - val_accuracy: 0.8790 - val_loss: 0.3305\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8996 - loss: 0.2729 - val_accuracy: 0.8839 - val_loss: 0.3252\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.2713 - val_accuracy: 0.8885 - val_loss: 0.3205\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.2678 - val_accuracy: 0.8889 - val_loss: 0.3225\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2646 - val_accuracy: 0.8872 - val_loss: 0.3158\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.2585 - val_accuracy: 0.8858 - val_loss: 0.3239\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2603 - val_accuracy: 0.8886 - val_loss: 0.3084\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2475 - val_accuracy: 0.8885 - val_loss: 0.3150\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2512 - val_accuracy: 0.8833 - val_loss: 0.3201\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2483 - val_accuracy: 0.8894 - val_loss: 0.3128\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2446 - val_accuracy: 0.8829 - val_loss: 0.3236\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9065 - loss: 0.2435 - val_accuracy: 0.8892 - val_loss: 0.3193\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2360 - val_accuracy: 0.8912 - val_loss: 0.3196\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2356 - val_accuracy: 0.8922 - val_loss: 0.3136\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2320 - val_accuracy: 0.8894 - val_loss: 0.3229\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2316 - val_accuracy: 0.8878 - val_loss: 0.3293\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2299 - val_accuracy: 0.8917 - val_loss: 0.3224\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2258 - val_accuracy: 0.8900 - val_loss: 0.3257\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2305 - val_accuracy: 0.8882 - val_loss: 0.3261\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2217 - val_accuracy: 0.8918 - val_loss: 0.3309\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2210 - val_accuracy: 0.8913 - val_loss: 0.3208\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2257 - val_accuracy: 0.8890 - val_loss: 0.3259\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2169 - val_accuracy: 0.8930 - val_loss: 0.3225\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2170 - val_accuracy: 0.8928 - val_loss: 0.3331\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2158 - val_accuracy: 0.8968 - val_loss: 0.3117\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2143 - val_accuracy: 0.8905 - val_loss: 0.3148\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2111 - val_accuracy: 0.8923 - val_loss: 0.3411\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2122 - val_accuracy: 0.8929 - val_loss: 0.3250\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2121 - val_accuracy: 0.8897 - val_loss: 0.3231\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9210 - loss: 0.2067 - val_accuracy: 0.8943 - val_loss: 0.3269\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2067 - val_accuracy: 0.8901 - val_loss: 0.3457\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2085 - val_accuracy: 0.8917 - val_loss: 0.3357\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2024 - val_accuracy: 0.8928 - val_loss: 0.3447\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2000 - val_accuracy: 0.8951 - val_loss: 0.3276\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.1992 - val_accuracy: 0.8926 - val_loss: 0.3353\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1934 - val_accuracy: 0.8897 - val_loss: 0.3383\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2029 - val_accuracy: 0.8936 - val_loss: 0.3356\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.1924 - val_accuracy: 0.8931 - val_loss: 0.3276\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.1934 - val_accuracy: 0.8924 - val_loss: 0.3330\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.1895 - val_accuracy: 0.8948 - val_loss: 0.3280\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.1881 - val_accuracy: 0.8915 - val_loss: 0.3380\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.1924 - val_accuracy: 0.8953 - val_loss: 0.3165\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.1836 - val_accuracy: 0.8947 - val_loss: 0.3335\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.1913 - val_accuracy: 0.8960 - val_loss: 0.3324\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1863 - val_accuracy: 0.8937 - val_loss: 0.3349\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1865 - val_accuracy: 0.8926 - val_loss: 0.3498\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1823 - val_accuracy: 0.8948 - val_loss: 0.3378\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1850 - val_accuracy: 0.8938 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1846 - val_accuracy: 0.8949 - val_loss: 0.3470\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1786 - val_accuracy: 0.8988 - val_loss: 0.3423\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1828 - val_accuracy: 0.8946 - val_loss: 0.3464\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1801 - val_accuracy: 0.8965 - val_loss: 0.3512\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.1789 - val_accuracy: 0.8939 - val_loss: 0.3576\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1793 - val_accuracy: 0.8932 - val_loss: 0.3533\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1775 - val_accuracy: 0.8908 - val_loss: 0.3466\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9318 - loss: 0.1776 - val_accuracy: 0.8939 - val_loss: 0.3431\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.1703 - val_accuracy: 0.8924 - val_loss: 0.3549\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.1750 - val_accuracy: 0.8904 - val_loss: 0.3661\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1723 - val_accuracy: 0.8897 - val_loss: 0.3548\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.1737 - val_accuracy: 0.8942 - val_loss: 0.3680\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9351 - loss: 0.1716 - val_accuracy: 0.8888 - val_loss: 0.3572\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1743 - val_accuracy: 0.8950 - val_loss: 0.3608\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.1700 - val_accuracy: 0.8973 - val_loss: 0.3474\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.1678 - val_accuracy: 0.8933 - val_loss: 0.3456\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1741 - val_accuracy: 0.8944 - val_loss: 0.3511\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.1689 - val_accuracy: 0.8930 - val_loss: 0.3559\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.1712 - val_accuracy: 0.8959 - val_loss: 0.3665\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1650 - val_accuracy: 0.8940 - val_loss: 0.3618\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9381 - loss: 0.1628 - val_accuracy: 0.8938 - val_loss: 0.3539\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1603 - val_accuracy: 0.8943 - val_loss: 0.3582\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.1640 - val_accuracy: 0.8952 - val_loss: 0.3653\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.1560 - val_accuracy: 0.8917 - val_loss: 0.3667\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.1632 - val_accuracy: 0.8937 - val_loss: 0.3634\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1637 - val_accuracy: 0.8943 - val_loss: 0.3673\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1635 - val_accuracy: 0.8943 - val_loss: 0.3567\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1638 - val_accuracy: 0.8962 - val_loss: 0.3667\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9409 - loss: 0.1574 - val_accuracy: 0.8959 - val_loss: 0.3618\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1602 - val_accuracy: 0.8903 - val_loss: 0.3718\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.1600 - val_accuracy: 0.8960 - val_loss: 0.3660\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1597 - val_accuracy: 0.8921 - val_loss: 0.3728\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1586 - val_accuracy: 0.8901 - val_loss: 0.3800\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1546 - val_accuracy: 0.8884 - val_loss: 0.3846\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1596 - val_accuracy: 0.8964 - val_loss: 0.3641\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1590 - val_accuracy: 0.8919 - val_loss: 0.3652\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1565 - val_accuracy: 0.8932 - val_loss: 0.3914\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.1572 - val_accuracy: 0.8970 - val_loss: 0.3702\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1553 - val_accuracy: 0.8949 - val_loss: 0.3750\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1499 - val_accuracy: 0.8977 - val_loss: 0.3728\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.8990 - loss: 0.3858\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.8943 - val_accuracy: 0.8433 - val_loss: 0.4358\n",
      "Epoch 2/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.4677 - val_accuracy: 0.8502 - val_loss: 0.4096\n",
      "Epoch 3/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8487 - loss: 0.4213 - val_accuracy: 0.8610 - val_loss: 0.3909\n",
      "Epoch 4/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8552 - loss: 0.4027 - val_accuracy: 0.8626 - val_loss: 0.3661\n",
      "Epoch 5/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3837 - val_accuracy: 0.8624 - val_loss: 0.3766\n",
      "Epoch 6/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8656 - loss: 0.3673 - val_accuracy: 0.8697 - val_loss: 0.3606\n",
      "Epoch 7/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3666 - val_accuracy: 0.8698 - val_loss: 0.3607\n",
      "Epoch 8/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8729 - loss: 0.3532 - val_accuracy: 0.8751 - val_loss: 0.3477\n",
      "Epoch 9/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8739 - loss: 0.3438 - val_accuracy: 0.8755 - val_loss: 0.3471\n",
      "Epoch 10/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.3315 - val_accuracy: 0.8742 - val_loss: 0.3514\n",
      "Epoch 11/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8805 - loss: 0.3269 - val_accuracy: 0.8757 - val_loss: 0.3517\n",
      "Epoch 12/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8822 - loss: 0.3230 - val_accuracy: 0.8813 - val_loss: 0.3339\n",
      "Epoch 13/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8822 - loss: 0.3203 - val_accuracy: 0.8720 - val_loss: 0.3488\n",
      "Epoch 14/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3182 - val_accuracy: 0.8791 - val_loss: 0.3374\n",
      "Epoch 15/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8894 - loss: 0.3054 - val_accuracy: 0.8824 - val_loss: 0.3357\n",
      "Epoch 16/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.3019 - val_accuracy: 0.8775 - val_loss: 0.3461\n",
      "Epoch 17/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3024 - val_accuracy: 0.8838 - val_loss: 0.3294\n",
      "Epoch 18/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8902 - loss: 0.3011 - val_accuracy: 0.8809 - val_loss: 0.3368\n",
      "Epoch 19/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8887 - loss: 0.2978 - val_accuracy: 0.8840 - val_loss: 0.3258\n",
      "Epoch 20/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8919 - loss: 0.2864 - val_accuracy: 0.8817 - val_loss: 0.3362\n",
      "Epoch 21/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.2915 - val_accuracy: 0.8817 - val_loss: 0.3320\n",
      "Epoch 22/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.2835 - val_accuracy: 0.8813 - val_loss: 0.3319\n",
      "Epoch 23/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.2834 - val_accuracy: 0.8830 - val_loss: 0.3294\n",
      "Epoch 24/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.2805 - val_accuracy: 0.8826 - val_loss: 0.3286\n",
      "Epoch 25/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8958 - loss: 0.2831 - val_accuracy: 0.8819 - val_loss: 0.3234\n",
      "Epoch 26/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2746 - val_accuracy: 0.8868 - val_loss: 0.3229\n",
      "Epoch 27/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.2775 - val_accuracy: 0.8820 - val_loss: 0.3321\n",
      "Epoch 28/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.2773 - val_accuracy: 0.8833 - val_loss: 0.3342\n",
      "Epoch 29/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.2640 - val_accuracy: 0.8862 - val_loss: 0.3270\n",
      "Epoch 30/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2605 - val_accuracy: 0.8820 - val_loss: 0.3300\n",
      "Epoch 31/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.2701 - val_accuracy: 0.8848 - val_loss: 0.3264\n",
      "Epoch 32/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.2679 - val_accuracy: 0.8905 - val_loss: 0.3221\n",
      "Epoch 33/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2621 - val_accuracy: 0.8838 - val_loss: 0.3291\n",
      "Epoch 34/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9026 - loss: 0.2609 - val_accuracy: 0.8858 - val_loss: 0.3209\n",
      "Epoch 35/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2571 - val_accuracy: 0.8915 - val_loss: 0.3125\n",
      "Epoch 36/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2528 - val_accuracy: 0.8890 - val_loss: 0.3171\n",
      "Epoch 37/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2584 - val_accuracy: 0.8878 - val_loss: 0.3236\n",
      "Epoch 38/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2544 - val_accuracy: 0.8874 - val_loss: 0.3277\n",
      "Epoch 39/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.2591 - val_accuracy: 0.8903 - val_loss: 0.3133\n",
      "Epoch 40/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.2522 - val_accuracy: 0.8897 - val_loss: 0.3256\n",
      "Epoch 41/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2520 - val_accuracy: 0.8882 - val_loss: 0.3210\n",
      "Epoch 42/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2527 - val_accuracy: 0.8893 - val_loss: 0.3157\n",
      "Epoch 43/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2474 - val_accuracy: 0.8925 - val_loss: 0.3168\n",
      "Epoch 44/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2546 - val_accuracy: 0.8946 - val_loss: 0.3113\n",
      "Epoch 45/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2414 - val_accuracy: 0.8902 - val_loss: 0.3300\n",
      "Epoch 46/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2513 - val_accuracy: 0.8901 - val_loss: 0.3155\n",
      "Epoch 47/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2448 - val_accuracy: 0.8888 - val_loss: 0.3279\n",
      "Epoch 48/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2491 - val_accuracy: 0.8898 - val_loss: 0.3206\n",
      "Epoch 49/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2450 - val_accuracy: 0.8914 - val_loss: 0.3198\n",
      "Epoch 50/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2322 - val_accuracy: 0.8909 - val_loss: 0.3181\n",
      "Epoch 51/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2379 - val_accuracy: 0.8885 - val_loss: 0.3206\n",
      "Epoch 52/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2375 - val_accuracy: 0.8929 - val_loss: 0.3211\n",
      "Epoch 53/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2340 - val_accuracy: 0.8877 - val_loss: 0.3373\n",
      "Epoch 54/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2373 - val_accuracy: 0.8909 - val_loss: 0.3201\n",
      "Epoch 55/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2328 - val_accuracy: 0.8968 - val_loss: 0.3151\n",
      "Epoch 56/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2353 - val_accuracy: 0.8935 - val_loss: 0.3229\n",
      "Epoch 57/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2308 - val_accuracy: 0.8918 - val_loss: 0.3224\n",
      "Epoch 58/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2365 - val_accuracy: 0.8940 - val_loss: 0.3198\n",
      "Epoch 59/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2297 - val_accuracy: 0.8906 - val_loss: 0.3290\n",
      "Epoch 60/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2337 - val_accuracy: 0.8920 - val_loss: 0.3207\n",
      "Epoch 61/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2299 - val_accuracy: 0.8910 - val_loss: 0.3189\n",
      "Epoch 62/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2303 - val_accuracy: 0.8930 - val_loss: 0.3205\n",
      "Epoch 63/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2249 - val_accuracy: 0.8905 - val_loss: 0.3292\n",
      "Epoch 64/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2215 - val_accuracy: 0.8950 - val_loss: 0.3157\n",
      "Epoch 65/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2281 - val_accuracy: 0.8889 - val_loss: 0.3260\n",
      "Epoch 66/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2252 - val_accuracy: 0.8921 - val_loss: 0.3224\n",
      "Epoch 67/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2251 - val_accuracy: 0.8899 - val_loss: 0.3236\n",
      "Epoch 68/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2273 - val_accuracy: 0.8920 - val_loss: 0.3193\n",
      "Epoch 69/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2243 - val_accuracy: 0.8903 - val_loss: 0.3234\n",
      "Epoch 70/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2193 - val_accuracy: 0.8892 - val_loss: 0.3273\n",
      "Epoch 71/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2215 - val_accuracy: 0.8905 - val_loss: 0.3232\n",
      "Epoch 72/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2171 - val_accuracy: 0.8917 - val_loss: 0.3299\n",
      "Epoch 73/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2154 - val_accuracy: 0.8887 - val_loss: 0.3322\n",
      "Epoch 74/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2265 - val_accuracy: 0.8899 - val_loss: 0.3257\n",
      "Epoch 75/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2175 - val_accuracy: 0.8942 - val_loss: 0.3379\n",
      "Epoch 76/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2194 - val_accuracy: 0.8937 - val_loss: 0.3216\n",
      "Epoch 77/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2163 - val_accuracy: 0.8941 - val_loss: 0.3296\n",
      "Epoch 78/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2152 - val_accuracy: 0.8913 - val_loss: 0.3340\n",
      "Epoch 79/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2182 - val_accuracy: 0.8903 - val_loss: 0.3239\n",
      "Epoch 80/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9219 - loss: 0.2114 - val_accuracy: 0.8899 - val_loss: 0.3266\n",
      "Epoch 81/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9210 - loss: 0.2164 - val_accuracy: 0.8938 - val_loss: 0.3247\n",
      "Epoch 82/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2142 - val_accuracy: 0.8936 - val_loss: 0.3331\n",
      "Epoch 83/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2189 - val_accuracy: 0.8879 - val_loss: 0.3367\n",
      "Epoch 84/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2123 - val_accuracy: 0.8951 - val_loss: 0.3156\n",
      "Epoch 85/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2096 - val_accuracy: 0.8916 - val_loss: 0.3276\n",
      "Epoch 86/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2095 - val_accuracy: 0.8921 - val_loss: 0.3229\n",
      "Epoch 87/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2165 - val_accuracy: 0.8926 - val_loss: 0.3296\n",
      "Epoch 88/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2111 - val_accuracy: 0.8913 - val_loss: 0.3248\n",
      "Epoch 89/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2132 - val_accuracy: 0.8918 - val_loss: 0.3379\n",
      "Epoch 90/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2055 - val_accuracy: 0.8956 - val_loss: 0.3234\n",
      "Epoch 91/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2075 - val_accuracy: 0.8898 - val_loss: 0.3444\n",
      "Epoch 92/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2051 - val_accuracy: 0.8907 - val_loss: 0.3357\n",
      "Epoch 93/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2063 - val_accuracy: 0.8932 - val_loss: 0.3314\n",
      "Epoch 94/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2115 - val_accuracy: 0.8922 - val_loss: 0.3355\n",
      "Epoch 95/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2032 - val_accuracy: 0.8921 - val_loss: 0.3354\n",
      "Epoch 96/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2068 - val_accuracy: 0.8922 - val_loss: 0.3301\n",
      "Epoch 97/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2086 - val_accuracy: 0.8933 - val_loss: 0.3283\n",
      "Epoch 98/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2066 - val_accuracy: 0.8935 - val_loss: 0.3267\n",
      "Epoch 99/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.1958 - val_accuracy: 0.8930 - val_loss: 0.3261\n",
      "Epoch 100/100\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9247 - loss: 0.2050 - val_accuracy: 0.8907 - val_loss: 0.3418\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.8902 - loss: 0.3450\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=100,batch_size=100,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7304 - loss: 0.7511 - val_accuracy: 0.8385 - val_loss: 0.4472\n",
      "Epoch 2/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.4301 - val_accuracy: 0.8415 - val_loss: 0.4238\n",
      "Epoch 3/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8579 - loss: 0.3866 - val_accuracy: 0.8606 - val_loss: 0.3822\n",
      "Epoch 4/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3674 - val_accuracy: 0.8653 - val_loss: 0.3727\n",
      "Epoch 5/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8748 - loss: 0.3437 - val_accuracy: 0.8740 - val_loss: 0.3497\n",
      "Epoch 6/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8766 - loss: 0.3341 - val_accuracy: 0.8743 - val_loss: 0.3453\n",
      "Epoch 7/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.3217 - val_accuracy: 0.8760 - val_loss: 0.3436\n",
      "Epoch 8/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.3154 - val_accuracy: 0.8746 - val_loss: 0.3420\n",
      "Epoch 9/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.3125 - val_accuracy: 0.8762 - val_loss: 0.3382\n",
      "Epoch 10/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8919 - loss: 0.2921 - val_accuracy: 0.8788 - val_loss: 0.3274\n",
      "Epoch 11/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.2923 - val_accuracy: 0.8794 - val_loss: 0.3379\n",
      "Epoch 12/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2829 - val_accuracy: 0.8809 - val_loss: 0.3275\n",
      "Epoch 13/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.2788 - val_accuracy: 0.8843 - val_loss: 0.3222\n",
      "Epoch 14/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.2771 - val_accuracy: 0.8769 - val_loss: 0.3343\n",
      "Epoch 15/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.2747 - val_accuracy: 0.8857 - val_loss: 0.3236\n",
      "Epoch 16/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.2728 - val_accuracy: 0.8839 - val_loss: 0.3227\n",
      "Epoch 17/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.2651 - val_accuracy: 0.8819 - val_loss: 0.3268\n",
      "Epoch 18/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9043 - loss: 0.2574 - val_accuracy: 0.8849 - val_loss: 0.3392\n",
      "Epoch 19/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.2544 - val_accuracy: 0.8826 - val_loss: 0.3288\n",
      "Epoch 20/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2541 - val_accuracy: 0.8860 - val_loss: 0.3209\n",
      "Epoch 21/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2501 - val_accuracy: 0.8814 - val_loss: 0.3230\n",
      "Epoch 22/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9058 - loss: 0.2535 - val_accuracy: 0.8905 - val_loss: 0.3122\n",
      "Epoch 23/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2420 - val_accuracy: 0.8889 - val_loss: 0.3201\n",
      "Epoch 24/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2489 - val_accuracy: 0.8912 - val_loss: 0.3183\n",
      "Epoch 25/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2409 - val_accuracy: 0.8945 - val_loss: 0.3069\n",
      "Epoch 26/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2337 - val_accuracy: 0.8890 - val_loss: 0.3206\n",
      "Epoch 27/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2379 - val_accuracy: 0.8982 - val_loss: 0.3047\n",
      "Epoch 28/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2325 - val_accuracy: 0.8961 - val_loss: 0.3078\n",
      "Epoch 29/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2340 - val_accuracy: 0.8922 - val_loss: 0.3156\n",
      "Epoch 30/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2251 - val_accuracy: 0.8885 - val_loss: 0.3172\n",
      "Epoch 31/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2314 - val_accuracy: 0.8951 - val_loss: 0.3149\n",
      "Epoch 32/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2236 - val_accuracy: 0.8922 - val_loss: 0.3261\n",
      "Epoch 33/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2288 - val_accuracy: 0.8916 - val_loss: 0.3151\n",
      "Epoch 34/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2248 - val_accuracy: 0.8929 - val_loss: 0.3155\n",
      "Epoch 35/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2193 - val_accuracy: 0.8922 - val_loss: 0.3275\n",
      "Epoch 36/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2196 - val_accuracy: 0.8918 - val_loss: 0.3143\n",
      "Epoch 37/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2110 - val_accuracy: 0.8949 - val_loss: 0.3172\n",
      "Epoch 38/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2093 - val_accuracy: 0.8926 - val_loss: 0.3219\n",
      "Epoch 39/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2182 - val_accuracy: 0.8943 - val_loss: 0.3197\n",
      "Epoch 40/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9207 - loss: 0.2125 - val_accuracy: 0.8938 - val_loss: 0.3299\n",
      "Epoch 41/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2112 - val_accuracy: 0.8956 - val_loss: 0.3241\n",
      "Epoch 42/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2127 - val_accuracy: 0.8914 - val_loss: 0.3238\n",
      "Epoch 43/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2049 - val_accuracy: 0.8948 - val_loss: 0.3253\n",
      "Epoch 44/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2030 - val_accuracy: 0.8997 - val_loss: 0.3132\n",
      "Epoch 45/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2056 - val_accuracy: 0.8952 - val_loss: 0.3241\n",
      "Epoch 46/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2081 - val_accuracy: 0.8975 - val_loss: 0.3198\n",
      "Epoch 47/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.1957 - val_accuracy: 0.8959 - val_loss: 0.3206\n",
      "Epoch 48/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2005 - val_accuracy: 0.8975 - val_loss: 0.3307\n",
      "Epoch 49/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.1983 - val_accuracy: 0.8920 - val_loss: 0.3291\n",
      "Epoch 50/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.1931 - val_accuracy: 0.8962 - val_loss: 0.3170\n",
      "Epoch 51/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1953 - val_accuracy: 0.8982 - val_loss: 0.3310\n",
      "Epoch 52/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1961 - val_accuracy: 0.8952 - val_loss: 0.3244\n",
      "Epoch 53/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.1934 - val_accuracy: 0.8950 - val_loss: 0.3344\n",
      "Epoch 54/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2036 - val_accuracy: 0.9009 - val_loss: 0.3173\n",
      "Epoch 55/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.1922 - val_accuracy: 0.8985 - val_loss: 0.3448\n",
      "Epoch 56/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1896 - val_accuracy: 0.8899 - val_loss: 0.3527\n",
      "Epoch 57/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.1960 - val_accuracy: 0.8974 - val_loss: 0.3285\n",
      "Epoch 58/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.1843 - val_accuracy: 0.8923 - val_loss: 0.3450\n",
      "Epoch 59/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.1958 - val_accuracy: 0.9013 - val_loss: 0.3301\n",
      "Epoch 60/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.1845 - val_accuracy: 0.8958 - val_loss: 0.3466\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8941 - loss: 0.3508\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=60,batch_size=60,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.8095 - val_accuracy: 0.8348 - val_loss: 0.4610\n",
      "Epoch 2/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.4373 - val_accuracy: 0.8605 - val_loss: 0.3916\n",
      "Epoch 3/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8588 - loss: 0.3941 - val_accuracy: 0.8595 - val_loss: 0.3801\n",
      "Epoch 4/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3673 - val_accuracy: 0.8578 - val_loss: 0.3919\n",
      "Epoch 5/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3576 - val_accuracy: 0.8729 - val_loss: 0.3566\n",
      "Epoch 6/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.3368 - val_accuracy: 0.8736 - val_loss: 0.3595\n",
      "Epoch 7/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8825 - loss: 0.3243 - val_accuracy: 0.8774 - val_loss: 0.3377\n",
      "Epoch 8/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.3106 - val_accuracy: 0.8795 - val_loss: 0.3343\n",
      "Epoch 9/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3023 - val_accuracy: 0.8840 - val_loss: 0.3285\n",
      "Epoch 10/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.2974 - val_accuracy: 0.8814 - val_loss: 0.3265\n",
      "Epoch 11/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.2923 - val_accuracy: 0.8788 - val_loss: 0.3361\n",
      "Epoch 12/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8977 - loss: 0.2734 - val_accuracy: 0.8827 - val_loss: 0.3287\n",
      "Epoch 13/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.2857 - val_accuracy: 0.8853 - val_loss: 0.3211\n",
      "Epoch 14/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2719 - val_accuracy: 0.8817 - val_loss: 0.3273\n",
      "Epoch 15/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.2657 - val_accuracy: 0.8838 - val_loss: 0.3233\n",
      "Epoch 16/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2656 - val_accuracy: 0.8859 - val_loss: 0.3186\n",
      "Epoch 17/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2558 - val_accuracy: 0.8907 - val_loss: 0.3182\n",
      "Epoch 18/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9058 - loss: 0.2517 - val_accuracy: 0.8897 - val_loss: 0.3144\n",
      "Epoch 19/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2493 - val_accuracy: 0.8804 - val_loss: 0.3489\n",
      "Epoch 20/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.2532 - val_accuracy: 0.8895 - val_loss: 0.3156\n",
      "Epoch 21/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2384 - val_accuracy: 0.8910 - val_loss: 0.3164\n",
      "Epoch 22/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2510 - val_accuracy: 0.8921 - val_loss: 0.3119\n",
      "Epoch 23/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2359 - val_accuracy: 0.8874 - val_loss: 0.3297\n",
      "Epoch 24/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2321 - val_accuracy: 0.8893 - val_loss: 0.3088\n",
      "Epoch 25/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2361 - val_accuracy: 0.8903 - val_loss: 0.3159\n",
      "Epoch 26/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2328 - val_accuracy: 0.8944 - val_loss: 0.3177\n",
      "Epoch 27/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2270 - val_accuracy: 0.8873 - val_loss: 0.3354\n",
      "Epoch 28/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2303 - val_accuracy: 0.8865 - val_loss: 0.3262\n",
      "Epoch 29/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2224 - val_accuracy: 0.8909 - val_loss: 0.3127\n",
      "Epoch 30/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2169 - val_accuracy: 0.8946 - val_loss: 0.3132\n",
      "Epoch 31/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2129 - val_accuracy: 0.8961 - val_loss: 0.3173\n",
      "Epoch 32/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2159 - val_accuracy: 0.8940 - val_loss: 0.3247\n",
      "Epoch 33/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2131 - val_accuracy: 0.8897 - val_loss: 0.3344\n",
      "Epoch 34/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2102 - val_accuracy: 0.8951 - val_loss: 0.3204\n",
      "Epoch 35/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9212 - loss: 0.2108 - val_accuracy: 0.8928 - val_loss: 0.3242\n",
      "Epoch 36/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2063 - val_accuracy: 0.8959 - val_loss: 0.3224\n",
      "Epoch 37/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2061 - val_accuracy: 0.8958 - val_loss: 0.3214\n",
      "Epoch 38/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.2045 - val_accuracy: 0.8958 - val_loss: 0.3197\n",
      "Epoch 39/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2047 - val_accuracy: 0.8983 - val_loss: 0.3099\n",
      "Epoch 40/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2017 - val_accuracy: 0.8970 - val_loss: 0.3258\n",
      "Epoch 41/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.1978 - val_accuracy: 0.8949 - val_loss: 0.3268\n",
      "Epoch 42/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.1914 - val_accuracy: 0.8915 - val_loss: 0.3335\n",
      "Epoch 43/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.1976 - val_accuracy: 0.8949 - val_loss: 0.3219\n",
      "Epoch 44/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1935 - val_accuracy: 0.8955 - val_loss: 0.3329\n",
      "Epoch 45/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.1959 - val_accuracy: 0.8992 - val_loss: 0.3263\n",
      "Epoch 46/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1979 - val_accuracy: 0.8951 - val_loss: 0.3299\n",
      "Epoch 47/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.1910 - val_accuracy: 0.8948 - val_loss: 0.3411\n",
      "Epoch 48/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1869 - val_accuracy: 0.8963 - val_loss: 0.3348\n",
      "Epoch 49/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1909 - val_accuracy: 0.8962 - val_loss: 0.3316\n",
      "Epoch 50/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1835 - val_accuracy: 0.8958 - val_loss: 0.3365\n",
      "Epoch 51/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1901 - val_accuracy: 0.8990 - val_loss: 0.3637\n",
      "Epoch 52/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.1859 - val_accuracy: 0.8940 - val_loss: 0.3446\n",
      "Epoch 53/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.1866 - val_accuracy: 0.8962 - val_loss: 0.3323\n",
      "Epoch 54/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1880 - val_accuracy: 0.8958 - val_loss: 0.3554\n",
      "Epoch 55/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.1850 - val_accuracy: 0.8920 - val_loss: 0.3543\n",
      "Epoch 56/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1796 - val_accuracy: 0.8910 - val_loss: 0.3444\n",
      "Epoch 57/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1834 - val_accuracy: 0.8979 - val_loss: 0.3307\n",
      "Epoch 58/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9343 - loss: 0.1763 - val_accuracy: 0.8952 - val_loss: 0.3260\n",
      "Epoch 59/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9358 - loss: 0.1745 - val_accuracy: 0.8949 - val_loss: 0.3593\n",
      "Epoch 60/60\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.1745 - val_accuracy: 0.8904 - val_loss: 0.3647\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.8893 - loss: 0.3776\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(xtrain2,y_trainc,epochs=60,batch_size=60,validation_data=(xtest2,y_testc))\n",
    "\n",
    "tloss,tacc=model2.evaluate(xtest2,y_testc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
